{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kebbie","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Welcome to the documentation of the <code>kebbie</code> package.</p> <p><code>kebbie</code> is a small framework for testing and benchmarking mobile keyboards. The primary goal of this package is to establish a cohesive and standardized method for evaluating the various NLP capabilities of a mobile keyboard and comparing them to existing alternatives.</p> <p>This is achieved through two features offered by <code>kebbie</code> :</p> <ul> <li>An easy-to-use evaluation function that facilitates the testing of multiple NLP functionalities offered by a mobile keyboard : auto-correction, auto-completion, next-word prediction, and swipe gesture recognition.</li> <li>A command-line interface for running the evaluation on established keyboards, operated within emulator.</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#latest-version","title":"Latest version","text":"<p>You can install the latest version of the package directly from PyPi with :</p> <pre><code>pip install kebbie\n</code></pre> <p>Hint</p> <p>If you want to install directly from Github, run : <pre><code>pip install git+https://github.com/FleksySDK/kebbie.git\n</code></pre></p>"},{"location":"#specific-version","title":"Specific version","text":"<p>You can install a specific version of the package (<code>0.1.0</code> in ths example) from PyPi with :</p> <pre><code>pip install kebbie==0.1.0\n</code></pre> <p>Hint</p> <p>If you want to install directly from Github, run : <pre><code>pip install git+https://github.com/FleksySDK/kebbie.git@v0.1.0\n</code></pre></p>"},{"location":"#local","title":"Local","text":"<p>You can also clone the repository locally and install it manually :</p> <pre><code>git clone https://github.com/FleksySDK/kebbie.git\ncd kebbie\npip install -e .\n</code></pre>"},{"location":"#extra-dependencies","title":"Extra dependencies","text":"<p>You can also install extras dependencies, for example :</p> <pre><code>pip install -e .[docs]\n</code></pre> <p>Will install necessary dependencies for building the docs.</p> <p>Hint</p> <p>If you installed the package directly from github, run : <pre><code>pip install \"kebbie[docs] @ git+https://github.com/FleksySDK/kebbie.git\"\n</code></pre></p> <p>List of extra dependencies :</p> <ul> <li><code>test</code> : Dependencies for running unit-tests.</li> <li><code>hook</code> : Dependencies for running pre-commit hooks.</li> <li><code>lint</code> : Dependencies for running linters and formatters.</li> <li><code>docs</code> : Dependencies for building the documentation.</li> <li><code>dev</code> : <code>test</code> + <code>hook</code> + <code>lint</code> + <code>docs</code>.</li> <li><code>all</code> : All extra dependencies.</li> </ul>"},{"location":"#contribute","title":"Contribute","text":"<p>To contribute, install the package locally (see Installation), create your own branch, add your code (and tests, and documentation), and open a PR !</p>"},{"location":"#pre-commit-hooks","title":"Pre-commit hooks","text":"<p>Pre-commit hooks are set to check the code added whenever you commit something.</p> <p>When you try to commit your code, hooks are automatically run, and if you code does not meet the quality required by linters, it will not be committed. You then have to fix your code and try to commit again !</p> <p>Important</p> <p>If you never ran the hooks before, install it with : <pre><code>pip install -e .[hook]\npre-commit install\n</code></pre></p> <p>Info</p> <p>You can manually run the pre-commit hooks with : <pre><code>pre-commit run --all-files\n</code></pre></p>"},{"location":"#unit-tests","title":"Unit-tests","text":"<p>When you contribute, you need to make sure all the unit-tests pass. You should also add tests if necessary !</p> <p>Info</p> <p>Install the dependencies for testing with : <pre><code>pip install -e .[test]\n</code></pre></p> <p>You can run the tests with :</p> <pre><code>pytest\n</code></pre> <p>Info</p> <p>Tests are not included in the pre-commit hooks, because running the tests might be slow, and for the sake of developers we want the pre-commit hooks to be fast !</p> <p>Info</p> <p>Pre-commit hooks will not run the tests, but it will automatically update the coverage badge !</p>"},{"location":"#documentation","title":"Documentation","text":"<p>When you contribute, make sure to keep the documentation up-to-date.</p> <p>You can visualize the documentation locally by running :</p> <pre><code>mkdocs serve\n</code></pre> <p>Info</p> <p>Before running this command, you need to install the documentation dependencies : <pre><code>pip install -e .[docs]\n</code></pre></p>"},{"location":"architecture/","title":"Architecture","text":"<p>This page presents the internals and design decisions of the <code>kebbie</code> package.</p>"},{"location":"architecture/#the-oracle","title":"The Oracle","text":"<p>The Oracle is the main class of the package.</p> <p></p> <p>It's the class that takes care of iterating the dataset, introducing the artifical typos, and calling the given Corrector with the noisy text. Then it scores the results, knowing what was the expected text, and return the aggregated metrics as a result.</p> <p>Performances</p> <p>The task is embarassingly parallel. Each sentence can be tested separately. The Oracle leverages multiprocessing to ensure we run the tests as fast as possible.</p> <p>Reproducibility</p> <p>Although The Oracle runs in parallel, the evaluation is entirely reproducible and deterministic. Running twice the same evaluation (with the same Corrector and the same parameters) should give you the exact same results.</p> <p>If you follow the flow of the data, this is what it looks like :</p> <p></p>"},{"location":"architecture/#the-noise-model","title":"The Noise Model","text":"<p>The NoiseModel is the class responsible for introducing artificial typos in a clean text.</p> <p>This is done in two steps :</p> <ul> <li>From a clean word, create a noisy equivalent, which corresponds to a \"cognitive\" typo (i.e. the user might not know the exact spelling of the word)</li> <li>Then from this noisy word, we type each character one by one in a fuzzy way (might type the character next to the intended character), which corresponds to a \"physical\" typo (i.e. fat finger syndrome)</li> </ul> <p></p> <p>Info</p> <p>The keystrokes are generated by using two Gaussian distributions (over the X-axis and the Y-axis), centered on the middle of the intended key.</p> <p>In the end, the output is a noisy version of the word, alongside with the corresponding keystrokes coordinates.</p>"},{"location":"emu_setup/","title":"Emulator setup","text":""},{"location":"emu_setup/#installing-appium-20","title":"Installing Appium 2.0","text":"<p>Appium is required to communicate between Python and the emulators.</p> <p>Install Appium 2.0 by following their official documentation.</p> <p>Then install the required drivers :</p> <pre><code># For Android\nappium driver install uiautomator2\n\n# For iOS\nappium driver install xcuitest\n</code></pre> <p>To start Appium, open a new terminal and type :</p> <pre><code>appium\n</code></pre> <p>Note</p> <p>Once it's running, don't close the terminal. Appium needs to run in order for Python to communicate with the emulators.</p>"},{"location":"emu_setup/#setting-up-android-emulator","title":"Setting up Android emulator","text":""},{"location":"emu_setup/#creating-the-emulator","title":"Creating the emulator","text":"<ul> <li>Install Android Studio</li> <li>Create a new virtual device </li> <li>Select the phone (<code>Pixel 2</code> for example) and the system image (<code>Tiramisu - Android 13.0</code> for example)</li> </ul>"},{"location":"emu_setup/#starting-the-emulator","title":"Starting the emulator","text":"<p>Once you have created the emulator, you should be able to see its name from the command line :</p> <pre><code>emulator -list-avds\n</code></pre> If you encounter <code>command not found: emulator</code> <p>If the command fails with <code>command not found: emulator</code>, you need to update your path accordingly :</p> <pre><code>export ANDROID_HOME=/Users/&lt;username&gt;/Library/Android/sdk\nexport PATH=$ANDROID_HOME/platform-tools:$ANDROID_HOME/emulator:$PATH\n</code></pre> <p>You can start the emulator directly from the command line with : (so you don't need to run Android Studio, which takes a lot of resources)</p> <pre><code>emulator -avd &lt;name&gt; -no-snapshot-load\n</code></pre> <p>Once started, make sure you can see it. From another terminal, run :</p> <pre><code>adb devices\n</code></pre> If you encounter <code>command not found: adb</code> <p>If the command fails with <code>command not found: adb</code>, you need to update your path accordingly :</p> <pre><code>export ANDROID_HOME=/Users/&lt;username&gt;/Library/Android/sdk\nexport PATH=$ANDROID_HOME/platform-tools:$ANDROID_HOME/emulator:$PATH\n</code></pre> <p>Info</p> <p>In Android, to open the keyboard, we access a notepad website (www.justnotepad.com).</p> <p>The reason we do that is because it's the easiest way to access a typing field, and it works across versions and emulators.</p>"},{"location":"emu_setup/#preparing-gboard","title":"Preparing GBoard","text":"<p>GBoard is enabled by default on Android, so there is nothing to do.</p> <p>Tip</p> <p>You can make sure GBoard is indeed the selected keyboard by going to the <code>Settings</code> -&gt; <code>System</code> -&gt; <code>Languages &amp; Input</code> -&gt; <code>On-screen keyboard</code>.</p> <p>By default, GBoard has the clipboard enabled, and it may interfere with the layout detection. You can disable the clipboard in the settings of GBoard :</p> <p></p> <p></p> <p>Make sure to disable the clipboard :</p> <p></p> <p>Layout</p> <p>For now, the only layout supported is <code>english US</code>. Make sure this is the layout GBoard is using.</p>"},{"location":"emu_setup/#preparing-swiftkey","title":"Preparing Swiftkey","text":"<p>Swiftkey keyboard isn't installed on the emulator by default : you need to install it first.</p> <p>Note</p> <p>If you want to run the tests in parallel on several emulators, you need to repeat these steps for each emulator.</p> <p>Start the emulator, then go to Google, and paste this link to install Swiftkey.</p> <p>Tip</p> <p>If the clipboard isn't shared with the emulator, open a terminal and run :</p> <pre><code>adb shell input text \"https://play.google.com/store/apps/details?id=com.touchtype.swiftkey&amp;hl=en_US&amp;gl=US\"\n</code></pre> <p>Install the keyboard on your emulator :</p> <p></p> <p>Open the app, follow the instructions to activate the keyboard.</p> <p>By default, Swiftkey has the clipboard enabled, and it may interfere with the layout detection. You can disable the clipboard. First, access the clipboard settings :</p> <p></p> <p></p> <p>And disable the clipboard suggestions :</p> <p></p>"},{"location":"emu_setup/#setting-up-ios-emulator","title":"Setting up iOS emulator","text":""},{"location":"emu_setup/#creating-the-emulator_1","title":"Creating the emulator","text":"<ul> <li>Install XCode</li> <li>Open WebDriverAgent in Xcode : <pre><code>open ~/.appium/node_modules/appium-xcuitest-driver/node_modules/appium-webdriveragent/WebDriverAgent.xcodeproj\n</code></pre></li> <li>Go to <code>Signing &amp; Capabilities</code> of the project :</li> </ul> <ul> <li>Then click \"Team\" and select your Apple ID</li> <li>You should do this for the three following targets : <code>WebDriverAgentLib</code>, <code>WebDriverAgentRunner</code>, <code>IntegrationApp</code>.</li> </ul> <p>Now, make sure you can properly build the <code>WebDriverAgentRunner</code> target : select it in the top bar and run it (button \"play\") :</p> <p></p> <p>If all the stars are aligned, it should start the emulator !</p>"},{"location":"emu_setup/#starting-the-emulator_1","title":"Starting the emulator","text":"<p>Once you have ensured the emulator runs properly, you should be able to start it from the command line (without Xcode open).</p> <p>First, check the list of emulators available :</p> <pre><code>xcrun simctl list\n</code></pre> <p>Example of emulators listed :</p> <pre><code>-- iOS 17.4 --\n    iPhone SE (3rd generation) (96ADAD77-ECE6-420E-B56C-505E0C16231B) (Shutdown)\n    iPhone 15 (128F95FC-F499-4B09-A3B2-55937BF52B0B) (Shutdown)\n    iPhone 15 Plus (86591FC6-B3E7-43A2-9E9B-D4A2A90DAF31) (Shutdown)\n    iPhone 15 Pro (9D38F87D-273B-4D8F-8AD5-E901C1974C1E) (Shutdown)\n    iPhone 15 Pro Max (15EF57B4-69E6-4369-9534-70692A2023E5) (Shutdown)\n    iPad Air (5th generation) (252D522B-CEAA-4085-BE17-A453BC219755) (Shutdown)\n    iPad (10th generation) (39F2ADD2-2FCF-44C3-9DC9-4CC4D50875E9) (Shutdown)\n    iPad mini (6th generation) (59125B84-4ED1-40C1-8457-3CE824394385) (Shutdown)\n    iPad Pro (11-inch) (4th generation) (DB122D71-F358-48DA-B11C-D25305657E7F) (Shutdown)\n    iPad Pro (12.9-inch) (6th generation) (1100927A-B631-4678-AB19-02EA4F680537) (Shutdown)\n</code></pre> <p>Then you can start the device you want with :</p> <pre><code>xcrun simctl boot &lt;UUID&gt;\n</code></pre> <p>For example, to start <code>iPhone 15 Pro</code>, you should run :</p> <pre><code>xcrun simctl boot 9D38F87D-273B-4D8F-8AD5-E901C1974C1E\n</code></pre> <p>Warning</p> <p>The <code>xcrun simctl boot</code> command only launch the simulator background service, to launch the foreground GUI, run :</p> <pre><code>open -a Simulator\n</code></pre> <p>Note</p> <p>To shutdown the simulator, run :</p> <pre><code>xcrun simctl shutdown &lt;UUID&gt;\n</code></pre>"},{"location":"emu_setup/#preparing-ios-keyboard","title":"Preparing iOS Keyboard","text":"<p>iOS Keyboard is the default keyboard on iOS, so there is nothing to do to enable it.</p> <p>However, predictions and auto-corrections are disabled by default. They should be enabled :</p> <ul> <li>Go to \"Settings\" :</li> </ul> <p></p> <ul> <li>Then go to \"General\" :</li> </ul> <p></p> <ul> <li>Then go to \"Keyboard\" :</li> </ul> <p></p> <ul> <li>Then enable \"Auto-Correction\" and \"Predictive Text\" :</li> </ul> <p></p> <p>Also, inline predictions are enabled by default, and it may interfere with <code>kebbie</code>. Make sure to turn it off (also in the keyboard settings) :</p> <p></p> <p>Layout</p> <p>For now, the only layout supported is <code>english US</code>. Make sure this is the layout iOS keyboard is using.</p>"},{"location":"emu_setup/#preparing-fleksy-keyboard","title":"Preparing Fleksy keyboard","text":"<p>Fleksy is a fully-featured keyboard SDK. A demo keyboard is provided, allowing anyone to test its performance.</p> <p>You first need to install the keyboard in your simulator. To do this, start your simulator (see Starting the emulator), and then run :</p> <pre><code>wget https://github.com/FleksySDK/kebbie/files/15290354/Fleksy.zip\nunzip Fleksy.zip\nxcrun simctl install &lt;UUID&gt; Fleksy.app\n</code></pre> <p>Tip</p> <p>You can find the UUID of your simulator by running : <code>xcrun simctl list</code> and finding which one is <code>Booted</code>.</p> <p>Once the app is installed, start it :</p> <p></p> <p>Click \"Add Keyboard\" :</p> <p></p> <p>Then go to \"General\" :</p> <p></p> <p>Then go to \"Keyboard\" :</p> <p></p> <p>Then go to \"Keyboards\" :</p> <p></p> <p>Then click \"Add New Keyboard\" :</p> <p></p> <p>And select \"Fleksy For Research\" :</p> <p></p> <p>Then select the Fleksy keyboard you just installed :</p> <p></p> <p>And enable \"Full Access\" :</p> <p></p> <p>Once enabled, you still need to select the right keyboard ! Open the keyboard using any text field, and hold the switch keyboard key. You can then select the keyboard you want to test :</p> <p></p> <p>And similarly to the default iOS keyboard, you should enable predictions and auto-corrections :</p> <ul> <li>Go to \"Settings\" :</li> </ul> <p></p> <ul> <li>Then go to \"General\" :</li> </ul> <p></p> <ul> <li>Then go to \"Keyboard\" :</li> </ul> <p></p> <ul> <li>Then enable \"Auto-Correction\" and \"Predictive Text\" :</li> </ul> <p></p>"},{"location":"emu_setup/#preparing-keyboardkit","title":"Preparing KeyboardKit","text":"<p>KeyboardKit is an open-source SDK that lets you create a custom keyboard. They provide a demo keyboard that we can use to test its performance.</p> <p>Before being able to run <code>kebbie evaluate</code> to benchmark KeyboardKit, you need to install the demo keyboard on your simulator.</p> <p>First, clone the repository and open the project in Xcode :</p> <pre><code>git clone https://github.com/KeyboardKit/KeyboardKit.git\ncd KeyboardKit\nopen Demo/Demo.xcodeproj\n</code></pre> <p>Then, from Xcode, select the <code>Demo</code> project, select the right simulator, and press the play button :</p> <p></p> <p>It should start the simulator, with KeyboardKit installed.</p> <p>Once the simulator started, you need to enable the KeyboardKit keyboard and allow full access :</p> <p></p> <p></p> <p></p> <p>Once enabled, you still need to select the right keyboard ! Open the keyboard using any text field, and hold the switch keyboard key. You can then select the keyboard you want to test :</p> <p></p> <p>And similarly to the default iOS keyboard, you should enable predictions and auto-corrections :</p> <ul> <li>Go to \"Settings\" :</li> </ul> <p></p> <ul> <li>Then go to \"General\" :</li> </ul> <p></p> <ul> <li>Then go to \"Keyboard\" :</li> </ul> <p></p> <ul> <li>Then enable \"Auto-Correction\" and \"Predictive Text\" :</li> </ul> <p></p>"},{"location":"emu_setup/#parallel-emulators","title":"Parallel emulators","text":"<p>In order to run tests faster, we can setup multiple emulators, and run the evaluate() function in parallel. Let's see how to set up multiple emulators for both Android and iOS.</p>"},{"location":"emu_setup/#android","title":"Android","text":"<p>First, follow the section above to setup one Android emulator.</p> <p>Once it's done, you can simply clone it from Android Studio :</p> <p></p> <p>Clone it several times. Once the emulators are created, you should be able to list them from the command line :</p> <pre><code>emulator -list-avds\n</code></pre> <p>Then open several terminal, and in each terminal open one emulator :</p> <pre><code>emulator -avd &lt;name&gt; -no-snapshot-load\n</code></pre> <p>After they started, you should be able to see them with :</p> <pre><code>adb devices\n</code></pre> <p>Tip</p> <p>Once you can see the emulators with the <code>adb devices</code> command, there is nothing else to do ! You can run the <code>kebbie</code> CLI just like you would do for a single emulator : the CLI will detect the running emulators with the <code>adb devices</code> command.</p>"},{"location":"emu_setup/#ios","title":"iOS","text":"<p>First, follow the section above to setup one iOS simulator and make sure everything works for a single device.</p> <p>Once it's done, you can list the device availables :</p> <pre><code>xcrun simctl list\n</code></pre> <p>Example of emulators listed :</p> <pre><code>-- iOS 17.4 --\n    iPhone SE (3rd generation) (96ADAD77-ECE6-420E-B56C-505E0C16231B) (Shutdown)\n    iPhone 15 (128F95FC-F499-4B09-A3B2-55937BF52B0B) (Shutdown)\n    iPhone 15 Plus (86591FC6-B3E7-43A2-9E9B-D4A2A90DAF31) (Shutdown)\n    iPhone 15 Pro (9D38F87D-273B-4D8F-8AD5-E901C1974C1E) (Shutdown)\n    iPhone 15 Pro Max (15EF57B4-69E6-4369-9534-70692A2023E5) (Shutdown)\n    iPad Air (5th generation) (252D522B-CEAA-4085-BE17-A453BC219755) (Shutdown)\n    iPad (10th generation) (39F2ADD2-2FCF-44C3-9DC9-4CC4D50875E9) (Shutdown)\n    iPad mini (6th generation) (59125B84-4ED1-40C1-8457-3CE824394385) (Shutdown)\n    iPad Pro (11-inch) (4th generation) (DB122D71-F358-48DA-B11C-D25305657E7F) (Shutdown)\n    iPad Pro (12.9-inch) (6th generation) (1100927A-B631-4678-AB19-02EA4F680537) (Shutdown)\n</code></pre> <p>Select the UUID of the device you would like to run in parallel, and clone it with :</p> <pre><code>xcrun simctl clone &lt;UUID&gt; &lt;new_name&gt;\n</code></pre> <p>So for example, to have 4 parallel <code>iPhone 15 Pro</code>, you should run :</p> <pre><code>xcrun simctl clone 9D38F87D-273B-4D8F-8AD5-E901C1974C1E iPhone_15_2\nxcrun simctl clone 9D38F87D-273B-4D8F-8AD5-E901C1974C1E iPhone_15_3\nxcrun simctl clone 9D38F87D-273B-4D8F-8AD5-E901C1974C1E iPhone_15_4\n</code></pre> <p>Once this is done, you should see them listed when running :</p> <pre><code>xcrun simctl list\n</code></pre> <pre><code>-- iOS 17.4 --\n    iPhone SE (3rd generation) (96ADAD77-ECE6-420E-B56C-505E0C16231B) (Shutdown)\n    iPhone 15 (128F95FC-F499-4B09-A3B2-55937BF52B0B) (Shutdown)\n    iPhone 15 Plus (86591FC6-B3E7-43A2-9E9B-D4A2A90DAF31) (Shutdown)\n    iPhone 15 Pro (9D38F87D-273B-4D8F-8AD5-E901C1974C1E) (Booted)\n    iPhone_15_2 (C423F3BC-BC3A-4FFC-B264-C6075B60115F) (Shutdown)\n    iPhone_15_3 (2BEB33D0-8F33-4987-95FC-FD9B7C2BD54D) (Shutdown)\n    iPhone_15_4 (EE0719E9-FF3C-4539-9BCD-9F091B469F93) (Shutdown)\n    iPhone 15 Pro Max (15EF57B4-69E6-4369-9534-70692A2023E5) (Shutdown)\n    iPad Air (5th generation) (252D522B-CEAA-4085-BE17-A453BC219755) (Shutdown)\n    iPad (10th generation) (39F2ADD2-2FCF-44C3-9DC9-4CC4D50875E9) (Shutdown)\n    iPad mini (6th generation) (59125B84-4ED1-40C1-8457-3CE824394385) (Shutdown)\n    iPad Pro (11-inch) (4th generation) (DB122D71-F358-48DA-B11C-D25305657E7F) (Shutdown)\n    iPad Pro (12.9-inch) (6th generation) (1100927A-B631-4678-AB19-02EA4F680537) (Shutdown)\n</code></pre> <p>Then you can start each simulator with :</p> <pre><code>xcrun simctl boot &lt;UUID&gt;\n</code></pre> <p>For example, to start the 4 simulators we just created, you would run :</p> <pre><code>xcrun simctl boot 9D38F87D-273B-4D8F-8AD5-E901C1974C1E\nxcrun simctl boot C423F3BC-BC3A-4FFC-B264-C6075B60115F\nxcrun simctl boot 2BEB33D0-8F33-4987-95FC-FD9B7C2BD54D\nxcrun simctl boot EE0719E9-FF3C-4539-9BCD-9F091B469F93\n</code></pre> <p>Tip</p> <p>Once the simulators started, there is nothing else to do ! You can run the <code>kebbie</code> CLI just like you would do for a single emulator : the CLI will automatically detect the running emulators with the <code>xcrun simctl list</code> command.</p> <p>However, make sure to enable auto-correction and predictive suggestions in each of the simulator (see Preparing the iOS Keyboard for more information)</p> <p>Warning</p> <p>The <code>xcrun simctl boot</code> command only launch the simulator background service, to launch the foreground GUI, run :</p> <pre><code>open -a Simulator\n</code></pre> <p>Note</p> <p>To shutdown a simulator, run :</p> <pre><code>xcrun simctl shutdown &lt;UUID&gt;\n</code></pre>"},{"location":"emulated_keyboard/","title":"Emulated keyboards","text":"<p>In Usage, we saw how to use the <code>kebbie</code> framework to test our code and get various metrics to understand how good our custom auto-correction was.</p> <p>Now, let's see how to use the <code>kebbie</code> CLI to run similar tests on an existing keyboard (within an emulator) such as GBoard.</p>"},{"location":"emulated_keyboard/#setup","title":"Setup","text":"<p>First, you need to install and setup Appium and the emulators.</p> <p>Follow the intructions in Emulator setup.</p> <p>Once everything you need is installed, you should have the following running :</p> <ul> <li>Appium in a terminal</li> <li>At least one emulator</li> </ul>"},{"location":"emulated_keyboard/#layout-detection","title":"Layout detection","text":"<p><code>kebbie</code> tries to automatically detect the layout of the keyboard in use. It is working for GBoard or iOS keyboard for example.</p> <p>But some keyboards cannot be detected automatically. In this case we rely on a manual definition of the layout.</p> <p>But these manual definitions of the layout may not fit all devices.</p>"},{"location":"emulated_keyboard/#showing-the-layout","title":"Showing the layout","text":"<p><code>kebbie</code> provides a CLI to check the layout. To visualize the keyboard's layout, run the <code>show_layout</code> command. For example for GBoard :</p> <pre><code>kebbie show_layout -K gboard\n</code></pre> <p>It will display 3 images (one for each layer of the keyboard : <code>lowercase</code>, <code>uppercase</code>, <code>numbers</code>), so you can see if the layout (automatically detected or manually defined) fits the current keyboard. You can leave the images by pressing any key.</p> <p>Info</p> <p>Before leaving, the command will also display in the terminal the detected suggestions of the keyboard. If they don't correspond to what's displayed in the emulator, something might be wrong !</p> <p>For auto-detected keyboards, these suggestions are retrieved directly from the XML tree (fast and accurate). For keyboards with manual layout, we use OCR to find the suggestions (slow and may be wrong).</p> <p>Tip</p> <p>If you have several emulators running, the <code>show_layout</code> command will find and display the layout for each emulator, one by one.</p> <p>Example where the layout match the keys properly :</p> <p></p> <p>Example where the layout doesn't match the keyboard's keys :</p> <p></p> <p>If it doesn't match...</p> <p>You need to modify the definition of the layout (in emulator.py), and experiment with new coordinates until it matches well...</p>"},{"location":"emulated_keyboard/#list-of-supported-keyboards","title":"List of supported keyboards","text":"<p>Here is the list of keyboards for which the layout auto-detection is supported :</p> <ul> <li>GBoard, with the <code>-K gboard</code> argument</li> <li>iOS keyboard, with the <code>-K ios</code> argument</li> <li>KeyboardKit Pro, with the <code>-K kbkitpro</code> argument</li> <li>KeyboardKit Open-source, with the <code>-K kbkitoss</code> argument</li> <li>Tappa keyboard, with the <code>-K tappa</code> argument</li> </ul>"},{"location":"emulated_keyboard/#testing-the-keyboard","title":"Testing the keyboard","text":"<p>After you made sure the layout is properly detected / defined, it's time to run the tests !</p> <p>Simply run :</p> <pre><code># For GBoard on Android emulator\nkebbie evaluate -K gboard --all_tasks\n\n# For iOS keyboard on iOS emulator\nkebbie evaluate -K ios --all_tasks\n</code></pre> <p>After a while, you should see the emulator start typing sentences !</p> <p>The command line will type the sentences from the test data, and record the suggestions and the auto-corrections from the keyboard.</p> <p>Once all sentences are tested, the results will be saved in a file <code>results.json</code>.</p> <p>Info</p> <p>The <code>evaluate</code> CLI will use only 100 sentences of the test data (versus 2 000 by default for the evaluate() function, see Usage).</p> <p>This is because typing on an emulated keyboard is significantly slower. 100 sentences is enough to get some good, comparable metrics.</p> <p>Note that we specified the option <code>--all_tasks</code>. With this option, we are computing the results for all of the tasks supported by the emulator : auto-correction, auto-completion, and next-word prediction.</p> <p>Unsupported</p> <p>For now, swipe gesture recognition is not supported for the emulated keyboards.</p> <p>The default behavior (when <code>--all_tasks</code> is not specified) is to run only the auto-correction task. It is significantly faster, specially for keyboards with a layout defined manually, because they require OCR, which is quite slow.</p> <p>If you want to change the number of sentences the CLI run on, just use the option <code>--n_sentences</code> :</p> <pre><code>kebbie evaluate -K gboard --all_tasks --n_sentences 10\n</code></pre> <p>You can change the destination file for the results with the option <code>--result_file</code> :</p> <pre><code>kebbie evaluate -K gboard --all_tasks --result_file my/folder/evaluation_results.json\n</code></pre> <p>You can track the most common mistakes with the option <code>--track_mistakes</code> :</p> <pre><code>kebbie evaluate -K gboard --all_tasks --track_mistakes\n</code></pre> <p>It will save the most common mistakes in the result file.</p>"},{"location":"how_testing_is_done/","title":"How testing is done ?","text":"<p>The basic idea is simple : we take a dataset of english sentences, we corrupt these sentences by introducing artificially generated typos, and then we measure how these typos are corrected.</p>"},{"location":"how_testing_is_done/#artificial-typos","title":"Artificial typos","text":"<p>To introduce typos in the clean text, we simulate all possible typos that a human typing on a mobile keyboard could do. This include :</p> <ul> <li>Characters additions / deletions</li> <li>Characters transpositions</li> <li>Accent simplifications</li> <li>Case simplifications</li> <li>Fat-finger syndrome (fuzzy typing)</li> <li>Common typos (sampled from a dataset of most common typos)</li> </ul> <p>We use the following typo rates :</p> <ul> <li>Character transpositions : 1% of all characters</li> <li>Character additions : 0.5% of all characters</li> <li>Character deletions : 0.5% of all characters</li> <li>Space deletions : 1% of all space characters</li> <li>Symbol deletions : 10% of symbol characters</li> <li>Accent simplification : 8% of accented characters</li> <li>Case simplification : 8% of uppercased characters</li> <li>Common typos : 5% of words</li> </ul> <p>With these rates, we obtain an overall typo rate of 12%.</p> <p>Sources</p> <p>These rates come from studies on real-human typing habits : Reference #1, Reference #2.</p> <p>Particularly, Reference #1 (which focus on mobile device typing) shows that typing on mobile devices leads to 2.3% of uncorrected errors (see introduction), and 8% of words autocorrected (see Intelligent text entry, page 8), for an overall typo rate of 10.3%.</p> Details <p>Additionally to these typo rates, we further modify the probabilities :</p> <ul> <li>FRONT_DELETION_MULTIPLIER is used to reduce the probability of a deletion happening on the first character of the word. This number was computed after analyzing the Tweeter typo corpus (see this script)</li> </ul> <p>Here is a few examples of sentences before and after introducing typos :</p> Clean sentence Corrupted sentence Typos introduced He went hiking and said he'd think about it; never came back. He went hikimg and said hed think about it; never came back. Fuzzy typing &amp; Symbol deletion Like, what you're doing here and what all this stuff is. Like, what you're doinghere and waht all this stuff is. Space deletion &amp; Character transposition You must do something about yourself. You must do something about yourself. That's the way to get rid of pests like that. That's the waj to get rid of pedts like thhat. Common typo &amp; Fuzzy typing &amp; Character addition He obviously wanted an ally. he obviously wanted an ally. Case simplification This is all we got between us and the Almighty! This is lal we got beween us and the Almgihty! 2 x Character transposition &amp; Character deletion"},{"location":"how_testing_is_done/#swipe-gesture-generation","title":"Swipe gesture generation","text":"<p>For the task of swipe gesture resolution, the input is not simple text : we need to generate a swipe gesture.</p> <p>When generating fuzzy typing typo, we sample key taps positions on the keyboard, using Gaussian distributions, and use these key taps position to see if the correct character was typed, or if a neighbor key was typed.</p> <p>For generating the swipe gesture, we sample some key taps positions just like we do for fuzzy typing, and then link the different keystrokes of the word using bezier curves. Some randomness on the speed &amp; acceleration between points is added, in order to generate more natural swipe gestures.</p> <p>Here is some examples of the generated swipe gestures (in red are the keystrokes generated by the fuzzy typing, in blue the points of the corresponding swipe gesture created).</p> <p>For the word <code>gives</code> :</p> <p></p> <p></p> <p></p> <p>For the word <code>they</code> :</p> <p></p> <p></p> <p></p>"},{"location":"how_testing_is_done/#data","title":"Data","text":""},{"location":"how_testing_is_done/#test-data","title":"Test data","text":"<p>For the data, we use the test set of the SODA dataset.</p> <p>We chose to use this dataset for the evaluation for several reasons :</p> <ul> <li>Recent</li> <li>Extremely clean dataset</li> <li>Cover two very distinct domains (<code>narrative</code> &amp; <code>dialogue</code>)</li> </ul>"},{"location":"how_testing_is_done/#common-typos-dataset","title":"Common typos dataset","text":"<p>As mentioned in the section Artificial typos, we rely on a dataset of common typos, and use these common typos when generating plausible typos.</p> <p>The dataset of common typos that we use is the Twitter Typo Corpus.</p>"},{"location":"how_testing_is_done/#tasks","title":"Tasks","text":"<p>We test the most important NLP features of a mobile keyboards. These are :</p> <ul> <li>Auto-correction: Corrects the words typed by the user. For example, if a user types <code>I\u2019m especialy touched</code>, the typo should be detected and corrected to <code>I\u2019m especially touched</code>.</li> <li>Auto-completion: Completes the word typed by the user. For example, if a user types <code>I love y</code>, the word should be auto-completed to <code>I love you</code>.</li> <li>Next-word prediction: Predicts the next word to be typed. For example, if a user types <code>I want to eat french</code>, a probable next word can be <code>fries</code>.</li> <li>Swipe gesture resolution: Predicts the intended word from a swipe gesture.</li> </ul>"},{"location":"how_testing_is_done/#metrics","title":"Metrics","text":"<p>If you look into the results from <code>kebbie</code>, for each task we have a handful of metrics that help us understand how good the tested keyboard is. Let's look at the details of these metrics.</p>"},{"location":"how_testing_is_done/#formulas","title":"Formulas","text":""},{"location":"how_testing_is_done/#next-word-prediction-swipe-resolution-auto-completion","title":"Next-word prediction, swipe resolution, auto-completion","text":"<p>For these three tasks, the metric used is Accuracy.</p> <p>The formula is : <code>accuracy = correct / total</code></p> <p>Where <code>correct</code> is the number of correct predictions, and <code>total</code> the total number of predictions.</p> <p>For the next-word prediction task and auto-completion task, we use top-3 accuracy as the main reference metric. It\u2019s the same as accuracy, but instead of considering only one candidate (which is either correct or not), we consider the 3 most probable candidates (if any one of these 3 candidates is correct).</p> <p>The reason for this is because the next-word predictions and auto-completion predictions are not \u201cforced\u201d upon the user : 3 predictions are displayed at the top of the keyboard, and the user can choose any of the prediction displayed. So the correct prediction should appear among these 3 predictions displayed.</p> <p>For swipe resolution however, only the best prediction is selected and applied. So we use accuracy as the main reference metric (and not top-3 accuracy).</p>"},{"location":"how_testing_is_done/#auto-correction","title":"Auto-correction","text":"<p>For auto-correction, it\u2019s different. We have a notion of true/false positive/negative. Let\u2019s first define these notions :</p> <ul> <li>True Negative : No typo introduced, the model doesn\u2019t correct anything</li> <li>False Positive : No typo introduced, but the model correct (wrongly) the word</li> <li>True Positive : A typo is introduced, the model correct the word into the expected word</li> <li>False Negative : A typo is introduced, but the model doesn\u2019t correct anything</li> </ul> <p>With an example it\u2019s easier to visualize :</p> Word typed by the user Word after being corrected by the model Expected word True Negative love love love False Positive love loev love True Positive loev love love False Negative loev loev love <p>From these notions, we can compute the following metrics : accuracy, precision, recall, F-score, using the following formulas :</p> <p><code>accuracy = (tp + tn) / (tp + tn + fp + fn)</code></p> <p><code>precision = tp / (tp + fp)</code></p> <p><code>recall = tp / (tp + fn)</code></p> <p><code>f_score = 2 * (precision * recall) / (precision + recall)</code></p> <p>Note</p> <p>F-score is the harmonic mean of precision and recall. It\u2019s a way to gather both precision and recall in a single metric.</p> <p>Important</p> <p>Actually we use F\u03b2-score, which is a variant of the F-score where we can use a constant \u03b2 to weight the precision/recall ratio (see the wikipedia page about F-score).</p> <p>This is useful because we value precision more.</p> <p>We currently use \u03b2 = 0.9, which means precision has slightly more weight than recall.</p>"},{"location":"how_testing_is_done/#understanding-the-metrics","title":"Understanding the metrics","text":""},{"location":"how_testing_is_done/#swipe-resolution","title":"Swipe resolution","text":"<p><code>Accuracy</code> - <code>[0 - 1]</code> - <code>higher is better</code></p> <p>Accuracy is straightforward : this is the ratio of correct predictions.</p> <p>So an accuracy of <code>0.8</code> means the model correctly predicted the word being swiped 80% of the time.</p>"},{"location":"how_testing_is_done/#next-word-prediction-auto-completion","title":"Next-word prediction &amp; auto-completion","text":"<p><code>Top-3 accuracy</code> - <code>[0 - 1]</code> - <code>higher is better</code></p> <p>Same as accuracy, but 3 candidates are considered.</p> <p>So a top-3 accuracy of <code>0.6</code> means that within the 3 candidates predicted by the model, the next word (or the word completion) is in these 3 candidates 60% of the time.</p>"},{"location":"how_testing_is_done/#auto-correction_1","title":"Auto-correction","text":"<p><code>Precision</code> - <code>[0 - 1]</code> - <code>higher is better</code></p> <p>Precision is the ratio of typos among what is corrected by the model.</p> <p>So a precision of <code>0.7</code> means that among all corrections made by the model, 70% were actually typos (and 30% were correct words that didn\u2019t need to be corrected).</p> <p>A low precision means many words are corrected when they should not, and a high precision means only actual typos are corrected.</p> <p><code>Recall</code> - <code>[0 - 1]</code> - <code>higher is better</code></p> <p>Recall is the ratio of typos detected by the model.</p> <p>So a recall of <code>0.65</code> means that the model correctly detected 65% of typos (and 35% of typos were not corrected by the model).</p> <p>A low recall is symptom that most typos are not detected, and a high recall means most of typos are detected as typos.</p> <p><code>F-score</code> - <code>[0 - 1]</code> - <code>higher is better</code></p> <p>F-score is the harmonic mean of precision and recall, it\u2019s just a way to gather both precision and recall in a single metric.</p> <p>Note that we weight precision slightly more than recall.</p>"},{"location":"internals/","title":"Internals","text":""},{"location":"internals/#cmdpy","title":"<code>cmd.py</code>","text":"<p>Module containing the implementation for the <code>kebbie</code> command line.</p>"},{"location":"internals/#kebbie.cmd.instantiate_correctors","title":"<code>instantiate_correctors(keyboard, fast_mode=True, instantiate_emulator=True)</code>","text":"<p>Create the right correctors (with the right platform, etc...) given the arguments from the command line.</p> <p>Parameters:</p> Name Type Description Default <code>keyboard</code> <code>str</code> <p>Name fo the keyboard to load.</p> required <code>fast_mode</code> <code>bool</code> <p>If <code>True</code>, the corrector will be instantiated in fast mode (only AC).</p> <code>True</code> <code>instantiate_emulator</code> <code>bool</code> <p>If <code>True</code>, the emulators are instantiated (which trigger the layout detection). If <code>False</code>, only the corrector is instantiated, not the emulator.</p> <code>True</code> <p>Returns:</p> Type Description <code>List[EmulatorCorrector]</code> <p>The list of created Correctors.</p> Source code in <code>kebbie/cmd.py</code> <pre><code>def instantiate_correctors(\n    keyboard: str, fast_mode: bool = True, instantiate_emulator: bool = True\n) -&gt; List[EmulatorCorrector]:\n    \"\"\"Create the right correctors (with the right platform, etc...) given the\n    arguments from the command line.\n\n    Args:\n        keyboard (str): Name fo the keyboard to load.\n        fast_mode (bool, optional): If `True`, the corrector will be\n            instantiated in fast mode (only AC).\n        instantiate_emulator (bool, optional): If `True`, the emulators are\n            instantiated (which trigger the layout detection). If `False`, only\n            the corrector is instantiated, not the emulator.\n\n    Returns:\n        The list of created Correctors.\n    \"\"\"\n    if keyboard in [\"gboard\", \"tappa\", \"swiftkey\"]:\n        # Android keyboards\n        return [\n            EmulatorCorrector(\n                device=d,\n                platform=\"android\",\n                keyboard=keyboard,\n                fast_mode=fast_mode,\n                instantiate_emulator=instantiate_emulator,\n            )\n            for d in Emulator.get_android_devices()\n        ]\n    else:\n        # iOS keyboards\n        return [\n            EmulatorCorrector(\n                device=i,\n                platform=\"ios\",\n                keyboard=keyboard,\n                fast_mode=fast_mode,\n                instantiate_emulator=instantiate_emulator,\n                ios_name=ios_name,\n                ios_platform=ios_platform,\n            )\n            for i, (ios_platform, ios_name) in enumerate(Emulator.get_ios_devices())\n        ]\n</code></pre>"},{"location":"internals/#kebbie.cmd.common_args","title":"<code>common_args(parser)</code>","text":"<p>Add common arguments to the given parser.</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>ArgumentParser</code> <p>Parser where to add the arguments.</p> required Source code in <code>kebbie/cmd.py</code> <pre><code>def common_args(parser: argparse.ArgumentParser):\n    \"\"\"Add common arguments to the given parser.\n\n    Args:\n        parser (argparse.ArgumentParser): Parser where to add the arguments.\n    \"\"\"\n    parser.add_argument(\n        \"--keyboard\",\n        \"-K\",\n        dest=\"keyboard\",\n        type=str,\n        required=True,\n        choices=[\"gboard\", \"ios\", \"kbkitpro\", \"kbkitoss\", \"tappa\", \"fleksy\", \"swiftkey\"],\n        help=\"Which keyboard, to be tested, is currently installed on the emulator.\",\n    )\n</code></pre>"},{"location":"internals/#kebbie.cmd.cli","title":"<code>cli()</code>","text":"<p>Entry-point of the <code>kebbie</code> command line.</p> Source code in <code>kebbie/cmd.py</code> <pre><code>def cli():\n    \"\"\"Entry-point of the `kebbie` command line.\"\"\"\n    # create the top-level parser\n    parser = argparse.ArgumentParser(description=\"Kebbie's command line.\")\n    subparsers = parser.add_subparsers(title=\"commands\", dest=\"cmd\")\n\n    evaluate_parser = subparsers.add_parser(\"evaluate\", help=\"Run the evaluation using emulated keyboard.\")\n    evaluate_parser.set_defaults(cmd=\"evaluate\")\n    common_args(evaluate_parser)\n    evaluate_parser.add_argument(\n        \"--result_file\",\n        \"-R\",\n        dest=\"result_file\",\n        type=str,\n        default=\"results.json\",\n        help=\"When to save the results of the evaluation\",\n    )\n    evaluate_parser.add_argument(\n        \"--all_tasks\",\n        \"-A\",\n        dest=\"all_tasks\",\n        action=\"store_true\",\n        default=False,\n        help=\"If specified, all tasks are evaluated (not only auto-correction, but also auto-completion and \"\n        \"next-word prediction).\",\n    )\n    evaluate_parser.add_argument(\n        \"--n_sentences\",\n        \"-N\",\n        dest=\"n_sentences\",\n        type=int,\n        default=100,\n        help=\"The number of sentences to use for the evaluation. Emulated keyboard are slow, so we can't run on the \"\n        \"full test set. Instead we pick the first N sentences.\",\n    )\n    evaluate_parser.add_argument(\n        \"--track_mistakes\",\n        \"-T\",\n        dest=\"track_mistakes\",\n        action=\"store_true\",\n        default=False,\n        help=\"If specified, mistakes will be tracked and saved in the result file.\",\n    )\n\n    layout_parser = subparsers.add_parser(\n        \"show_layout\", help=\"Display the layout over the keyboard for debugging purpose.\"\n    )\n    layout_parser.set_defaults(cmd=\"show_layout\")\n    common_args(layout_parser)\n\n    args = parser.parse_args()\n\n    if args.cmd is None:\n        parser.print_help(sys.stderr)\n        sys.exit(1)\n    elif args.cmd == \"evaluate\":\n        correctors = instantiate_correctors(args.keyboard, fast_mode=not args.all_tasks, instantiate_emulator=False)\n\n        # Get dataset, and filter it to keep only a small number of sentences\n        dataset = get_soda_dataset(args.n_sentences)\n\n        # Run the evaluation\n        results = evaluate(correctors, dataset=dataset, track_mistakes=args.track_mistakes)\n\n        # Save the results in a file\n        with open(args.result_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(results, f, ensure_ascii=False, indent=4)\n\n        print(\"Overall score : \", results[\"overall_score\"])\n\n    elif args.cmd == \"show_layout\":\n        correctors = instantiate_correctors(args.keyboard)\n        for c in correctors:\n            c.emulator.show_keyboards()\n            print(f\"Predictions : {c.emulator.get_predictions()}\")\n</code></pre>"},{"location":"internals/#correctorspy","title":"<code>correctors.py</code>","text":"<p>Module containing the base Corrector class.</p>"},{"location":"internals/#kebbie.correctors.EmulatorCorrector","title":"<code>EmulatorCorrector</code>","text":"<p>               Bases: <code>Corrector</code></p> <p>Corrector using an emulated keyboard.</p> <p>Parameters:</p> Name Type Description Default <code>platform</code> <code>str</code> <p>Name of the platform used. <code>android</code> or <code>ios</code>.</p> required <code>keyboard</code> <code>str</code> <p>Name of the keyboard to test.</p> required <code>device</code> <code>str</code> <p>Device UDID to use for the emulator.</p> <code>None</code> <code>fast_mode</code> <code>bool</code> <p>If <code>True</code>, only auto-correction will be tested, and suggestions will not be retrieved. This is faster because we don't take screenshot and run the OCR.</p> <code>True</code> <code>instantiate_emulator</code> <code>bool</code> <p>If <code>False</code>, the emulator is not initialized (It will only be initialized after being pickled). This is useful to quickly create instances of this class, without going through the whole layout detection (which takes time) 2 times : at initialization and after being pickled.</p> <code>True</code> Source code in <code>kebbie/correctors.py</code> <pre><code>class EmulatorCorrector(Corrector):\n    \"\"\"Corrector using an emulated keyboard.\n\n    Args:\n        platform (str): Name of the platform used. `android` or `ios`.\n        keyboard (str): Name of the keyboard to test.\n        device (str): Device UDID to use for the emulator.\n        fast_mode (bool): If `True`, only auto-correction will be tested,\n            and suggestions will not be retrieved. This is faster because\n            we don't take screenshot and run the OCR.\n        instantiate_emulator (bool): If `False`, the emulator is not\n            initialized (It will only be initialized after being pickled).\n            This is useful to quickly create instances of this class,\n            without going through the whole layout detection (which takes\n            time) 2 times : at initialization and after being pickled.\n    \"\"\"\n\n    def __init__(\n        self,\n        platform: str,\n        keyboard: str,\n        device: str = None,\n        fast_mode: bool = True,\n        ios_name: str = None,\n        ios_platform: str = None,\n        instantiate_emulator: bool = True,\n    ):\n        super().__init__()\n\n        self.platform = platform\n        self.keyboard = keyboard\n        self.device = device\n        self.fast_mode = fast_mode\n        self.ios_name = ios_name\n        self.ios_platform = ios_platform\n\n        self.emulator = None\n        if instantiate_emulator:\n            self.emulator = Emulator(\n                self.platform,\n                self.keyboard,\n                device=self.device,\n                ios_name=self.ios_name,\n                ios_platform=self.ios_platform,\n            )\n\n        # Typing on keyboard is slow. Because we go through several AC calls\n        # in one sentence, keep track of the previously typed context, so we\n        # can just type the remaining characters\n        self.previous_context = \"\"\n\n    def __reduce__(self) -&gt; Tuple:\n        \"\"\"This method simply makes the object pickable.\n\n        Returns:\n            Tuple of callable and arguments.\n        \"\"\"\n        return (\n            self.__class__,\n            (self.platform, self.keyboard, self.device, self.fast_mode, self.ios_name, self.ios_platform),\n        )\n\n    def cached_type(self, context: str, word: str):\n        \"\"\"This class keeps track of the content of the context currently\n        typed in the emulator. This method uses this current context to\n        determine if we need to retype the sentence or not. Instead of\n        always erasing the content being typed, we can directly type the\n        remaining characters, which saves up time.\n\n        Args:\n            context (str): Context to paste.\n            word (str): Word to type.\n        \"\"\"\n        sentence = context + word\n        if sentence.startswith(self.previous_context):\n            # The sentence to type start similarly as the previous context\n            # Don't retype everything, just what we need\n            self.emulator.type_characters(sentence[len(self.previous_context) :])\n        else:\n            # The previous context is not right, erase everything and type it\n            self.emulator.paste(context)\n            self.emulator.type_characters(word)\n        self.previous_context = sentence\n\n    def auto_correct(\n        self,\n        context: str,\n        keystrokes: List[Optional[Tuple[float, float]]],\n        word: str,\n    ) -&gt; List[str]:\n        \"\"\"Implementation of `auto_correct` method for emulated keyboards.\n\n        Args:\n            context (str): String representing the previously typed characters\n                (the beginning of the sentence basically).\n            keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n                (x and y coordinates) for each keystroke of the word being\n                typed.\n            word (str): Word being typed (corresponding to the keystrokes).\n\n        Returns:\n            The list of correction candidates.\n        \"\"\"\n        self.cached_type(context, word)\n        candidates = self.emulator.get_predictions() if not self.fast_mode else []\n\n        candidates = [c for c in candidates if c != \"\"]\n\n        # On keyboard, the leftmost candidate is the word being typed without\n        # any change. If the word doesn't have a typo, this first candidate\n        # should be kept as the auto-correction, but if the word has a typo,\n        # we should remove it from the candidates list (as it will be\n        # auto-corrected).\n        # In order to know if it will be auto-corrected or not, we have no\n        # choice but type a space and retrieve the current text to see if it\n        # was auto-corrected or not.\n        self.emulator.type_characters(\" \")\n        self.previous_context = self.emulator.get_text()\n        autocorrection = self.previous_context[len(context) :].strip()\n\n        if len(candidates) == 0:\n            candidates = [autocorrection]\n        elif candidates[0] != autocorrection:\n            candidates.pop(0)\n            if autocorrection not in candidates:\n                candidates.insert(0, autocorrection)\n\n        return candidates\n\n    def auto_complete(\n        self,\n        context: str,\n        keystrokes: List[Optional[Tuple[float, float]]],\n        partial_word: str,\n    ) -&gt; List[str]:\n        \"\"\"Implementation of `auto_complete` method for emulated keyboards.\n\n        Args:\n            context (str): String representing the previously typed characters\n                (the beginning of the sentence basically).\n            keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n                (x and y coordinates) for each keystroke of the word being\n                typed.\n            partial_word (str): Partial word being typed (corresponding to the\n                keystrokes).\n\n        Returns:\n            The list of completion candidates.\n        \"\"\"\n        if self.fast_mode:\n            return []\n\n        self.cached_type(context, partial_word)\n        candidates = self.emulator.get_predictions()\n\n        candidates = [c for c in candidates if c != \"\"]\n\n        return candidates\n\n    def predict_next_word(self, context: str) -&gt; List[str]:\n        \"\"\"Implementation of `predict_next_word` method for emulated keyboards.\n\n        Args:\n            context (str): String representing the previously typed characters\n                (the beginning of the sentence basically).\n\n        Returns:\n            The list of next-word candidates.\n        \"\"\"\n        if self.fast_mode:\n            return []\n\n        # In order to get the predictions, the space should be typed\n        assert context[-1] == \" \"\n        self.cached_type(context[:-1], \" \")\n        candidates = self.emulator.get_predictions()\n        candidates = [c for c in candidates if c != \"\"]\n\n        return candidates\n</code></pre>"},{"location":"internals/#kebbie.correctors.EmulatorCorrector.__reduce__","title":"<code>__reduce__()</code>","text":"<p>This method simply makes the object pickable.</p> <p>Returns:</p> Type Description <code>Tuple</code> <p>Tuple of callable and arguments.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def __reduce__(self) -&gt; Tuple:\n    \"\"\"This method simply makes the object pickable.\n\n    Returns:\n        Tuple of callable and arguments.\n    \"\"\"\n    return (\n        self.__class__,\n        (self.platform, self.keyboard, self.device, self.fast_mode, self.ios_name, self.ios_platform),\n    )\n</code></pre>"},{"location":"internals/#kebbie.correctors.EmulatorCorrector.cached_type","title":"<code>cached_type(context, word)</code>","text":"<p>This class keeps track of the content of the context currently typed in the emulator. This method uses this current context to determine if we need to retype the sentence or not. Instead of always erasing the content being typed, we can directly type the remaining characters, which saves up time.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>Context to paste.</p> required <code>word</code> <code>str</code> <p>Word to type.</p> required Source code in <code>kebbie/correctors.py</code> <pre><code>def cached_type(self, context: str, word: str):\n    \"\"\"This class keeps track of the content of the context currently\n    typed in the emulator. This method uses this current context to\n    determine if we need to retype the sentence or not. Instead of\n    always erasing the content being typed, we can directly type the\n    remaining characters, which saves up time.\n\n    Args:\n        context (str): Context to paste.\n        word (str): Word to type.\n    \"\"\"\n    sentence = context + word\n    if sentence.startswith(self.previous_context):\n        # The sentence to type start similarly as the previous context\n        # Don't retype everything, just what we need\n        self.emulator.type_characters(sentence[len(self.previous_context) :])\n    else:\n        # The previous context is not right, erase everything and type it\n        self.emulator.paste(context)\n        self.emulator.type_characters(word)\n    self.previous_context = sentence\n</code></pre>"},{"location":"internals/#kebbie.correctors.EmulatorCorrector.auto_correct","title":"<code>auto_correct(context, keystrokes, word)</code>","text":"<p>Implementation of <code>auto_correct</code> method for emulated keyboards.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>String representing the previously typed characters (the beginning of the sentence basically).</p> required <code>keystrokes</code> <code>List[Optional[Tuple[float, float]]]</code> <p>List of positions (x and y coordinates) for each keystroke of the word being typed.</p> required <code>word</code> <code>str</code> <p>Word being typed (corresponding to the keystrokes).</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of correction candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def auto_correct(\n    self,\n    context: str,\n    keystrokes: List[Optional[Tuple[float, float]]],\n    word: str,\n) -&gt; List[str]:\n    \"\"\"Implementation of `auto_correct` method for emulated keyboards.\n\n    Args:\n        context (str): String representing the previously typed characters\n            (the beginning of the sentence basically).\n        keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n            (x and y coordinates) for each keystroke of the word being\n            typed.\n        word (str): Word being typed (corresponding to the keystrokes).\n\n    Returns:\n        The list of correction candidates.\n    \"\"\"\n    self.cached_type(context, word)\n    candidates = self.emulator.get_predictions() if not self.fast_mode else []\n\n    candidates = [c for c in candidates if c != \"\"]\n\n    # On keyboard, the leftmost candidate is the word being typed without\n    # any change. If the word doesn't have a typo, this first candidate\n    # should be kept as the auto-correction, but if the word has a typo,\n    # we should remove it from the candidates list (as it will be\n    # auto-corrected).\n    # In order to know if it will be auto-corrected or not, we have no\n    # choice but type a space and retrieve the current text to see if it\n    # was auto-corrected or not.\n    self.emulator.type_characters(\" \")\n    self.previous_context = self.emulator.get_text()\n    autocorrection = self.previous_context[len(context) :].strip()\n\n    if len(candidates) == 0:\n        candidates = [autocorrection]\n    elif candidates[0] != autocorrection:\n        candidates.pop(0)\n        if autocorrection not in candidates:\n            candidates.insert(0, autocorrection)\n\n    return candidates\n</code></pre>"},{"location":"internals/#kebbie.correctors.EmulatorCorrector.auto_complete","title":"<code>auto_complete(context, keystrokes, partial_word)</code>","text":"<p>Implementation of <code>auto_complete</code> method for emulated keyboards.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>String representing the previously typed characters (the beginning of the sentence basically).</p> required <code>keystrokes</code> <code>List[Optional[Tuple[float, float]]]</code> <p>List of positions (x and y coordinates) for each keystroke of the word being typed.</p> required <code>partial_word</code> <code>str</code> <p>Partial word being typed (corresponding to the keystrokes).</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of completion candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def auto_complete(\n    self,\n    context: str,\n    keystrokes: List[Optional[Tuple[float, float]]],\n    partial_word: str,\n) -&gt; List[str]:\n    \"\"\"Implementation of `auto_complete` method for emulated keyboards.\n\n    Args:\n        context (str): String representing the previously typed characters\n            (the beginning of the sentence basically).\n        keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n            (x and y coordinates) for each keystroke of the word being\n            typed.\n        partial_word (str): Partial word being typed (corresponding to the\n            keystrokes).\n\n    Returns:\n        The list of completion candidates.\n    \"\"\"\n    if self.fast_mode:\n        return []\n\n    self.cached_type(context, partial_word)\n    candidates = self.emulator.get_predictions()\n\n    candidates = [c for c in candidates if c != \"\"]\n\n    return candidates\n</code></pre>"},{"location":"internals/#kebbie.correctors.EmulatorCorrector.predict_next_word","title":"<code>predict_next_word(context)</code>","text":"<p>Implementation of <code>predict_next_word</code> method for emulated keyboards.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>String representing the previously typed characters (the beginning of the sentence basically).</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of next-word candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def predict_next_word(self, context: str) -&gt; List[str]:\n    \"\"\"Implementation of `predict_next_word` method for emulated keyboards.\n\n    Args:\n        context (str): String representing the previously typed characters\n            (the beginning of the sentence basically).\n\n    Returns:\n        The list of next-word candidates.\n    \"\"\"\n    if self.fast_mode:\n        return []\n\n    # In order to get the predictions, the space should be typed\n    assert context[-1] == \" \"\n    self.cached_type(context[:-1], \" \")\n    candidates = self.emulator.get_predictions()\n    candidates = [c for c in candidates if c != \"\"]\n\n    return candidates\n</code></pre>"},{"location":"internals/#emulatorpy","title":"<code>emulator.py</code>","text":"<p>Module containing the code necessary to interact with the emulators, using Appium.</p>"},{"location":"internals/#kebbie.emulator.Emulator","title":"<code>Emulator</code>","text":"<p>Class used to interact with an emulator and type word on a given keyboard.</p> <p>Parameters:</p> Name Type Description Default <code>platform</code> <code>str</code> <p><code>android</code> or <code>ios</code>.</p> required <code>keyboard</code> <code>str</code> <p>The name of the keyboard installed on the emulator. This is needed because each keyboard has a different layout, and we need to know each key's position in order to type words.</p> required <code>device</code> <code>str</code> <p>Device UDID to use.</p> <code>None</code> <code>host</code> <code>str</code> <p>Appium server's address.</p> <code>'127.0.0.1'</code> <code>port</code> <code>str</code> <p>Appium server's port.</p> <code>'4723'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Error raised if the given platform doesn't exist.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class Emulator:\n    \"\"\"Class used to interact with an emulator and type word on a given keyboard.\n\n    Args:\n        platform (str): `android` or `ios`.\n        keyboard (str): The name of the keyboard installed on the emulator.\n            This is needed because each keyboard has a different layout, and we\n            need to know each key's position in order to type words.\n        device (str, optional): Device UDID to use.\n        host (str, optional): Appium server's address.\n        port (str, optional): Appium server's port.\n\n    Raises:\n        ValueError: Error raised if the given platform doesn't exist.\n    \"\"\"\n\n    def __init__(  # noqa: C901\n        self,\n        platform: str,\n        keyboard: str,\n        device: str = None,\n        host: str = \"127.0.0.1\",\n        port: str = \"4723\",\n        ios_name: str = None,\n        ios_platform: str = None,\n    ):\n        super().__init__()\n\n        self.platform = platform.lower()\n        if self.platform not in [ANDROID, IOS]:\n            raise ValueError(f\"Unknown platform : {self.platform}. Please specify `{ANDROID}` or `{IOS}`.\")\n\n        # Start appium\n        capabilities = ANDROID_CAPABILITIES if self.platform == ANDROID else IOS_CAPABILITIES\n        if self.platform == IOS:\n            capabilities[\"deviceName\"] = ios_name\n            capabilities[\"platformVersion\"] = ios_platform\n            capabilities[\"wdaLocalPort\"] = 8000 + (device if device is not None else 0)\n        if self.platform == ANDROID and device is not None:\n            capabilities[\"udid\"] = device\n        self.driver = webdriver.Remote(f\"{host}:{port}\", capabilities)\n        self.driver.implicitly_wait(20)\n\n        self.screen_size = self.driver.get_window_size()\n\n        self.keyboard = keyboard.lower()\n\n        # Access a typing field\n        self.typing_field = None\n        self._access_typing_field()\n\n        # Keep track of the keyboard behavior\n        # When the typing field is empty, the keyboard is uppercase by default\n        self.kb_is_upper = True\n        self.last_char_is_space = False\n        self.last_char_is_eos = False\n\n        # Set the keyboard as default\n        if self.platform == ANDROID:\n            self.select_keyboard(keyboard)\n\n        # Get the right layout\n        if self.keyboard == GBOARD:\n            self.detected = GboardLayoutDetector(self.driver, self._tap)\n            self.layout = self.detected.layout\n        elif self.keyboard == TAPPA:\n            self.detected = TappaLayoutDetector(self.driver, self._tap)\n            self.layout = self.detected.layout\n        elif self.keyboard == FLEKSY:\n            self.detected = FleksyLayoutDetector(self.driver)\n            self.layout = self.detected.layout\n        elif self.keyboard == IOS:\n            self.detected = IosLayoutDetector(self.driver, self._tap)\n            self.layout = self.detected.layout\n        elif self.keyboard == KBKITPRO:\n            self.detected = KbkitproLayoutDetector(self.driver, self._tap)\n            self.layout = self.detected.layout\n        elif self.keyboard == KBKITOSS:\n            self.detected = KbkitossLayoutDetector(self.driver, self._tap)\n            self.layout = self.detected.layout\n        elif self.keyboard == SWIFTKEY:\n            self.detected = SwiftkeyLayoutDetector(self.driver, self._tap)\n            self.layout = self.detected.layout\n        else:\n            raise ValueError(\n                f\"Unknown keyboard : {self.keyboard}. Please specify `{GBOARD}`, `{TAPPA}`, `{FLEKSY}`, \"\n                f\"`{SWIFTKEY}`, `{KBKITPRO}`, `{KBKITOSS}` or `{IOS}`.\"\n            )\n\n        self.typing_field.clear()\n\n    def _access_typing_field(self):\n        \"\"\"Start the right application and access the typing field where we\n        will type our text.\n        \"\"\"\n        if self.platform == ANDROID:\n            subprocess.run(\n                [\"adb\", \"shell\", \"am\", \"start\", \"-a\", \"android.intent.action.VIEW\", \"-d\", BROWSER_PAD_URL],\n                stdout=subprocess.PIPE,\n            )\n            typing_field_loaded = False\n            while not typing_field_loaded:\n                typing_fields = self.driver.find_elements(By.CLASS_NAME, ANDROID_TYPING_FIELD_CLASS_NAME)\n                typing_field_loaded = len(typing_fields) == 2\n            self.typing_field = typing_fields[0]\n        else:\n            self.driver.find_element(By.CLASS_NAME, IOS_START_CHAT_CLASS_NAME).click()\n            self.typing_field = self.driver.find_element(By.ID, IOS_TYPING_FIELD_ID)\n        self.typing_field.click()\n        self.typing_field.clear()\n\n    def get_android_devices() -&gt; List[str]:\n        \"\"\"Static method that uses the `adb devices` command to retrieve the\n        list of devices running.\n\n        Returns:\n            List of detected device UDID.\n        \"\"\"\n        result = subprocess.run([\"adb\", \"devices\"], stdout=subprocess.PIPE)\n        devices = result.stdout.decode().split(\"\\n\")\n        devices = [d.split()[0] for d in devices if not (d.startswith(\"List of devices attached\") or len(d) == 0)]\n        return devices\n\n    def select_keyboard(self, keyboard):\n        \"\"\"Searches the IME of the desired keyboard and selects it, only for Android.\n\n        Args:\n            keyboard (str): Keyboard to search.\n        \"\"\"\n        if keyboard not in KEYBOARD_PACKAGE:\n            print(\n                f\"Warning ! {keyboard}'s IME isn't provided (in `KEYBOARD_PACKAGE`), can't automatically select the \"\n                \"keyboard.\"\n            )\n            return\n\n        ime_list = subprocess.check_output([\"adb\", \"shell\", \"ime\", \"list\", \"-s\"], universal_newlines=True)\n        ime_name = None\n        for ime in ime_list.strip().split(\"\\n\"):\n            if KEYBOARD_PACKAGE[keyboard] in ime:\n                ime_name = ime\n                break\n        if ime_name:\n            subprocess.run(\n                [\"adb\", \"shell\", \"settings\", \"put\", \"secure\", \"show_ime_with_hard_keyboard\", \"1\"],\n                stdout=subprocess.PIPE,\n            )\n            subprocess.run([\"adb\", \"shell\", \"ime\", \"enable\", ime_name], stdout=subprocess.PIPE)\n            subprocess.run([\"adb\", \"shell\", \"ime\", \"set\", ime_name], stdout=subprocess.PIPE)\n\n    def get_ios_devices() -&gt; List[Tuple[str, str]]:\n        \"\"\"Static method that uses the `xcrun simctl` command to retrieve the\n        list of booted devices.\n\n        Returns:\n            List of booted device platform and device name.\n        \"\"\"\n        devices = []\n\n        result = subprocess.run([\"xcrun\", \"simctl\", \"list\", \"devices\"], stdout=subprocess.PIPE)\n        out = result.stdout.decode().split(\"\\n\")\n\n        curr_platform = \"\"\n        for line in out:\n            if line.startswith(\"== \") and line.endswith(\" ==\"):\n                continue\n            elif line.startswith(\"-- \") and line.endswith(\" --\"):\n                curr_platform = line[3:-3]\n            else:\n                m = re.match(r\"\\s+([^\\t]+)\\s+\\([A-Z0-9\\-]+\\)\\s+\\((Booted|Shutdown)\\)\", line)\n                if m:\n                    device_name = m.group(1)\n                    status = m.group(2)\n\n                    if status == \"Booted\" and curr_platform.startswith(\"iOS \"):\n                        devices.append((curr_platform[4:], device_name))\n\n        return devices\n\n    def _paste(self, text: str):\n        \"\"\"Paste the given text into the typing field, to quickly simulate\n        typing a context.\n\n        Args:\n            text (str): Text to paste.\n        \"\"\"\n        if text == \"\":\n            self.typing_field.clear()\n            self.kb_is_upper = True\n            self.last_char_is_space = False\n            self.last_char_is_eos = False\n        else:\n            # Note : on Android, pasting content in the field will erase the previous content\n            # (which is what we want). On iOS it will not, we need to do it \"manually\"\n            if self.platform == IOS:\n                self.typing_field.clear()\n            if self.keyboard == KBKITPRO or self.keyboard == KBKITOSS or self.keyboard == FLEKSY:\n                # In the case of KeyboardKit / Fleksy, after pasting the content, typing a space\n                # trigger a punctuation (because previous context may end with a space)\n                # To avoid this behavior, break the cycle by typing a backspace\n                self._tap(self.layout[\"lowercase\"][\"backspace\"])\n            self.typing_field.send_keys(text)\n            self.kb_is_upper = len(text) &gt; 1 and self._is_eos(text[-2]) and text.endswith(\" \")\n            self.last_char_is_space = text.endswith(\" \")\n            self.last_char_is_eos = self._is_eos(text[-1])\n\n    def paste(self, text: str):\n        \"\"\"Paste the given text into the typing field, to quickly simulate\n        typing a context.\n\n        This method is just a wrapper around `_paste()`, making sure the typing\n        field is accessible. If for some reason it is not accessible, it tries\n        to access it and perform the action again.\n\n        Args:\n            text (str): Text to paste.\n        \"\"\"\n        try:\n            self._paste(text)\n        except StaleElementReferenceException:\n            self._access_typing_field()\n            self._paste(text)\n\n    def type_characters(self, characters: str):  # noqa: C901\n        \"\"\"Type the given sentence on the keyboard. For each character, it\n        finds the keys to press and send a tap on the keyboard.\n\n        Args:\n            characters (str): The sentence to type.\n        \"\"\"\n        for c in characters:\n            if c == \" \":\n                if self.last_char_is_space:\n                    # If the previous character was a space, don't retype a space\n                    # because it can be transformed into a `.`\n                    continue\n\n                if self.kb_is_upper:\n                    self._tap(self.layout[\"uppercase\"][\"spacebar\"])\n                else:\n                    self._tap(self.layout[\"lowercase\"][\"spacebar\"])\n\n                # Behavior of the keyboard : if the previous character typed was an EOS marker\n                # and a space is typed, the keyboard automatically switch to uppercase\n                if self.last_char_is_eos:\n                    self.kb_is_upper = True\n            elif c in self.layout[\"lowercase\"]:\n                # The character is a lowercase character\n                if self.kb_is_upper:\n                    # If the keyboard is in uppercase mode, change it to lowercase\n                    self._tap(self.layout[\"uppercase\"][\"shift\"])\n                    if self.keyboard == SWIFTKEY:\n                        # Swiftkey needs double tap, otherwise we are capslocking\n                        self._tap(self.layout[\"uppercase\"][\"shift\"])\n                self._tap(self.layout[\"lowercase\"][c])\n            elif c in self.layout[\"uppercase\"]:\n                # The character is an uppercase character\n                if not self.kb_is_upper:\n                    # Change the keyboard to uppercase\n                    self._tap(self.layout[\"lowercase\"][\"shift\"])\n                self._tap(self.layout[\"uppercase\"][c])\n                # After typing one character, the keyboard automatically come back to lowercase\n            elif c in self.layout[\"numbers\"]:\n                # The character is a number of a special character\n                # Access the number keyboard properly\n                if self.kb_is_upper:\n                    self._tap(self.layout[\"uppercase\"][\"numbers\"])\n                else:\n                    self._tap(self.layout[\"lowercase\"][\"numbers\"])\n                self._tap(self.layout[\"numbers\"][c])\n\n                if c != \"'\" or self.keyboard in [GBOARD, SWIFTKEY]:\n                    # For some reason, when `'` is typed, the keyboard automatically goes back\n                    # to lowercase, so no need to re-tap the button (unless the keyboard is GBoard / Swiftkey).\n                    # In all other cases, switch back to letters keyboard\n                    self._tap(self.layout[\"numbers\"][\"letters\"])\n            else:\n                # Can't type this character, ignore it\n                continue\n\n            # Behavior of the keyboard : if the previous character typed was an EOS marker\n            # and a space is typed, the keyboard automatically switch to uppercase\n            self.kb_is_upper = self.last_char_is_eos and c == \" \"\n\n            # Update infos about what we typed\n            self.last_char_is_eos = self._is_eos(c)\n            self.last_char_is_space = c == \" \"\n\n    def _is_eos(self, c: str) -&gt; bool:\n        \"\"\"Check if the given character is an End-Of-Sentence marker. If an EOS\n        marker is typed followed by a space, the keyboard automatically switch\n        to uppercase letters (unless it's GBoard).\n\n        Args:\n            c (str): Character to check.\n\n        Returns:\n            True if the character is an EOS marker.\n        \"\"\"\n        if self.keyboard == GBOARD:\n            return False\n        else:\n            return c in [\".\", \"!\", \"?\"]\n\n    def _tap(self, frame: List[int], keyboard_frame: List[int] = None):\n        \"\"\"Tap on the screen at the position described by the given frame.\n\n        Args:\n            frame (List[int]): Frame describing the position where to tap. A\n                frame is : [start_pos_x, start_pos_y, width, height].\n            keyboard_frame (List[int]): If specified, the Keyboard frame to\n                use. If `None`, it will use `self.layout[\"keyboard_frame\"]`.\n        \"\"\"\n        x, y, w, h = frame\n        base_x, base_y, *_ = keyboard_frame if keyboard_frame else self.layout[\"keyboard_frame\"]\n\n        pos_x = base_x + x + int(w / 2)\n        pos_y = base_y + y + int(h / 2)\n\n        actions = ActionChains(self.driver)\n        actions.w3c_actions = ActionBuilder(self.driver, mouse=PointerInput(interaction.POINTER_TOUCH, \"touch\"))\n        actions.w3c_actions.pointer_action.move_to_location(pos_x, pos_y)\n        actions.w3c_actions.pointer_action.pointer_down()\n        actions.w3c_actions.pointer_action.pause(0.05)\n        actions.w3c_actions.pointer_action.release()\n        actions.perform()\n\n    def _take_screenshot(self):\n        \"\"\"Take a screenshot of the full screen.\n\n        Returns:\n            The image of the screen.\n        \"\"\"\n        screen_data = self.driver.get_screenshot_as_png()\n        screen = np.asarray(Image.open(io.BytesIO(screen_data)))\n        return screen.copy()\n\n    def get_predictions(self, lang: str = \"en\") -&gt; List[str]:\n        \"\"\"Retrieve the predictions displayed by the keyboard.\n\n        Args:\n            lang (str): Language to use for the OCR.\n\n        Returns:\n            List of predictions from the keyboard.\n        \"\"\"\n        if hasattr(self, \"detected\"):\n            # Only keyboards that were auto-detected (using XML tree) have the\n            # attribute `detected`. If that's the case, it means we\n            # can retrieve the suggestions directly from the XML tree !\n            predictions = self.detected.get_suggestions()\n        else:\n            # Other keyboards still have to use (slow) OCR\n            time.sleep(PREDICTION_DELAY)\n            screen = self._take_screenshot()\n\n            kb_x, kb_y, kb_w, kb_h = self.layout[\"keyboard_frame\"]\n            screen = screen[kb_y : kb_y + kb_h, kb_x : kb_x + kb_w]\n\n            predictions = []\n            for x, y, w, h in self.layout[\"suggestions_frames\"]:\n                suggestion_area = screen[y : y + h, x : x + w]\n                ocr_results = pytesseract.image_to_string(suggestion_area, config=TESSERACT_CONFIG)\n                pred = ocr_results.strip().replace(\"\u201c\", \"\").replace('\"', \"\").replace(\"\\\\\", \"\")\n                predictions.append(pred)\n\n        return predictions\n\n    def _get_text(self) -&gt; str:\n        \"\"\"Return the text currently contained in the typing field.\n\n        Returns:\n            Text of the typing field.\n        \"\"\"\n        return self.typing_field.text\n\n    def get_text(self) -&gt; str:\n        \"\"\"Return the text currently contained in the typing field.\n\n        This method is just a wrapper around `_get_text()`, making sure the\n        typing field is accessible. If for some reason it is not accessible, it\n        tries to access it and perform the action again.\n\n        Returns:\n            Text of the typing field.\n        \"\"\"\n        try:\n            return self._get_text()\n        except StaleElementReferenceException:\n            self._access_typing_field()\n            return self._get_text()\n\n    def show_keyboards(self):\n        \"\"\"Take a screenshot and overlay the given layout, for debugging the\n        position of each keys.\n        \"\"\"\n        # Type a character, in order to have some suggestions\n        # Keyboard starts with uppercase letter by default (unless GBoard), and\n        # automatically go to lowercase after\n        if self.keyboard == GBOARD:\n            self._tap(self.layout[\"lowercase\"][\"a\"])\n        else:\n            self._tap(self.layout[\"uppercase\"][\"A\"])\n        screen_lower = self._take_screenshot()\n\n        self._tap(self.layout[\"lowercase\"][\"shift\"])\n        screen_upper = self._take_screenshot()\n\n        self._tap(self.layout[\"lowercase\"][\"numbers\"])\n        screen_numbers = self._take_screenshot()\n\n        for layout_name, screen in zip(\n            [\"lowercase\", \"uppercase\", \"numbers\"], [screen_lower, screen_upper, screen_numbers]\n        ):\n            self._set_area_box(screen, (0, 0), self.layout[\"keyboard_frame\"], \"keyboard frame\")\n            if \"suggestions_frames\" in self.layout:\n                for i, suggestion_frame in enumerate(self.layout[\"suggestions_frames\"]):\n                    self._set_area_box(screen, self.layout[\"keyboard_frame\"], suggestion_frame, f\"suggestion {i}\")\n            for key_name, key_frame in self.layout[layout_name].items():\n                self._set_area_box(screen, self.layout[\"keyboard_frame\"], key_frame, key_name)\n\n            cv2.imshow(layout_name, screen)\n\n        cv2.waitKey(0)\n        cv2.destroyAllWindows()\n\n    def _set_area_box(self, image, base_coords: Tuple[int], coords: Tuple[int], tag: str):\n        \"\"\"Add an area box on the given image (color is random).\n\n        Args:\n            image: Image where to add the box.\n            base_coords (Tuple[int]): Base coordinates from the full image.\n            coords (Tuple[int]): Coordinates of the element, as well as\n                dimensions.\n            tag (str): Tag for this box.\n        \"\"\"\n        base_x, base_y, *_ = base_coords\n        x, y, w, h = coords\n        x += base_x\n        y += base_y\n        # Generate color only until 200, to ensure it's dark enough\n        color = (random.randint(0, 200), random.randint(0, 200), random.randint(0, 200))\n        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n        cv2.putText(image, tag, (x, y + h + 17), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.get_android_devices","title":"<code>get_android_devices()</code>","text":"<p>Static method that uses the <code>adb devices</code> command to retrieve the list of devices running.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of detected device UDID.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_android_devices() -&gt; List[str]:\n    \"\"\"Static method that uses the `adb devices` command to retrieve the\n    list of devices running.\n\n    Returns:\n        List of detected device UDID.\n    \"\"\"\n    result = subprocess.run([\"adb\", \"devices\"], stdout=subprocess.PIPE)\n    devices = result.stdout.decode().split(\"\\n\")\n    devices = [d.split()[0] for d in devices if not (d.startswith(\"List of devices attached\") or len(d) == 0)]\n    return devices\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.select_keyboard","title":"<code>select_keyboard(keyboard)</code>","text":"<p>Searches the IME of the desired keyboard and selects it, only for Android.</p> <p>Parameters:</p> Name Type Description Default <code>keyboard</code> <code>str</code> <p>Keyboard to search.</p> required Source code in <code>kebbie/emulator.py</code> <pre><code>def select_keyboard(self, keyboard):\n    \"\"\"Searches the IME of the desired keyboard and selects it, only for Android.\n\n    Args:\n        keyboard (str): Keyboard to search.\n    \"\"\"\n    if keyboard not in KEYBOARD_PACKAGE:\n        print(\n            f\"Warning ! {keyboard}'s IME isn't provided (in `KEYBOARD_PACKAGE`), can't automatically select the \"\n            \"keyboard.\"\n        )\n        return\n\n    ime_list = subprocess.check_output([\"adb\", \"shell\", \"ime\", \"list\", \"-s\"], universal_newlines=True)\n    ime_name = None\n    for ime in ime_list.strip().split(\"\\n\"):\n        if KEYBOARD_PACKAGE[keyboard] in ime:\n            ime_name = ime\n            break\n    if ime_name:\n        subprocess.run(\n            [\"adb\", \"shell\", \"settings\", \"put\", \"secure\", \"show_ime_with_hard_keyboard\", \"1\"],\n            stdout=subprocess.PIPE,\n        )\n        subprocess.run([\"adb\", \"shell\", \"ime\", \"enable\", ime_name], stdout=subprocess.PIPE)\n        subprocess.run([\"adb\", \"shell\", \"ime\", \"set\", ime_name], stdout=subprocess.PIPE)\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.get_ios_devices","title":"<code>get_ios_devices()</code>","text":"<p>Static method that uses the <code>xcrun simctl</code> command to retrieve the list of booted devices.</p> <p>Returns:</p> Type Description <code>List[Tuple[str, str]]</code> <p>List of booted device platform and device name.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_ios_devices() -&gt; List[Tuple[str, str]]:\n    \"\"\"Static method that uses the `xcrun simctl` command to retrieve the\n    list of booted devices.\n\n    Returns:\n        List of booted device platform and device name.\n    \"\"\"\n    devices = []\n\n    result = subprocess.run([\"xcrun\", \"simctl\", \"list\", \"devices\"], stdout=subprocess.PIPE)\n    out = result.stdout.decode().split(\"\\n\")\n\n    curr_platform = \"\"\n    for line in out:\n        if line.startswith(\"== \") and line.endswith(\" ==\"):\n            continue\n        elif line.startswith(\"-- \") and line.endswith(\" --\"):\n            curr_platform = line[3:-3]\n        else:\n            m = re.match(r\"\\s+([^\\t]+)\\s+\\([A-Z0-9\\-]+\\)\\s+\\((Booted|Shutdown)\\)\", line)\n            if m:\n                device_name = m.group(1)\n                status = m.group(2)\n\n                if status == \"Booted\" and curr_platform.startswith(\"iOS \"):\n                    devices.append((curr_platform[4:], device_name))\n\n    return devices\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.paste","title":"<code>paste(text)</code>","text":"<p>Paste the given text into the typing field, to quickly simulate typing a context.</p> <p>This method is just a wrapper around <code>_paste()</code>, making sure the typing field is accessible. If for some reason it is not accessible, it tries to access it and perform the action again.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to paste.</p> required Source code in <code>kebbie/emulator.py</code> <pre><code>def paste(self, text: str):\n    \"\"\"Paste the given text into the typing field, to quickly simulate\n    typing a context.\n\n    This method is just a wrapper around `_paste()`, making sure the typing\n    field is accessible. If for some reason it is not accessible, it tries\n    to access it and perform the action again.\n\n    Args:\n        text (str): Text to paste.\n    \"\"\"\n    try:\n        self._paste(text)\n    except StaleElementReferenceException:\n        self._access_typing_field()\n        self._paste(text)\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.type_characters","title":"<code>type_characters(characters)</code>","text":"<p>Type the given sentence on the keyboard. For each character, it finds the keys to press and send a tap on the keyboard.</p> <p>Parameters:</p> Name Type Description Default <code>characters</code> <code>str</code> <p>The sentence to type.</p> required Source code in <code>kebbie/emulator.py</code> <pre><code>def type_characters(self, characters: str):  # noqa: C901\n    \"\"\"Type the given sentence on the keyboard. For each character, it\n    finds the keys to press and send a tap on the keyboard.\n\n    Args:\n        characters (str): The sentence to type.\n    \"\"\"\n    for c in characters:\n        if c == \" \":\n            if self.last_char_is_space:\n                # If the previous character was a space, don't retype a space\n                # because it can be transformed into a `.`\n                continue\n\n            if self.kb_is_upper:\n                self._tap(self.layout[\"uppercase\"][\"spacebar\"])\n            else:\n                self._tap(self.layout[\"lowercase\"][\"spacebar\"])\n\n            # Behavior of the keyboard : if the previous character typed was an EOS marker\n            # and a space is typed, the keyboard automatically switch to uppercase\n            if self.last_char_is_eos:\n                self.kb_is_upper = True\n        elif c in self.layout[\"lowercase\"]:\n            # The character is a lowercase character\n            if self.kb_is_upper:\n                # If the keyboard is in uppercase mode, change it to lowercase\n                self._tap(self.layout[\"uppercase\"][\"shift\"])\n                if self.keyboard == SWIFTKEY:\n                    # Swiftkey needs double tap, otherwise we are capslocking\n                    self._tap(self.layout[\"uppercase\"][\"shift\"])\n            self._tap(self.layout[\"lowercase\"][c])\n        elif c in self.layout[\"uppercase\"]:\n            # The character is an uppercase character\n            if not self.kb_is_upper:\n                # Change the keyboard to uppercase\n                self._tap(self.layout[\"lowercase\"][\"shift\"])\n            self._tap(self.layout[\"uppercase\"][c])\n            # After typing one character, the keyboard automatically come back to lowercase\n        elif c in self.layout[\"numbers\"]:\n            # The character is a number of a special character\n            # Access the number keyboard properly\n            if self.kb_is_upper:\n                self._tap(self.layout[\"uppercase\"][\"numbers\"])\n            else:\n                self._tap(self.layout[\"lowercase\"][\"numbers\"])\n            self._tap(self.layout[\"numbers\"][c])\n\n            if c != \"'\" or self.keyboard in [GBOARD, SWIFTKEY]:\n                # For some reason, when `'` is typed, the keyboard automatically goes back\n                # to lowercase, so no need to re-tap the button (unless the keyboard is GBoard / Swiftkey).\n                # In all other cases, switch back to letters keyboard\n                self._tap(self.layout[\"numbers\"][\"letters\"])\n        else:\n            # Can't type this character, ignore it\n            continue\n\n        # Behavior of the keyboard : if the previous character typed was an EOS marker\n        # and a space is typed, the keyboard automatically switch to uppercase\n        self.kb_is_upper = self.last_char_is_eos and c == \" \"\n\n        # Update infos about what we typed\n        self.last_char_is_eos = self._is_eos(c)\n        self.last_char_is_space = c == \" \"\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.get_predictions","title":"<code>get_predictions(lang='en')</code>","text":"<p>Retrieve the predictions displayed by the keyboard.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>Language to use for the OCR.</p> <code>'en'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of predictions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_predictions(self, lang: str = \"en\") -&gt; List[str]:\n    \"\"\"Retrieve the predictions displayed by the keyboard.\n\n    Args:\n        lang (str): Language to use for the OCR.\n\n    Returns:\n        List of predictions from the keyboard.\n    \"\"\"\n    if hasattr(self, \"detected\"):\n        # Only keyboards that were auto-detected (using XML tree) have the\n        # attribute `detected`. If that's the case, it means we\n        # can retrieve the suggestions directly from the XML tree !\n        predictions = self.detected.get_suggestions()\n    else:\n        # Other keyboards still have to use (slow) OCR\n        time.sleep(PREDICTION_DELAY)\n        screen = self._take_screenshot()\n\n        kb_x, kb_y, kb_w, kb_h = self.layout[\"keyboard_frame\"]\n        screen = screen[kb_y : kb_y + kb_h, kb_x : kb_x + kb_w]\n\n        predictions = []\n        for x, y, w, h in self.layout[\"suggestions_frames\"]:\n            suggestion_area = screen[y : y + h, x : x + w]\n            ocr_results = pytesseract.image_to_string(suggestion_area, config=TESSERACT_CONFIG)\n            pred = ocr_results.strip().replace(\"\u201c\", \"\").replace('\"', \"\").replace(\"\\\\\", \"\")\n            predictions.append(pred)\n\n    return predictions\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.get_text","title":"<code>get_text()</code>","text":"<p>Return the text currently contained in the typing field.</p> <p>This method is just a wrapper around <code>_get_text()</code>, making sure the typing field is accessible. If for some reason it is not accessible, it tries to access it and perform the action again.</p> <p>Returns:</p> Type Description <code>str</code> <p>Text of the typing field.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_text(self) -&gt; str:\n    \"\"\"Return the text currently contained in the typing field.\n\n    This method is just a wrapper around `_get_text()`, making sure the\n    typing field is accessible. If for some reason it is not accessible, it\n    tries to access it and perform the action again.\n\n    Returns:\n        Text of the typing field.\n    \"\"\"\n    try:\n        return self._get_text()\n    except StaleElementReferenceException:\n        self._access_typing_field()\n        return self._get_text()\n</code></pre>"},{"location":"internals/#kebbie.emulator.Emulator.show_keyboards","title":"<code>show_keyboards()</code>","text":"<p>Take a screenshot and overlay the given layout, for debugging the position of each keys.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def show_keyboards(self):\n    \"\"\"Take a screenshot and overlay the given layout, for debugging the\n    position of each keys.\n    \"\"\"\n    # Type a character, in order to have some suggestions\n    # Keyboard starts with uppercase letter by default (unless GBoard), and\n    # automatically go to lowercase after\n    if self.keyboard == GBOARD:\n        self._tap(self.layout[\"lowercase\"][\"a\"])\n    else:\n        self._tap(self.layout[\"uppercase\"][\"A\"])\n    screen_lower = self._take_screenshot()\n\n    self._tap(self.layout[\"lowercase\"][\"shift\"])\n    screen_upper = self._take_screenshot()\n\n    self._tap(self.layout[\"lowercase\"][\"numbers\"])\n    screen_numbers = self._take_screenshot()\n\n    for layout_name, screen in zip(\n        [\"lowercase\", \"uppercase\", \"numbers\"], [screen_lower, screen_upper, screen_numbers]\n    ):\n        self._set_area_box(screen, (0, 0), self.layout[\"keyboard_frame\"], \"keyboard frame\")\n        if \"suggestions_frames\" in self.layout:\n            for i, suggestion_frame in enumerate(self.layout[\"suggestions_frames\"]):\n                self._set_area_box(screen, self.layout[\"keyboard_frame\"], suggestion_frame, f\"suggestion {i}\")\n        for key_name, key_frame in self.layout[layout_name].items():\n            self._set_area_box(screen, self.layout[\"keyboard_frame\"], key_frame, key_name)\n\n        cv2.imshow(layout_name, screen)\n\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n</code></pre>"},{"location":"internals/#kebbie.emulator.LayoutDetector","title":"<code>LayoutDetector</code>","text":"<p>Base class for auto-detection of the keyboard layout.</p> <p>To auto-detect a new keyboard, create a new sub-class, and overwite <code>__init__()</code> and <code>get_suggestions()</code>. Use the existing subclass for GBoard as reference.</p> <p>Parameters:</p> Name Type Description Default <code>driver</code> <code>Remote</code> <p>The Appium driver, used to access elements on the emulator.</p> required <code>tap_fn</code> <code>Callable</code> <p>A callback used to tap at specific position on the screen. See <code>Emulator._tap()</code>.</p> required <code>xpath_root</code> <code>str</code> <p>XPath to the root element of the keyboard.</p> required <code>xpath_keys</code> <code>str</code> <p>XPath to detect the keys elements.</p> required Source code in <code>kebbie/emulator.py</code> <pre><code>class LayoutDetector:\n    \"\"\"Base class for auto-detection of the keyboard layout.\n\n    To auto-detect a new keyboard, create a new sub-class, and overwite\n    `__init__()` and `get_suggestions()`. Use the existing subclass for GBoard\n    as reference.\n\n    Args:\n        driver (webdriver.Remote): The Appium driver, used to access elements\n            on the emulator.\n        tap_fn (Callable): A callback used to tap at specific position on the\n            screen. See `Emulator._tap()`.\n        xpath_root (str): XPath to the root element of the keyboard.\n        xpath_keys (str): XPath to detect the keys elements.\n    \"\"\"\n\n    def __init__(\n        self, driver: webdriver.Remote, tap_fn: Callable, xpath_root: str, xpath_keys: str, android: bool = True\n    ):\n        self.driver = driver\n        self.tap = tap_fn\n        self.xpath_root = xpath_root\n        self.xpath_keys = xpath_keys\n        self.android = android\n\n        layout = {}\n\n        # Get the root element of our keyboard\n        root = self.driver.find_element(By.XPATH, self.xpath_root)\n\n        # On empty field, the keyboard is on uppercase\n        # So first, retrieve the keyboard frame and uppercase characters\n        kb_frame, screen_layout = self._detect_keys(root, current_layout=\"uppercase\")\n        layout[\"keyboard_frame\"] = kb_frame\n        layout[\"uppercase\"] = screen_layout\n\n        # Then, after typing a letter, the keyboard goes to lowercase automatically\n        self.tap(layout[\"uppercase\"][\"A\"], layout[\"keyboard_frame\"])\n        _, screen_layout = self._detect_keys(root, keyboard_frame=layout[\"keyboard_frame\"], current_layout=\"lowercase\")\n        layout[\"lowercase\"] = screen_layout\n\n        # Finally, access the symbols keyboard and get characters positions\n        self.tap(layout[\"lowercase\"][\"numbers\"], layout[\"keyboard_frame\"])\n        _, screen_layout = self._detect_keys(root, keyboard_frame=layout[\"keyboard_frame\"], current_layout=\"numbers\")\n        layout[\"numbers\"] = screen_layout\n\n        # Reset out keyboard to the original layer\n        self.tap(layout[\"numbers\"][\"letters\"], layout[\"keyboard_frame\"])\n\n        self.layout = layout\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Note that it's slower to access the XML through methods like\n        `find_element()`, and it's faster to access the raw XML with\n        `self.driver.page_source` and parse it as text directly.\n\n        Raises:\n            NotImplementedError: Exception raised if this method is not\n                overwritten.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        raise NotImplementedError\n\n    def _detect_keys(\n        self, root: WebElement, current_layout: str, keyboard_frame: List[int] = None\n    ) -&gt; Tuple[List[int], Dict]:\n        \"\"\"This method detects all keys currently on screen.\n\n        If no keyboard_frame is given, it will also detects the keyboard frame.\n\n        Args:\n            root (WebElement): Root element in the XML tree that represents the\n                keyboard (with all its keys).\n            current_layout (str): Name of the current layout.\n            keyboard_frame (List[int], optional): Optionally, the keyboard\n                frame (so we don't need to re-detect it everytime).\n\n        Returns:\n            Keyboard frame\n            Layout with all the keys detected on this screen.\n        \"\"\"\n        layout = {}\n        if keyboard_frame is None:\n            if self.android:\n                # Detect the keyboard frame\n                kb = root.find_element(By.ID, \"android:id/inputArea\")\n                keyboard_frame = self._get_frame(kb)\n            else:\n                keyboard_frame = self._get_frame(root)\n\n        for key_elem in root.find_elements(By.XPATH, self.xpath_keys):\n            label = self._get_label(key_elem, current_layout=current_layout)\n            if label is not None:\n                layout[label] = self._get_frame(key_elem)\n\n        # Then update the letters positions to be relative to the keyboard frame\n        for k in layout:\n            layout[k][0] -= keyboard_frame[0]\n            layout[k][1] -= keyboard_frame[1]\n\n        return keyboard_frame, layout\n\n    def _get_frame(self, element: WebElement) -&gt; List[int]:\n        \"\"\"For layout detection, this method returns the bounds of the given\n        element.\n\n        Args:\n            element (WebElement): XML Element describing a key.\n\n        Returns:\n            Bounds of this key.\n        \"\"\"\n        if self.android:\n            m = re.match(r\"\\[(\\d+),(\\d+)\\]\\[(\\d+),(\\d+)\\]\", element.get_attribute(\"bounds\"))\n            if m:\n                bounds = [int(g) for g in m.groups()]\n                return [bounds[0], bounds[1], bounds[2] - bounds[0], bounds[3] - bounds[1]]\n        else:\n            r = json.loads(element.get_attribute(\"rect\"))\n            return [r[\"x\"], r[\"y\"], r[\"width\"], r[\"height\"]]\n\n    def _get_label(self, element: WebElement, current_layout: str, is_suggestion: bool = False) -&gt; str:\n        \"\"\"For layout detection, this method returns the content of the given\n        element.\n\n        This method returns `None` if it's a key we don't care about. This\n        method takes care of translating the content (the name used in the XML\n        tree is not the same as the one used in our layout).\n\n        Args:\n            element (WebElement): XML Element describing a key.\n            current_layout (str): Name of the current layout.\n            is_suggestion (bool, optional): If we are retrieving the content of\n                a suggestion, the content shouldn't be translated.\n\n        Returns:\n            Content of the key, or None if it's a key we should ignore.\n        \"\"\"\n        content = element.get_attribute(\"content-desc\") if self.android else element.get_attribute(\"name\")\n\n        if is_suggestion:\n            # If we are getting the content of the suggestion, return the content directly\n            return content\n\n        if content in CONTENT_TO_IGNORE:\n            return None\n        elif not self.android and content == \"more\":\n            if current_layout == \"uppercase\" or current_layout == \"lowercase\":\n                return \"numbers\"\n            else:\n                return \"letters\"\n        elif content in CONTENT_TO_RENAME:\n            return CONTENT_TO_RENAME[content]\n        else:\n            return content\n</code></pre>"},{"location":"internals/#kebbie.emulator.LayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Note that it's slower to access the XML through methods like <code>find_element()</code>, and it's faster to access the raw XML with <code>self.driver.page_source</code> and parse it as text directly.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Exception raised if this method is not overwritten.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Note that it's slower to access the XML through methods like\n    `find_element()`, and it's faster to access the raw XML with\n    `self.driver.page_source` and parse it as text directly.\n\n    Raises:\n        NotImplementedError: Exception raised if this method is not\n            overwritten.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"internals/#kebbie.emulator.GboardLayoutDetector","title":"<code>GboardLayoutDetector</code>","text":"<p>               Bases: <code>LayoutDetector</code></p> <p>Layout detector for the Gboard keyboard. See <code>LayoutDetector</code> for more information.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class GboardLayoutDetector(LayoutDetector):\n    \"\"\"Layout detector for the Gboard keyboard. See `LayoutDetector` for more\n    information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(\n            *args,\n            xpath_root=f\"./*/*[@package='{KEYBOARD_PACKAGE[GBOARD]}']\",\n            xpath_keys=\".//*[@resource-id][@content-desc]\",\n            **kwargs,\n        )\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        suggestions = []\n\n        sections = [\n            data\n            for data in self.driver.page_source.split(\"&lt;android.widget.FrameLayout\")\n            if \"com.google.android.inputmethod\" in data\n        ]\n        for section in sections:\n            if \"content-desc\" in section and \"resource-id\" not in section and 'long-clickable=\"true\"' in section:\n                m = re.search(r\"content\\-desc=\\\"([^\\\"]*)\\\"\", section)\n                if m:\n                    content = m.group(1)\n\n                    # Deal with emojis\n                    emoji = re.match(r\"emoji (&amp;[^;]+;)\", content)\n                    suggestions.append(html.unescape(emoji[1]) if emoji else content)\n\n        return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.GboardLayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    suggestions = []\n\n    sections = [\n        data\n        for data in self.driver.page_source.split(\"&lt;android.widget.FrameLayout\")\n        if \"com.google.android.inputmethod\" in data\n    ]\n    for section in sections:\n        if \"content-desc\" in section and \"resource-id\" not in section and 'long-clickable=\"true\"' in section:\n            m = re.search(r\"content\\-desc=\\\"([^\\\"]*)\\\"\", section)\n            if m:\n                content = m.group(1)\n\n                # Deal with emojis\n                emoji = re.match(r\"emoji (&amp;[^;]+;)\", content)\n                suggestions.append(html.unescape(emoji[1]) if emoji else content)\n\n    return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.IosLayoutDetector","title":"<code>IosLayoutDetector</code>","text":"<p>               Bases: <code>LayoutDetector</code></p> <p>Layout detector for the iOS default keyboard. See <code>LayoutDetector</code> for more information.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class IosLayoutDetector(LayoutDetector):\n    \"\"\"Layout detector for the iOS default keyboard. See `LayoutDetector` for\n    more information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(\n            *args,\n            xpath_root=\".//XCUIElementTypeKeyboard\",\n            xpath_keys=\"(.//XCUIElementTypeKey|.//XCUIElementTypeButton)\",\n            android=False,\n            **kwargs,\n        )\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        suggestions = []\n\n        sections = [\n            data for data in self.driver.page_source.split(\"&lt;XCUIElementTypeOther\") if \"name=\" in data.split(\"&gt;\")[0]\n        ]\n        is_typing_predictions_section = False\n        for section in sections:\n            m = re.search(r\"name=\\\"([^\\\"]*)\\\"\", section)\n            if m:\n                name = m.group(1)\n\n                if name == \"Typing Predictions\":\n                    is_typing_predictions_section = True\n                    continue\n\n                if is_typing_predictions_section:\n                    suggestions.append(name.replace(\"\u201c\", \"\").replace(\"\u201d\", \"\"))\n\n        return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.IosLayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    suggestions = []\n\n    sections = [\n        data for data in self.driver.page_source.split(\"&lt;XCUIElementTypeOther\") if \"name=\" in data.split(\"&gt;\")[0]\n    ]\n    is_typing_predictions_section = False\n    for section in sections:\n        m = re.search(r\"name=\\\"([^\\\"]*)\\\"\", section)\n        if m:\n            name = m.group(1)\n\n            if name == \"Typing Predictions\":\n                is_typing_predictions_section = True\n                continue\n\n            if is_typing_predictions_section:\n                suggestions.append(name.replace(\"\u201c\", \"\").replace(\"\u201d\", \"\"))\n\n    return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.KbkitproLayoutDetector","title":"<code>KbkitproLayoutDetector</code>","text":"<p>               Bases: <code>LayoutDetector</code></p> <p>Layout detector for the KeyboardKit Pro demo keyboard. See <code>LayoutDetector</code> for more information.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class KbkitproLayoutDetector(LayoutDetector):\n    \"\"\"Layout detector for the KeyboardKit Pro demo keyboard. See\n    `LayoutDetector` for more information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(\n            *args,\n            xpath_root=\".//XCUIElementTypeOther[XCUIElementTypeButton and XCUIElementTypeTextField]\",\n            xpath_keys=\".//XCUIElementTypeButton\",\n            android=False,\n            **kwargs,\n        )\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        suggestions = []\n\n        for data in self.driver.page_source.split(\"&lt;XCUIElementTypeOther\"):\n            if \"&lt;XCUIElementTypeTextField\" in data:\n                pred_part = data.split(\"&lt;XCUIElementTypeTextField\")[0]\n                if \"&lt;XCUIElementTypeButton\" in pred_part and 'name=\"Add\"' in pred_part:\n                    for elem in pred_part.split(\"&gt;\")[2:]:\n                        if \"&lt;XCUIElementTypeTextField\" in elem:\n                            break\n                        m = re.search(r\"name=\\\"([^\\\"]*)\\\"\", elem)\n                        if m:\n                            name = m.group(1)\n                            suggestions.append(name.replace(\"\u201c\", \"\").replace(\"\u201d\", \"\"))\n\n        return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.KbkitproLayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    suggestions = []\n\n    for data in self.driver.page_source.split(\"&lt;XCUIElementTypeOther\"):\n        if \"&lt;XCUIElementTypeTextField\" in data:\n            pred_part = data.split(\"&lt;XCUIElementTypeTextField\")[0]\n            if \"&lt;XCUIElementTypeButton\" in pred_part and 'name=\"Add\"' in pred_part:\n                for elem in pred_part.split(\"&gt;\")[2:]:\n                    if \"&lt;XCUIElementTypeTextField\" in elem:\n                        break\n                    m = re.search(r\"name=\\\"([^\\\"]*)\\\"\", elem)\n                    if m:\n                        name = m.group(1)\n                        suggestions.append(name.replace(\"\u201c\", \"\").replace(\"\u201d\", \"\"))\n\n    return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.KbkitossLayoutDetector","title":"<code>KbkitossLayoutDetector</code>","text":"<p>               Bases: <code>LayoutDetector</code></p> <p>Layout detector for the KeyboardKit OSS demo keyboard. See <code>LayoutDetector</code> for more information.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class KbkitossLayoutDetector(LayoutDetector):\n    \"\"\"Layout detector for the KeyboardKit OSS demo keyboard. See\n    `LayoutDetector` for more information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(\n            *args,\n            xpath_root=\".//XCUIElementTypeOther[XCUIElementTypeButton and XCUIElementTypeStaticText]\",\n            xpath_keys=\".//XCUIElementTypeButton\",\n            android=False,\n            **kwargs,\n        )\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        suggestions = []\n\n        for data in self.driver.page_source.split(\"&lt;XCUIElementTypeOther\"):\n            if \", Subtitle\" in data:\n                pred_part = data.split(\", Subtitle\")[0]\n                for elem in pred_part.split(\"&gt;\")[1:]:\n                    m = re.search(r\"name=\\\"([^\\\"]*)\\\"?\", elem)\n                    if m:\n                        name = m.group(1)\n                        suggestions.append(name.replace(\"\u201c\", \"\").replace(\"\u201d\", \"\"))\n\n        return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.KbkitossLayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    suggestions = []\n\n    for data in self.driver.page_source.split(\"&lt;XCUIElementTypeOther\"):\n        if \", Subtitle\" in data:\n            pred_part = data.split(\", Subtitle\")[0]\n            for elem in pred_part.split(\"&gt;\")[1:]:\n                m = re.search(r\"name=\\\"([^\\\"]*)\\\"?\", elem)\n                if m:\n                    name = m.group(1)\n                    suggestions.append(name.replace(\"\u201c\", \"\").replace(\"\u201d\", \"\"))\n\n    return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.SwiftkeyLayoutDetector","title":"<code>SwiftkeyLayoutDetector</code>","text":"<p>               Bases: <code>LayoutDetector</code></p> <p>Layout detector for the Swiftkey keyboard. See <code>LayoutDetector</code> for more information.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class SwiftkeyLayoutDetector(LayoutDetector):\n    \"\"\"Layout detector for the Swiftkey keyboard. See `LayoutDetector` for more\n    information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(\n            *args,\n            xpath_root=f\"./*/*[@package='{KEYBOARD_PACKAGE[SWIFTKEY]}']\",\n            xpath_keys=\".//*[@class='android.view.View'][@content-desc]\",\n            **kwargs,\n        )\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        suggestions = []\n\n        # Get the raw content as text, weed out useless elements\n        for data in self.driver.page_source.split(\"&lt;android.widget.FrameLayout\"):\n            if \"com.touchtype.swiftkey\" in data and \"&lt;android.view.View \" in data:\n                sections = data.split(\"&lt;android.view.View \")\n                for section in sections[1:]:\n                    m = re.search(r\"content-desc=\\\"([^\\\"]*)\\\"\", section)\n                    if m:\n                        suggestions.append(html.unescape(m.group(1)))\n                break\n\n        return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.SwiftkeyLayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    suggestions = []\n\n    # Get the raw content as text, weed out useless elements\n    for data in self.driver.page_source.split(\"&lt;android.widget.FrameLayout\"):\n        if \"com.touchtype.swiftkey\" in data and \"&lt;android.view.View \" in data:\n            sections = data.split(\"&lt;android.view.View \")\n            for section in sections[1:]:\n                m = re.search(r\"content-desc=\\\"([^\\\"]*)\\\"\", section)\n                if m:\n                    suggestions.append(html.unescape(m.group(1)))\n            break\n\n    return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.TappaLayoutDetector","title":"<code>TappaLayoutDetector</code>","text":"<p>               Bases: <code>LayoutDetector</code></p> <p>Layout detector for the Tappa keyboard. See <code>LayoutDetector</code> for more information.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class TappaLayoutDetector(LayoutDetector):\n    \"\"\"Layout detector for the Tappa keyboard. See `LayoutDetector` for more\n    information.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(\n            *args,\n            xpath_root=f\"./*/*[@package='{KEYBOARD_PACKAGE[TAPPA]}']\",\n            xpath_keys=\".//com.mocha.keyboard.inputmethod.keyboard.Key\",\n            **kwargs,\n        )\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        suggestions = []\n\n        # Get the raw content as text, weed out useless elements\n        section = self.driver.page_source.split(f\"{KEYBOARD_PACKAGE[TAPPA]}:id/toolbar\")[1].split(\n            \"&lt;/android.widget.FrameLayout&gt;\"\n        )[0]\n\n        for line in section.split(\"\\n\"):\n            if \"&lt;android.widget.TextView\" in line:\n                m = re.search(r\"text=\\\"([^\\\"]*)\\\"\", line)\n                if m:\n                    suggestions.append(html.unescape(m.group(1)))\n\n        return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.TappaLayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    suggestions = []\n\n    # Get the raw content as text, weed out useless elements\n    section = self.driver.page_source.split(f\"{KEYBOARD_PACKAGE[TAPPA]}:id/toolbar\")[1].split(\n        \"&lt;/android.widget.FrameLayout&gt;\"\n    )[0]\n\n    for line in section.split(\"\\n\"):\n        if \"&lt;android.widget.TextView\" in line:\n            m = re.search(r\"text=\\\"([^\\\"]*)\\\"\", line)\n            if m:\n                suggestions.append(html.unescape(m.group(1)))\n\n    return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.FleksyLayoutDetector","title":"<code>FleksyLayoutDetector</code>","text":"<p>               Bases: <code>LayoutDetector</code></p> <p>Layout detector for the Fleksy keyboard. See <code>LayoutDetector</code> for more information.</p> <p>Note that this class is only semi-automatically detected : the layout itself is not detected, but the suggestions are retrieved from the XML tree (no need to rely on OCR, much faster). The layout is hard-coded for now.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>class FleksyLayoutDetector(LayoutDetector):\n    \"\"\"Layout detector for the Fleksy keyboard. See `LayoutDetector` for more\n    information.\n\n    Note that this class is only semi-automatically detected : the layout\n    itself is not detected, but the suggestions are retrieved from the XML tree\n    (no need to rely on OCR, much faster). The layout is hard-coded for now.\n    \"\"\"\n\n    def __init__(self, driver: webdriver.Remote):\n        self.driver = driver\n\n        # Adapt the layout to the screen\n        w = FLEKSY_LAYOUT[\"keyboard_frame\"][2]\n        h = FLEKSY_LAYOUT[\"keyboard_frame\"][3]\n        self.layout = {\"keyboard_frame\": FLEKSY_LAYOUT[\"keyboard_frame\"]}\n        for layout_name in [\"lowercase\", \"uppercase\", \"numbers\"]:\n            for key_name, key_frame in FLEKSY_LAYOUT[layout_name].items():\n                if layout_name not in self.layout:\n                    self.layout[layout_name] = {}\n                self.layout[layout_name][key_name] = [\n                    int(key_frame[0] * w),\n                    int(key_frame[1] * h),\n                    int(key_frame[2] * w),\n                    int(key_frame[3] * h),\n                ]\n\n    def get_suggestions(self) -&gt; List[str]:\n        \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n        Returns:\n            List of suggestions from the keyboard.\n        \"\"\"\n        suggestions = []\n\n        # Get the raw content as text, weed out useless elements\n        sections = [\n            s\n            for s in self.driver.page_source.split(\"XCUIElementTypeOther\")\n            if \"XCUIElementTypeStaticText\" in s and \"XCUIElementTypeButton\" not in s\n        ]\n\n        for s in sections:\n            m = re.search(r\"name=\\\"([^\\\"]*)\\\"\", s)\n            if m:\n                suggestions.append(html.unescape(m.group(1)))\n\n        return suggestions\n</code></pre>"},{"location":"internals/#kebbie.emulator.FleksyLayoutDetector.get_suggestions","title":"<code>get_suggestions()</code>","text":"<p>Method to retrieve the keyboard suggestions from the XML tree.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of suggestions from the keyboard.</p> Source code in <code>kebbie/emulator.py</code> <pre><code>def get_suggestions(self) -&gt; List[str]:\n    \"\"\"Method to retrieve the keyboard suggestions from the XML tree.\n\n    Returns:\n        List of suggestions from the keyboard.\n    \"\"\"\n    suggestions = []\n\n    # Get the raw content as text, weed out useless elements\n    sections = [\n        s\n        for s in self.driver.page_source.split(\"XCUIElementTypeOther\")\n        if \"XCUIElementTypeStaticText\" in s and \"XCUIElementTypeButton\" not in s\n    ]\n\n    for s in sections:\n        m = re.search(r\"name=\\\"([^\\\"]*)\\\"\", s)\n        if m:\n            suggestions.append(html.unescape(m.group(1)))\n\n    return suggestions\n</code></pre>"},{"location":"internals/#gesturepy","title":"<code>gesture.py</code>","text":"<p>Module containing the function <code>make_swipe_gesture</code>, which is used to create a natural-looking swipe gesture from a list of letter-points.</p>"},{"location":"internals/#kebbie.gesture.make_swipe_gesture","title":"<code>make_swipe_gesture(control_points)</code>","text":"<p>Function to generate artificial swipe gesture from a list of points. The given points represents the typed letters on the keyboard. This function simply generate several other points between the control points. Points are generated using sequential Bezier curves. The resulting swipe gesture pass by the control points.</p> <p>Parameters:</p> Name Type Description Default <code>control_points</code> <code>List[Tuple[float, float]]</code> <p>Control points, representing the letter typed. The resulting swipe gesture will pass by these points.</p> required <p>Returns:</p> Type Description <code>List[Tuple[float, float]]</code> <p>Points generated by the swipe gesture.</p> Source code in <code>kebbie/gesture.py</code> <pre><code>def make_swipe_gesture(control_points: List[Tuple[float, float]]) -&gt; List[Tuple[float, float]]:\n    \"\"\"Function to generate artificial swipe gesture from a list of points.\n    The given points represents the typed letters on the keyboard. This\n    function simply generate several other points between the control points.\n    Points are generated using sequential Bezier curves. The resulting swipe\n    gesture pass by the control points.\n\n    Args:\n        control_points (List[Tuple[float, float]]): Control points,\n            representing the letter typed. The resulting swipe gesture will\n            pass by these points.\n\n    Returns:\n        Points generated by the swipe gesture.\n    \"\"\"\n    gesture_points = [control_points[0]]\n\n    # Pick a \"style\" (speed &amp; acceleration) and keep it constant across the gesture\n    speed = random.uniform(MIN_N_POINTS_PER_DIST, MAX_N_POINTS_PER_DIST)\n    acceleration = random.uniform(MIN_ACCELERATION, MAX_ACCELERATION)\n\n    # Generate bezier curves between each control points\n    for p1, p2 in zip(control_points[:-1], control_points[1:]):\n        # The distance between the 2 points will dictate the speed and radius\n        d = euclidian_dist(p1, p2)\n        radius = min(d, MAX_RADIUS)\n        n_points = max(1, int(d * speed))\n\n        linspace = accelerated_linspace(n_points, acceleration)\n\n        # We don't want the curves to be straight between the control points,\n        # so we generate random points to add curves\n        p1_curv = random_point_around(p1, radius=radius)\n        p2_curv = random_point_around(p2, radius=radius)\n\n        # Make the bezier curve with the specified number of points\n        xs, ys = bezier_curve([p2, p2_curv, p1_curv, p1], linspace=linspace)\n        bezier_points = list(zip(xs, ys))\n\n        # Make sure the control point p2 is here\n        if bezier_points[-1] != p2:\n            bezier_points.append(p2)\n        # p1 was already added in the previous loop, no need to add it\n        if bezier_points[0] == p1:\n            bezier_points = bezier_points[1:]\n\n        gesture_points.extend(bezier_points)\n\n    return gesture_points\n</code></pre>"},{"location":"internals/#kebbie.gesture.random_point_around","title":"<code>random_point_around(p, radius)</code>","text":"<p>Generate a random point around the given point p, within the given radius.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Tuple[float, float]</code> <p>Coordinates to use as a starting point.</p> required <code>radius</code> <code>float</code> <p>Radius within the starting point to generate the random point.</p> required <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>Coordinates of the generated random point.</p> Source code in <code>kebbie/gesture.py</code> <pre><code>def random_point_around(p: Tuple[float, float], radius: float) -&gt; Tuple[float, float]:\n    \"\"\"Generate a random point around the given point p, within the given\n    radius.\n\n    Args:\n        p (Tuple[float, float]): Coordinates to use as a starting point.\n        radius (float): Radius within the starting point to generate the random\n            point.\n\n    Returns:\n        Coordinates of the generated random point.\n    \"\"\"\n    rand_x = random.uniform(p[0] - radius, p[0] + radius)\n    rand_y = random.uniform(p[1] - radius, p[1] + radius)\n    return (rand_x, rand_y)\n</code></pre>"},{"location":"internals/#kebbie.gesture.bernstein_poly","title":"<code>bernstein_poly(i, n, t)</code>","text":"<p>The Bernstein polynomial of n, i as a function of t.</p> <p>Taken from : https://stackoverflow.com/a/12644499/9494790</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>i</p> required <code>n</code> <code>int</code> <p>n</p> required <code>t</code> <code>float</code> <p>t</p> required <p>Returns:</p> Type Description <code>float</code> <p>The computed value for this polynomial function.</p> Source code in <code>kebbie/gesture.py</code> <pre><code>def bernstein_poly(i: int, n: int, t: float) -&gt; float:\n    \"\"\"The Bernstein polynomial of n, i as a function of t.\n\n    Taken from : https://stackoverflow.com/a/12644499/9494790\n\n    Args:\n        i (int): i\n        n (int): n\n        t (float): t\n\n    Returns:\n        The computed value for this polynomial function.\n    \"\"\"\n    return comb(n, i) * (t ** (n - i)) * (1 - t) ** i\n</code></pre>"},{"location":"internals/#kebbie.gesture.bezier_curve","title":"<code>bezier_curve(control_points, linspace)</code>","text":"<p>Given a set of control points, return the bezier curve defined by the control points.</p> <p>See : http://processingjs.nihongoresources.com/bezierinfo/</p> <p>Taken from : https://stackoverflow.com/a/12644499/9494790</p> <p>Parameters:</p> Name Type Description Default <code>control_points</code> <code>List[Tuple[float, float]]</code> <p>Control points used to generate the bezier curve.</p> required <code>linspace</code> <code>List[float]</code> <p>Linspace to use for sampling points across the Bezier curve.</p> required <p>Returns:</p> Type Description <code>Tuple[List[float], List[float]]</code> <p>Sampled points along the bezier curve.</p> Source code in <code>kebbie/gesture.py</code> <pre><code>def bezier_curve(control_points: List[Tuple[float, float]], linspace: List[float]) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"Given a set of control points, return the bezier curve defined by the\n    control points.\n\n    See : http://processingjs.nihongoresources.com/bezierinfo/\n\n    Taken from : https://stackoverflow.com/a/12644499/9494790\n\n    Args:\n        control_points (List[Tuple[float, float]]): Control points used to\n            generate the bezier curve.\n        linspace (List[float]): Linspace to use for sampling points across the\n            Bezier curve.\n\n    Returns:\n        Sampled points along the bezier curve.\n    \"\"\"\n    n_points = len(control_points)\n    x_points = np.array([p[0] for p in control_points])\n    y_points = np.array([p[1] for p in control_points])\n\n    polynomial_array = np.array([bernstein_poly(i, n_points - 1, linspace) for i in range(0, n_points)])\n\n    x_vals = np.dot(x_points, polynomial_array)\n    y_vals = np.dot(y_points, polynomial_array)\n\n    return x_vals, y_vals\n</code></pre>"},{"location":"internals/#kebbie.gesture.accelerated_linspace","title":"<code>accelerated_linspace(n, acceleration)</code>","text":"<p>Alternative to np.linspace, instead of giving a range of number evenly distributed, this one is not evenly distributed, and simulate an acceleration at first, and then a deceleration.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of points to generate in the linspace.</p> required <code>acceleration</code> <code>float</code> <p>A number that dictate how constant the acceleration is. The lower, the more S-shape is used.</p> required <p>Returns:</p> Type Description <code>List[float]</code> <p>Generated points.</p> Source code in <code>kebbie/gesture.py</code> <pre><code>def accelerated_linspace(n: int, acceleration: float) -&gt; List[float]:\n    \"\"\"Alternative to np.linspace, instead of giving a range of number evenly\n    distributed, this one is not evenly distributed, and simulate an\n    acceleration at first, and then a deceleration.\n\n    Args:\n        n (int): Number of points to generate in the linspace.\n        acceleration (float): A number that dictate how constant the\n            acceleration is. The lower, the more S-shape is used.\n\n    Returns:\n        Generated points.\n    \"\"\"\n\n    def norm(x):\n        nom = x - x.min()\n        denom = x.max() - x.min()\n        return nom / denom\n\n    def sigmoid(x, k):\n        return 1 / (1 + np.exp(-x / k))\n\n    linspace = np.linspace(-1.0, 1.0, n)\n\n    if n &lt;= 1:\n        return linspace\n    else:\n        return norm(sigmoid(linspace, k=acceleration))\n</code></pre>"},{"location":"internals/#layoutpy","title":"<code>layout.py</code>","text":"<p>Module containing the helpers <code>LayoutHelper</code>, useful class to deal with the layout of a keyboard, access key positions, etc...</p>"},{"location":"internals/#kebbie.layout.KeyInfo","title":"<code>KeyInfo</code>  <code>dataclass</code>","text":"<p>Structure containing all information needed for a given character (key).</p> <p>Parameters:</p> Name Type Description Default <code>klayer_id</code> <code>int</code> <p>Keyboard Layer ID where this key is located.</p> required <code>width</code> <code>float</code> <p>Width of the key.</p> required <code>height</code> <code>float</code> <p>Height of the key.</p> required <code>center</code> <code>Tuple[float, float]</code> <p>Center position (x, y coordinates) of the key.</p> required Source code in <code>kebbie/layout.py</code> <pre><code>@dataclass\nclass KeyInfo:\n    \"\"\"Structure containing all information needed for a given character (key).\n\n    Args:\n        klayer_id (int): Keyboard Layer ID where this key is located.\n        width (float): Width of the key.\n        height (float): Height of the key.\n        center (Tuple[float, float]): Center position (x, y coordinates) of the\n            key.\n    \"\"\"\n\n    klayer_id: int\n    width: float\n    height: float\n    center: Tuple[float, float]\n</code></pre>"},{"location":"internals/#kebbie.layout.Key","title":"<code>Key</code>  <code>dataclass</code>","text":"<p>Structure containing information needed for each key of a given keyboard layer.</p> <p>Parameters:</p> Name Type Description Default <code>char</code> <code>str</code> <p>Character associated with this key.</p> required <code>bounds</code> <code>Dict[str, float]</code> <p>Dictionary representing the bounding box of the key. The dictionary should contains the following keys : <code>right</code>, <code>left</code>, <code>top</code>, <code>bottom</code>.</p> required Source code in <code>kebbie/layout.py</code> <pre><code>@dataclass\nclass Key:\n    \"\"\"Structure containing information needed for each key of a given keyboard\n    layer.\n\n    Args:\n        char (str): Character associated with this key.\n        bounds (Dict[str, float]): Dictionary representing the bounding box of\n            the key. The dictionary should contains the following keys :\n            `right`, `left`, `top`, `bottom`.\n    \"\"\"\n\n    char: str\n    bounds: Dict[str, float]\n</code></pre>"},{"location":"internals/#kebbie.layout.LayoutHelper","title":"<code>LayoutHelper</code>","text":"<p>Small class that represents a Keyboard layout. The goal of this class is to offer some easy-to-use method to deal with a keyboard layout.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>Language of the layout to load.</p> <code>'en-US'</code> <code>custom_keyboard</code> <code>Dict</code> <p>If provided, instead of relying on the keyboard layout provided by default, uses the given keyboard layout.</p> <code>None</code> <code>ignore_layers_after</code> <code>Optional[int]) </code> <p>Ignore higher layers of the keyboard layout. If <code>None</code> is given, no layer is ignored.</p> <code>None</code> Source code in <code>kebbie/layout.py</code> <pre><code>class LayoutHelper:\n    \"\"\"Small class that represents a Keyboard layout. The goal of this class is\n    to offer some easy-to-use method to deal with a keyboard layout.\n\n    Args:\n        lang (str, optional): Language of the layout to load.\n        custom_keyboard (Dict, optional): If provided, instead of relying on\n            the keyboard layout provided by default, uses the given keyboard\n            layout.\n        ignore_layers_after (Optional[int]) : Ignore higher layers of the\n            keyboard layout. If `None` is given, no layer is ignored.\n    \"\"\"\n\n    def __init__(self, lang: str = \"en-US\", custom_keyboard: Dict = None, ignore_layers_after: Optional[int] = None):\n        keyboard = custom_keyboard if custom_keyboard is not None else load_keyboard(lang)\n        self.keys_info, self.klayers_info, self.accents = self._extract_infos(keyboard[\"layout\"], ignore_layers_after)\n        self.letter_accents = [c for c in self.accents if re.match(r\"^[\\pL]+$\", c)]\n        self.spelling_symbols = keyboard[\"settings\"][\"allowed_symbols_in_words\"]\n        self.layout_name = keyboard[\"keyboard\"][\"default-layout\"]\n\n    def _extract_infos(  # noqa: C901\n        self, keyboard_layout: Dict, ignore_layers_after: Optional[int] = None\n    ) -&gt; Tuple[Dict[str, KeyInfo], Dict[int, Key], List[str]]:\n        \"\"\"This method reads the given keyboard layout, and extract useful data\n        structures from this (to be used later by other methods). This\n        basically builds the LayoutHelper class (and should be used only inside\n        the constructor).\n\n        Note:\n            The given keyboard layout contains 24 layers. Each key appears in\n            one (or several) layer of the keyboard. Accents are associated to\n            the same key as their non-accented version.\n            This class may be used to generate typing noise, so accents should\n            have their own keys (and closer accents should be represented by\n            closer keys). This method takes care of it, by generating \"virtual\n            keyboard layers\", for each group of accents. The goal is to\n            generate a virtual keyboard layer that is as close as possible as\n            the actual keyboard, used by real-users.\n\n        Args:\n            keyboard_layout (Dict): Dictionary representing the keyboard and\n                its layout.\n            ignore_layers_after (Optional[int]) : Ignore higher layers of the\n                keyboard layout. If `None` is given, no layer is ignored.\n\n        Returns:\n            Key information for each character in the keyboard.\n            Key information for each layer of the keyboard.\n            List of accents used in the keyboard.\n        \"\"\"\n        keys_info = {}  # Dict char -&gt; key infos (bounds, center, klayer ID)\n        klayers_info = defaultdict(list)  # Dict klayer ID -&gt; list of keys (bounds, char)\n        all_accents = set()\n\n        # A keyboard layout is made of several \"layers\", each identified by a KeyboardID\n        last_klayer_id = len(keyboard_layout)\n        for klayer in keyboard_layout:\n            if klayer[\"buttons\"] is None or (ignore_layers_after is not None and klayer[\"id\"] &gt; ignore_layers_after):\n                continue\n\n            # Each layer is a list of button\n            for button in klayer[\"buttons\"]:\n                # Button always have a character, and optionally accents\n                char, accents = button[\"labels\"][0], button[\"labels\"][1:]\n\n                # Special characters : space, shift, numbers, magic, etc...\n                if button[\"type\"] != 1:\n                    if char.lower() == SPACE:\n                        char = \" \"\n                    elif char == POINT:\n                        # Points should be added to our key infos\n                        pass\n                    else:\n                        # Other special characters are ignored\n                        char = None\n\n                if char is None:\n                    continue\n\n                # Save the character and its key information\n                # Save it only if it's not already in a previous klayer\n                if char not in keys_info or keys_info[char].klayer_id &gt; klayer[\"id\"]:\n                    keys_info[char] = KeyInfo(\n                        klayer[\"id\"],\n                        button[\"boundingRect\"][\"right\"] - button[\"boundingRect\"][\"left\"],\n                        button[\"boundingRect\"][\"bottom\"] - button[\"boundingRect\"][\"top\"],\n                        (button[\"centerPoint\"][\"x\"], button[\"centerPoint\"][\"y\"]),\n                    )\n                # But always save its info in the klayers info\n                klayers_info[klayer[\"id\"]].append(Key(char, button[\"boundingRect\"]))\n\n                # Then, save the accents if any\n                for i, char_accent in enumerate(accents):\n                    all_accents.add(char_accent)\n\n                    # Create a virtual position for the accent\n                    bounds, center = self._make_virtual_key(i, button[\"boundingRect\"])\n\n                    # Save the accent (only if not existing) in a new virtual klayer\n                    if char_accent not in keys_info:\n                        keys_info[char_accent] = KeyInfo(\n                            last_klayer_id,\n                            bounds[\"right\"] - bounds[\"left\"],\n                            bounds[\"bottom\"] - bounds[\"top\"],\n                            (center[\"x\"], center[\"y\"]),\n                        )\n                    # But always saveits info in the klayers info\n                    klayers_info[last_klayer_id].append(Key(char_accent, bounds))\n\n                # If we added some accent in a virtual klayer, don't forget to update the last klayer ID\n                if accents:\n                    last_klayer_id += 1\n\n        return keys_info, klayers_info, sorted(all_accents)\n\n    def _make_virtual_key(\n        self, idx: int, initial_bounds: Dict[str, float]\n    ) -&gt; Tuple[Dict[str, float], Dict[str, float]]:\n        \"\"\"Method to create a new boundary for an accented character. Based on\n        the given id, the generated boundary box will be generated at a\n        different position.\n\n        This method tries to follow a similar pattern as the sample app, with\n        accents appearing in lines of 4 accents.\n\n        Args:\n            idx (int): The index of the bounding box to generate.\n            initial_bounds (Dict[str, float]): The bounding box of the\n                non-accented key.\n\n        Returns:\n            Generated bounding box.\n            Its associated center position.\n        \"\"\"\n        width = initial_bounds[\"right\"] - initial_bounds[\"left\"]\n        height = initial_bounds[\"bottom\"] - initial_bounds[\"top\"]\n\n        start_x = initial_bounds[\"left\"] + (idx % N_ACCENT_PER_LINE) * width\n        start_y = initial_bounds[\"bottom\"] - (idx // N_ACCENT_PER_LINE) * height\n\n        bounds = {\n            \"bottom\": start_y,\n            \"left\": start_x,\n            \"right\": start_x + width,\n            \"top\": start_y - height,\n        }\n        center = {\n            \"x\": bounds[\"left\"] + width / 2,\n            \"y\": bounds[\"top\"] + height / 2,\n        }\n        return bounds, center\n\n    def get_key_info(self, char: str) -&gt; Tuple[float, float, float, float, int]:\n        \"\"\"Method to retrieve the information associated to a specific key.\n\n        Args:\n            char (str): Character for which to retrieve key information.\n\n        Raises:\n            KeyError: Exception raised if the given character can't be typed (\n                because it doesn't exist on this keyboard layout).\n\n        Returns:\n            Width of the key for the requested character.\n            Height of the key for the requested character.\n            Center position (x-axis) of the key for the requested character.\n            Center position (y-axis) of the key for the requested character.\n            Keyboard layer ID where the character's key is located.\n        \"\"\"\n        k = self.keys_info[char]\n        return k.width, k.height, k.center[0], k.center[1], k.klayer_id\n\n    def get_key(self, pos: Tuple[float, float], klayer_id: int) -&gt; str:\n        \"\"\"Get the character associated with the given position.\n\n        Args:\n            pos (Tuple[float, float]): Position (x, y) in the keyboard.\n            klayer_id (int): Keyboard layer ID to use.\n\n        Returns:\n            Character associated to the given position.\n        \"\"\"\n        klayer = self.klayers_info[klayer_id]\n\n        try:\n            # Retrieve the key that contains the sampled position\n            key = next(\n                k\n                for k in klayer\n                if k.bounds[\"left\"] &lt;= pos[0] &lt;= k.bounds[\"right\"] and k.bounds[\"top\"] &lt;= pos[1] &lt;= k.bounds[\"bottom\"]\n            )\n        except StopIteration:\n            # Maybe the sampled position was out of bound -&gt; retrieve the closest key\n            key = min(\n                klayer,\n                key=lambda k: euclidian_dist(\n                    pos,\n                    (\n                        k.bounds[\"left\"] + (k.bounds[\"right\"] - k.bounds[\"left\"]) / 2,\n                        k.bounds[\"top\"] + (k.bounds[\"bottom\"] - k.bounds[\"top\"]) / 2,\n                    ),\n                ),\n            )\n\n        return key.char\n</code></pre>"},{"location":"internals/#kebbie.layout.LayoutHelper._extract_infos","title":"<code>_extract_infos(keyboard_layout, ignore_layers_after=None)</code>","text":"<p>This method reads the given keyboard layout, and extract useful data structures from this (to be used later by other methods). This basically builds the LayoutHelper class (and should be used only inside the constructor).</p> Note <p>The given keyboard layout contains 24 layers. Each key appears in one (or several) layer of the keyboard. Accents are associated to the same key as their non-accented version. This class may be used to generate typing noise, so accents should have their own keys (and closer accents should be represented by closer keys). This method takes care of it, by generating \"virtual keyboard layers\", for each group of accents. The goal is to generate a virtual keyboard layer that is as close as possible as the actual keyboard, used by real-users.</p> <p>Parameters:</p> Name Type Description Default <code>keyboard_layout</code> <code>Dict</code> <p>Dictionary representing the keyboard and its layout.</p> required <code>ignore_layers_after</code> <code>Optional[int]) </code> <p>Ignore higher layers of the keyboard layout. If <code>None</code> is given, no layer is ignored.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, KeyInfo]</code> <p>Key information for each character in the keyboard.</p> <code>Dict[int, Key]</code> <p>Key information for each layer of the keyboard.</p> <code>List[str]</code> <p>List of accents used in the keyboard.</p> Source code in <code>kebbie/layout.py</code> <pre><code>def _extract_infos(  # noqa: C901\n    self, keyboard_layout: Dict, ignore_layers_after: Optional[int] = None\n) -&gt; Tuple[Dict[str, KeyInfo], Dict[int, Key], List[str]]:\n    \"\"\"This method reads the given keyboard layout, and extract useful data\n    structures from this (to be used later by other methods). This\n    basically builds the LayoutHelper class (and should be used only inside\n    the constructor).\n\n    Note:\n        The given keyboard layout contains 24 layers. Each key appears in\n        one (or several) layer of the keyboard. Accents are associated to\n        the same key as their non-accented version.\n        This class may be used to generate typing noise, so accents should\n        have their own keys (and closer accents should be represented by\n        closer keys). This method takes care of it, by generating \"virtual\n        keyboard layers\", for each group of accents. The goal is to\n        generate a virtual keyboard layer that is as close as possible as\n        the actual keyboard, used by real-users.\n\n    Args:\n        keyboard_layout (Dict): Dictionary representing the keyboard and\n            its layout.\n        ignore_layers_after (Optional[int]) : Ignore higher layers of the\n            keyboard layout. If `None` is given, no layer is ignored.\n\n    Returns:\n        Key information for each character in the keyboard.\n        Key information for each layer of the keyboard.\n        List of accents used in the keyboard.\n    \"\"\"\n    keys_info = {}  # Dict char -&gt; key infos (bounds, center, klayer ID)\n    klayers_info = defaultdict(list)  # Dict klayer ID -&gt; list of keys (bounds, char)\n    all_accents = set()\n\n    # A keyboard layout is made of several \"layers\", each identified by a KeyboardID\n    last_klayer_id = len(keyboard_layout)\n    for klayer in keyboard_layout:\n        if klayer[\"buttons\"] is None or (ignore_layers_after is not None and klayer[\"id\"] &gt; ignore_layers_after):\n            continue\n\n        # Each layer is a list of button\n        for button in klayer[\"buttons\"]:\n            # Button always have a character, and optionally accents\n            char, accents = button[\"labels\"][0], button[\"labels\"][1:]\n\n            # Special characters : space, shift, numbers, magic, etc...\n            if button[\"type\"] != 1:\n                if char.lower() == SPACE:\n                    char = \" \"\n                elif char == POINT:\n                    # Points should be added to our key infos\n                    pass\n                else:\n                    # Other special characters are ignored\n                    char = None\n\n            if char is None:\n                continue\n\n            # Save the character and its key information\n            # Save it only if it's not already in a previous klayer\n            if char not in keys_info or keys_info[char].klayer_id &gt; klayer[\"id\"]:\n                keys_info[char] = KeyInfo(\n                    klayer[\"id\"],\n                    button[\"boundingRect\"][\"right\"] - button[\"boundingRect\"][\"left\"],\n                    button[\"boundingRect\"][\"bottom\"] - button[\"boundingRect\"][\"top\"],\n                    (button[\"centerPoint\"][\"x\"], button[\"centerPoint\"][\"y\"]),\n                )\n            # But always save its info in the klayers info\n            klayers_info[klayer[\"id\"]].append(Key(char, button[\"boundingRect\"]))\n\n            # Then, save the accents if any\n            for i, char_accent in enumerate(accents):\n                all_accents.add(char_accent)\n\n                # Create a virtual position for the accent\n                bounds, center = self._make_virtual_key(i, button[\"boundingRect\"])\n\n                # Save the accent (only if not existing) in a new virtual klayer\n                if char_accent not in keys_info:\n                    keys_info[char_accent] = KeyInfo(\n                        last_klayer_id,\n                        bounds[\"right\"] - bounds[\"left\"],\n                        bounds[\"bottom\"] - bounds[\"top\"],\n                        (center[\"x\"], center[\"y\"]),\n                    )\n                # But always saveits info in the klayers info\n                klayers_info[last_klayer_id].append(Key(char_accent, bounds))\n\n            # If we added some accent in a virtual klayer, don't forget to update the last klayer ID\n            if accents:\n                last_klayer_id += 1\n\n    return keys_info, klayers_info, sorted(all_accents)\n</code></pre>"},{"location":"internals/#kebbie.layout.LayoutHelper._make_virtual_key","title":"<code>_make_virtual_key(idx, initial_bounds)</code>","text":"<p>Method to create a new boundary for an accented character. Based on the given id, the generated boundary box will be generated at a different position.</p> <p>This method tries to follow a similar pattern as the sample app, with accents appearing in lines of 4 accents.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the bounding box to generate.</p> required <code>initial_bounds</code> <code>Dict[str, float]</code> <p>The bounding box of the non-accented key.</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Generated bounding box.</p> <code>Dict[str, float]</code> <p>Its associated center position.</p> Source code in <code>kebbie/layout.py</code> <pre><code>def _make_virtual_key(\n    self, idx: int, initial_bounds: Dict[str, float]\n) -&gt; Tuple[Dict[str, float], Dict[str, float]]:\n    \"\"\"Method to create a new boundary for an accented character. Based on\n    the given id, the generated boundary box will be generated at a\n    different position.\n\n    This method tries to follow a similar pattern as the sample app, with\n    accents appearing in lines of 4 accents.\n\n    Args:\n        idx (int): The index of the bounding box to generate.\n        initial_bounds (Dict[str, float]): The bounding box of the\n            non-accented key.\n\n    Returns:\n        Generated bounding box.\n        Its associated center position.\n    \"\"\"\n    width = initial_bounds[\"right\"] - initial_bounds[\"left\"]\n    height = initial_bounds[\"bottom\"] - initial_bounds[\"top\"]\n\n    start_x = initial_bounds[\"left\"] + (idx % N_ACCENT_PER_LINE) * width\n    start_y = initial_bounds[\"bottom\"] - (idx // N_ACCENT_PER_LINE) * height\n\n    bounds = {\n        \"bottom\": start_y,\n        \"left\": start_x,\n        \"right\": start_x + width,\n        \"top\": start_y - height,\n    }\n    center = {\n        \"x\": bounds[\"left\"] + width / 2,\n        \"y\": bounds[\"top\"] + height / 2,\n    }\n    return bounds, center\n</code></pre>"},{"location":"internals/#kebbie.layout.LayoutHelper.get_key_info","title":"<code>get_key_info(char)</code>","text":"<p>Method to retrieve the information associated to a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>char</code> <code>str</code> <p>Character for which to retrieve key information.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>Exception raised if the given character can't be typed ( because it doesn't exist on this keyboard layout).</p> <p>Returns:</p> Type Description <code>float</code> <p>Width of the key for the requested character.</p> <code>float</code> <p>Height of the key for the requested character.</p> <code>float</code> <p>Center position (x-axis) of the key for the requested character.</p> <code>float</code> <p>Center position (y-axis) of the key for the requested character.</p> <code>int</code> <p>Keyboard layer ID where the character's key is located.</p> Source code in <code>kebbie/layout.py</code> <pre><code>def get_key_info(self, char: str) -&gt; Tuple[float, float, float, float, int]:\n    \"\"\"Method to retrieve the information associated to a specific key.\n\n    Args:\n        char (str): Character for which to retrieve key information.\n\n    Raises:\n        KeyError: Exception raised if the given character can't be typed (\n            because it doesn't exist on this keyboard layout).\n\n    Returns:\n        Width of the key for the requested character.\n        Height of the key for the requested character.\n        Center position (x-axis) of the key for the requested character.\n        Center position (y-axis) of the key for the requested character.\n        Keyboard layer ID where the character's key is located.\n    \"\"\"\n    k = self.keys_info[char]\n    return k.width, k.height, k.center[0], k.center[1], k.klayer_id\n</code></pre>"},{"location":"internals/#kebbie.layout.LayoutHelper.get_key","title":"<code>get_key(pos, klayer_id)</code>","text":"<p>Get the character associated with the given position.</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>Tuple[float, float]</code> <p>Position (x, y) in the keyboard.</p> required <code>klayer_id</code> <code>int</code> <p>Keyboard layer ID to use.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Character associated to the given position.</p> Source code in <code>kebbie/layout.py</code> <pre><code>def get_key(self, pos: Tuple[float, float], klayer_id: int) -&gt; str:\n    \"\"\"Get the character associated with the given position.\n\n    Args:\n        pos (Tuple[float, float]): Position (x, y) in the keyboard.\n        klayer_id (int): Keyboard layer ID to use.\n\n    Returns:\n        Character associated to the given position.\n    \"\"\"\n    klayer = self.klayers_info[klayer_id]\n\n    try:\n        # Retrieve the key that contains the sampled position\n        key = next(\n            k\n            for k in klayer\n            if k.bounds[\"left\"] &lt;= pos[0] &lt;= k.bounds[\"right\"] and k.bounds[\"top\"] &lt;= pos[1] &lt;= k.bounds[\"bottom\"]\n        )\n    except StopIteration:\n        # Maybe the sampled position was out of bound -&gt; retrieve the closest key\n        key = min(\n            klayer,\n            key=lambda k: euclidian_dist(\n                pos,\n                (\n                    k.bounds[\"left\"] + (k.bounds[\"right\"] - k.bounds[\"left\"]) / 2,\n                    k.bounds[\"top\"] + (k.bounds[\"bottom\"] - k.bounds[\"top\"]) / 2,\n                ),\n            ),\n        )\n\n    return key.char\n</code></pre>"},{"location":"internals/#noise_modelpy","title":"<code>noise_model.py</code>","text":"<p>Module defining the <code>NoiseModel</code> class, which takes care of introducing typos in a clean text (and later see if the model can properly correct these typos).</p>"},{"location":"internals/#kebbie.noise_model.Typo","title":"<code>Typo</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum listing all possible typos that can be introduced.</p> Source code in <code>kebbie/noise_model.py</code> <pre><code>class Typo(Enum):\n    \"\"\"Enum listing all possible typos that can be introduced.\"\"\"\n\n    # Deletions\n    DELETE_SPELLING_SYMBOL = \"DELETE_SPELLING_SYMBOL\"\n    DELETE_SPACE = \"DELETE_SPACE\"\n    DELETE_PUNCTUATION = \"DELETE_PUNCTUATION\"\n    DELETE_CHAR = \"DELETE_CHAR\"\n\n    # Additions\n    ADD_SPELLING_SYMBOL = \"ADD_SPELLING_SYMBOL\"\n    ADD_SPACE = \"ADD_SPACE\"\n    ADD_PUNCTUATION = \"ADD_PUNCTUATION\"\n    ADD_CHAR = \"ADD_CHAR\"\n\n    # Substitutions\n    SUBSTITUTE_CHAR = \"SUBSTITUTE_CHAR\"\n\n    # Simplifications\n    SIMPLIFY_ACCENT = \"SIMPLIFY_ACCENT\"\n    SIMPLIFY_CASE = \"SIMPLIFY_CASE\"\n\n    # Transposition\n    TRANSPOSE_CHAR = \"TRANSPOSE_CHAR\"\n\n    # Common typos\n    COMMON_TYPO = \"COMMON_TYPO\"\n</code></pre>"},{"location":"internals/#kebbie.noise_model.NoiseModel","title":"<code>NoiseModel</code>","text":"<p>Class responsible for introducing typo in a clean text.</p> <p>Most of typos are introduced on text directly. Then fuzzy typing is applied, using two Gaussian distributions (for x-axis and y-axis), mimicking a user typing on a soft keyboard.</p> <p>The ratio arguments are here to choose how wide the Gaussian distribution is. A wider distribution will be less precise, a narrower distribution will be more precise. To test how wide a ratio is, run the following code : <pre><code>from scipy.stats import norm\n\ndef compute(x):\n    cdf = norm.cdf(x)\n    return cdf - (1 - cdf)\n\nprint(compute(2.32))    # &gt;&gt;&gt; 0.9796591226625606\n</code></pre> So in this case, a ratio of <code>2.32</code> gives a precision of ~98% (a typo will be introduced in 2% of the cases).</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>Language used.</p> required <code>custom_keyboard</code> <code>Dict</code> <p>If provided, instead of relying on the keyboard layout provided by default, uses the given keyboard layout.</p> <code>None</code> <code>common_typos</code> <code>Optional[Dict[str, List[str]]]</code> <p>Dictionary of common typos. If <code>None</code>, common typos are not used.</p> <code>None</code> <code>typo_probs</code> <code>Optional[Dict[str, float]]</code> <p>Probabilities for each type of typos. If <code>None</code> is given, <code>DEFAULT_TYPO_PROBS</code> is used.</p> <code>None</code> <code>x_offset</code> <code>float</code> <p>Parameter for the Gaussian distribution for the fuzzy typing. Base position offset on the x-axis.</p> <code>0</code> <code>y_offset</code> <code>float</code> <p>Parameter for the Gaussian distribution for the fuzzy typing. Base position offset on the y-axis.</p> <code>0</code> <code>x_ratio</code> <code>float</code> <p>Parameter for the Gaussian distribution for the fuzzy typing. It controls how wide the distribution is on the x-axis, which is the precision of the typing.</p> <code>DEFAULT_SIGMA_RATIO</code> <code>y_ratio</code> <code>float</code> <p>Parameter for the Gaussian distribution for the fuzzy typing. It controls how wide the distribution is on the y-axis, which is the precision of the typing.</p> <code>DEFAULT_SIGMA_RATIO</code> Source code in <code>kebbie/noise_model.py</code> <pre><code>class NoiseModel:\n    \"\"\"Class responsible for introducing typo in a clean text.\n\n    Most of typos are introduced on text directly. Then fuzzy typing is\n    applied, using two Gaussian distributions (for x-axis and y-axis),\n    mimicking a user typing on a soft keyboard.\n\n    The ratio arguments are here to choose how wide the Gaussian distribution\n    is. A wider distribution will be less precise, a narrower distribution will\n    be more precise. To test how wide a ratio is, run the following code :\n    ```\n    from scipy.stats import norm\n\n    def compute(x):\n        cdf = norm.cdf(x)\n        return cdf - (1 - cdf)\n\n    print(compute(2.32))    # &gt;&gt;&gt; 0.9796591226625606\n    ```\n    So in this case, a ratio of `2.32` gives a precision of ~98% (a typo will\n    be introduced in 2% of the cases).\n\n    Args:\n        lang (str): Language used.\n        custom_keyboard (Dict, optional): If provided, instead of relying on\n            the keyboard layout provided by default, uses the given keyboard\n            layout.\n        common_typos (Optional[Dict[str, List[str]]], optional): Dictionary of\n            common typos. If `None`, common typos are not used.\n        typo_probs (Optional[Dict[str, float]], optional): Probabilities for\n            each type of typos. If `None` is given, `DEFAULT_TYPO_PROBS` is\n            used.\n        x_offset (float, optional): Parameter for the Gaussian distribution for\n            the fuzzy typing. Base position offset on the x-axis.\n        y_offset (float, optional): Parameter for the Gaussian distribution for\n            the fuzzy typing. Base position offset on the y-axis.\n        x_ratio (float, optional): Parameter for the Gaussian distribution for\n            the fuzzy typing. It controls how wide the distribution is on the\n            x-axis, which is the precision of the typing.\n        y_ratio (float, optional): Parameter for the Gaussian distribution for\n            the fuzzy typing. It controls how wide the distribution is on the\n            y-axis, which is the precision of the typing.\n    \"\"\"\n\n    def __init__(\n        self,\n        lang: str,\n        custom_keyboard: Dict = None,\n        common_typos: Optional[Dict[str, List[str]]] = None,\n        typo_probs: Optional[Dict[str, float]] = None,\n        x_offset: float = 0,\n        y_offset: float = 0,\n        x_ratio: float = DEFAULT_SIGMA_RATIO,\n        y_ratio: float = DEFAULT_SIGMA_RATIO,\n    ):\n        self.lang = lang\n        self.x_offset, self.y_offset = x_offset, y_offset\n        self.x_ratio, self.y_ratio = x_ratio, y_ratio\n        self.klayout = LayoutHelper(self.lang, custom_keyboard=custom_keyboard, ignore_layers_after=3)\n        self.probs = typo_probs if typo_probs is not None else DEFAULT_TYPO_PROBS\n        self.common_typos = common_typos if common_typos is not None else self._get_common_typos()\n\n    def type_till_space(\n        self,\n        words: List[str],\n    ) -&gt; Tuple[\n        List[Optional[Tuple[float, float]]],\n        str,\n        int,\n        List[Typo],\n    ]:\n        \"\"\"Method introducing typos word by word.\n\n        This method receives a list of words, and type these words while\n        introducing typos.\n        So most of the time, only one word will be typed and the method will\n        return. In some cases, the space is mistyped or deleted, so two words\n        are typed.\n\n        Args:\n            words (List[str]): List of words to type.\n\n        Returns:\n            List of keystrokes (may contains some None).\n            The typed characters as string.\n            The number of words typed.\n            The list of typos introduced in the string typed.\n        \"\"\"\n        all_keystrokes = []\n        all_typed_char = \"\"\n        all_typos = []\n\n        for i, word in enumerate(words):\n            # Some words can't be corrected (numbers, symbols, etc...) -&gt; Don't introduce typos\n            error_free = False if self._is_correctable(word) else True\n\n            # Add typos in the word\n            noisy_word, typos = self._introduce_typos(word, error_free=error_free)\n            all_typos += typos\n\n            # Type the word (fuzzy)\n            keystrokes, typed_char, typos = self._fuzzy_type(noisy_word, error_free=error_free)\n            all_keystrokes += keystrokes\n            all_typed_char += typed_char\n            all_typos += typos\n\n            # Then, we try to type a space (separator between words)\n            # TODO : Modify this part for languages without space\n            noisy_space, sp_typo_1 = self._introduce_typos(SPACE)\n            keystrokes, typed_char, sp_typo_2 = self._fuzzy_type(noisy_space)\n\n            # If the space is correctly typed, return now, otherwise type the next word\n            if not sp_typo_1 and not sp_typo_2:\n                break\n            else:\n                all_keystrokes += keystrokes\n                all_typed_char += typed_char\n                all_typos += sp_typo_1 + sp_typo_2\n\n        return all_keystrokes, all_typed_char, i + 1, all_typos\n\n    def swipe(self, word: str) -&gt; Optional[List[Tuple[float, float]]]:\n        \"\"\"Method for creating an artificial swipe gesture given a word.\n\n        Args:\n            word (str): Word to type with a swipe gesture.\n\n        Returns:\n            Positions (x, y) of the generated swipe gesture, or None if the\n                swipe gesture couldn't be created.\n        \"\"\"\n        # Some words can't be corrected (numbers, symbols, etc...) -&gt; Don't introduce typos\n        error_free = False if self._is_correctable(word) else True\n\n        # Get the core keystrokes (fuzzy)\n        keystrokes, *_ = self._fuzzy_type(word, error_free=error_free)\n\n        # If we can swipe that word, create the corresponding artificial gesture\n        if all(keystrokes) and len(keystrokes) &gt; 1:\n            return make_swipe_gesture(keystrokes)\n        else:\n            return None\n\n    def _introduce_typos(self, word: str, error_free: bool = False) -&gt; Tuple[str, List[Typo]]:  # noqa: C901\n        \"\"\"Method to introduce typos in a given string.\n\n        Either the word is changed into an existing common typo, or the word is\n        processed as a stream of characters, each character having a chance of\n        being mistyped.\n        This method only add regular typos (deletions, additions, etc...), and\n        is not introducing fuzzy typing.\n\n        Args:\n            word (str): Clean string where to add typos.\n            error_free (bool): If set to True, don't introduce typo. Defaults\n                to False.\n\n        Returns:\n            The noisy string.\n            The list of typos introduced.\n        \"\"\"\n        if error_free:\n            return word, []\n\n        # First of all, we either consider the word as a unit and introduce a\n        # language-specific common typo (if available), or treat the word as a\n        # sequence of character, where each character can have a typo\n        if word in self.common_typos and sample(self.probs[Typo.COMMON_TYPO]):\n            # Introduce a common typo\n            return random.choice(self.common_typos[word]), [Typo.COMMON_TYPO]\n\n        # From here, treat the word as a stream of characters, and potentially\n        # add typos for each character\n        noisy_word = \"\"\n        typos = []\n        word_chars = list(word)\n        for i, char in enumerate(word_chars):\n            # First, potentially apply simplifications (removing accent, or\n            # lowercasing an uppercase character)\n            # Note that if the full word is uppercase, we don't apply lowercase\n            # simplification (doesn't feel like a natural typo a user would do)\n            if char in self.klayout.letter_accents and sample(self.probs[Typo.SIMPLIFY_ACCENT]):\n                char = strip_accents(char)\n                typos.append(Typo.SIMPLIFY_ACCENT)\n            if char.isupper() and len(word) &gt; 1 and not word.isupper() and sample(self.probs[Typo.SIMPLIFY_CASE]):\n                char = char.lower()\n                typos.append(Typo.SIMPLIFY_CASE)\n\n            # Check if this character exists on our keyboard\n            try:\n                *_, klayer_id = self.klayout.get_key_info(char)\n                char_is_on_kb = True\n                char_is_on_default_kb = klayer_id == 0\n            except KeyError:\n                char_is_on_kb = char_is_on_default_kb = False\n\n            # Then, add the possible typo depending on the character type\n            events = []\n            is_first_char = bool(i == 0)\n            is_last_char = bool(i &gt;= (len(word_chars) - 1))\n            if char.isnumeric() or not char_is_on_kb:\n                # Don't introduce typos for numbers or symbols that are not on keyboard\n                pass\n            else:\n                if not is_last_char:\n                    # Only transpose char if they are on the same keyboard layer\n                    try:\n                        *_, next_char_klayer_id = self.klayout.get_key_info(word[i + 1])\n                    except KeyError:\n                        next_char_klayer_id = None\n\n                    if klayer_id == next_char_klayer_id:\n                        events.append(Typo.TRANSPOSE_CHAR)\n                if char in self.klayout.spelling_symbols:\n                    events.append(Typo.DELETE_SPELLING_SYMBOL)\n                    events.append(Typo.ADD_SPELLING_SYMBOL)\n                elif char.isspace():\n                    events.append(Typo.DELETE_SPACE)\n                    events.append(Typo.ADD_SPACE)\n                elif char in string.punctuation:\n                    events.append(Typo.DELETE_PUNCTUATION)\n                    events.append(Typo.ADD_PUNCTUATION)\n                elif char_is_on_default_kb:\n                    events.append(Typo.DELETE_CHAR)\n                    events.append(Typo.ADD_CHAR)\n\n            # If it's the last character (and we are not typing a space),\n            # don't add deletions typos, because it's an auto-completion case,\n            # not auto-correction\n            if is_last_char and word != SPACE:\n                events = [e for e in events if e not in DELETIONS]\n\n            # Get the probabilities for these possible events\n            typo_probs = {e: self.probs[e] for e in events}\n            if is_first_char:\n                # Deleting the first character of the word is not so common, update the probabilities accordingly\n                typo_probs = {e: p * FRONT_DELETION_MULTIPLIER if e in DELETIONS else p for e, p in typo_probs.items()}\n\n            # And sample one of them\n            typo = sample_among(typo_probs)\n\n            # Process the typo\n            if typo is Typo.TRANSPOSE_CHAR:\n                noisy_char = word_chars[i + 1]\n                word_chars[i + 1] = char\n            elif typo in [Typo.DELETE_SPELLING_SYMBOL, Typo.DELETE_SPACE, Typo.DELETE_PUNCTUATION, Typo.DELETE_CHAR]:\n                noisy_char = \"\"\n            elif typo in [Typo.ADD_SPELLING_SYMBOL, Typo.ADD_SPACE, Typo.ADD_PUNCTUATION, Typo.ADD_CHAR]:\n                noisy_char = f\"{char}{char}\"\n            else:  # No typo\n                noisy_char = char\n\n            noisy_word += noisy_char\n            if typo is not None:\n                typos.append(typo)\n\n        return noisy_word, typos\n\n    def _fuzzy_type(\n        self, word: str, error_free: bool = False\n    ) -&gt; Tuple[List[Optional[Tuple[float, float]]], str, List[Typo]]:\n        \"\"\"Method adding fuzzy typing.\n\n        This method takes a string (potentially already noisy from other type\n        of typos), and fuzzy-type it : simulate a user on a soft-keyboard.\n        This \"fat-finger syndrom\" is simulated using two Gaussian\n        distributions, one for each axis (x, y).\n        This method also returns the generated keystrokes (positions on the\n        keyboard), but only for the default keyboard (ID = 0). Keystrokes from\n        other keyboard are set to None.\n\n        Args:\n            word (str): String to fuzzy-type.\n            error_free (bool): If set to True, don't introduce typo. Defaults\n                to False.\n\n        Returns:\n            List of keystrokes.\n            Fuzzy string (corresponding to the keystrokes).\n            List of typos introduced.\n        \"\"\"\n        fuzzy_word = \"\"\n        keystrokes = []\n        typos = []\n\n        # Type word character by character\n        for char in word:\n            try:\n                width, height, x_center, y_center, klayer_id = self.klayout.get_key_info(char)\n            except KeyError:\n                # This character doesn't exist on the current keyboard\n                # Just type it without introducing typo, like if the user copy-pasted it\n                keystrokes.append(None)\n                fuzzy_word += char\n                continue\n\n            # Sample a keystroke for this character\n            # Note that we don't generate typos for characters outside of the default keyboard\n            if error_free or klayer_id != 0:\n                keystroke = (x_center, y_center)\n            else:\n                # Compute mu and sigma for the Normal distribution\n                x_mu = x_center + self.x_offset\n                y_mu = y_center + self.y_offset\n                x_sigma = (width / 2) / self.x_ratio\n                y_sigma = (height / 2) / self.y_ratio\n\n                # Sample a position (x and y)\n                keystroke = (random.gauss(x_mu, x_sigma), random.gauss(y_mu, y_sigma))\n\n            # Convert it back to a character, to see where we tapped\n            fuzzy_char = self.klayout.get_key(keystroke, klayer_id)\n\n            # Save it (save the keystroke only if part of the default keyboard)\n            keystrokes.append(keystroke if klayer_id == 0 else None)\n            fuzzy_word += fuzzy_char\n            if fuzzy_char != char:\n                typos.append(Typo.SUBSTITUTE_CHAR)\n\n        return keystrokes, fuzzy_word, typos\n\n    def _is_correctable(self, word: str) -&gt; bool:\n        \"\"\"Method returning True if we expect the given word to be corrected\n        upon typo introduction, False otherwise.\n\n        This is necessary to ensure we don't introduce typos in words that\n        can't be corrected, because if we do, it will be counted as error.\n\n        For now, are considered non-correctable :\n         * Words that don't contains any letter (from Unicode standard)\n\n        Args:\n            word (str): Word to classify as correctable or not.\n\n        Returns:\n            True if the word is correctable (and therefore we can introduce\n            typo), False otherwise.\n        \"\"\"\n        # Use the Unicode category `L` (see https://en.wikipedia.org/wiki/Unicode_character_property#General_Category)\n        return not bool(re.match(r\"^[^\\pL]+$\", word))\n\n    def _get_common_typos(self) -&gt; Dict[str, List[str]]:\n        \"\"\"Retrieve the list (if it exists) of plausible common typos to use\n        when introducing typos.\n\n        Returns:\n            Dictionary where the keys are the correct words and the values are\n                the associated possible typos for this word.\n        \"\"\"\n        plang = self.lang.split(\"-\")[0]\n        common_typos_cache_file = os.path.join(CACHE_DIR, f\"{plang}.json\")\n\n        # Try to access the cached common typos, and if it fails, it means we\n        # don't have it locally\n        try:\n            with open(common_typos_cache_file, \"r\") as f:\n                return json.load(f)\n        except FileNotFoundError:\n            pass\n\n        # File is not cached, download &amp; process the common typos from online\n        os.makedirs(os.path.dirname(common_typos_cache_file), exist_ok=True)\n        typos = defaultdict(list)\n        if plang == \"en\":\n            response = requests.get(TWEET_TYPO_CORPUS_URL)\n            for line in response.text.strip().split(\"\\n\"):\n                typoed_word, correct_word, *_ = line.split(\"\\t\")\n                typos[correct_word].append(typoed_word)\n        else:\n            return {}\n\n        # Save the retrieved typos in cache\n        with open(common_typos_cache_file, \"w\") as f:\n            json.dump(typos, f, indent=4)\n\n        return typos\n</code></pre>"},{"location":"internals/#kebbie.noise_model.NoiseModel.type_till_space","title":"<code>type_till_space(words)</code>","text":"<p>Method introducing typos word by word.</p> <p>This method receives a list of words, and type these words while introducing typos. So most of the time, only one word will be typed and the method will return. In some cases, the space is mistyped or deleted, so two words are typed.</p> <p>Parameters:</p> Name Type Description Default <code>words</code> <code>List[str]</code> <p>List of words to type.</p> required <p>Returns:</p> Type Description <code>List[Optional[Tuple[float, float]]]</code> <p>List of keystrokes (may contains some None).</p> <code>str</code> <p>The typed characters as string.</p> <code>int</code> <p>The number of words typed.</p> <code>List[Typo]</code> <p>The list of typos introduced in the string typed.</p> Source code in <code>kebbie/noise_model.py</code> <pre><code>def type_till_space(\n    self,\n    words: List[str],\n) -&gt; Tuple[\n    List[Optional[Tuple[float, float]]],\n    str,\n    int,\n    List[Typo],\n]:\n    \"\"\"Method introducing typos word by word.\n\n    This method receives a list of words, and type these words while\n    introducing typos.\n    So most of the time, only one word will be typed and the method will\n    return. In some cases, the space is mistyped or deleted, so two words\n    are typed.\n\n    Args:\n        words (List[str]): List of words to type.\n\n    Returns:\n        List of keystrokes (may contains some None).\n        The typed characters as string.\n        The number of words typed.\n        The list of typos introduced in the string typed.\n    \"\"\"\n    all_keystrokes = []\n    all_typed_char = \"\"\n    all_typos = []\n\n    for i, word in enumerate(words):\n        # Some words can't be corrected (numbers, symbols, etc...) -&gt; Don't introduce typos\n        error_free = False if self._is_correctable(word) else True\n\n        # Add typos in the word\n        noisy_word, typos = self._introduce_typos(word, error_free=error_free)\n        all_typos += typos\n\n        # Type the word (fuzzy)\n        keystrokes, typed_char, typos = self._fuzzy_type(noisy_word, error_free=error_free)\n        all_keystrokes += keystrokes\n        all_typed_char += typed_char\n        all_typos += typos\n\n        # Then, we try to type a space (separator between words)\n        # TODO : Modify this part for languages without space\n        noisy_space, sp_typo_1 = self._introduce_typos(SPACE)\n        keystrokes, typed_char, sp_typo_2 = self._fuzzy_type(noisy_space)\n\n        # If the space is correctly typed, return now, otherwise type the next word\n        if not sp_typo_1 and not sp_typo_2:\n            break\n        else:\n            all_keystrokes += keystrokes\n            all_typed_char += typed_char\n            all_typos += sp_typo_1 + sp_typo_2\n\n    return all_keystrokes, all_typed_char, i + 1, all_typos\n</code></pre>"},{"location":"internals/#kebbie.noise_model.NoiseModel.swipe","title":"<code>swipe(word)</code>","text":"<p>Method for creating an artificial swipe gesture given a word.</p> <p>Parameters:</p> Name Type Description Default <code>word</code> <code>str</code> <p>Word to type with a swipe gesture.</p> required <p>Returns:</p> Type Description <code>Optional[List[Tuple[float, float]]]</code> <p>Positions (x, y) of the generated swipe gesture, or None if the swipe gesture couldn't be created.</p> Source code in <code>kebbie/noise_model.py</code> <pre><code>def swipe(self, word: str) -&gt; Optional[List[Tuple[float, float]]]:\n    \"\"\"Method for creating an artificial swipe gesture given a word.\n\n    Args:\n        word (str): Word to type with a swipe gesture.\n\n    Returns:\n        Positions (x, y) of the generated swipe gesture, or None if the\n            swipe gesture couldn't be created.\n    \"\"\"\n    # Some words can't be corrected (numbers, symbols, etc...) -&gt; Don't introduce typos\n    error_free = False if self._is_correctable(word) else True\n\n    # Get the core keystrokes (fuzzy)\n    keystrokes, *_ = self._fuzzy_type(word, error_free=error_free)\n\n    # If we can swipe that word, create the corresponding artificial gesture\n    if all(keystrokes) and len(keystrokes) &gt; 1:\n        return make_swipe_gesture(keystrokes)\n    else:\n        return None\n</code></pre>"},{"location":"internals/#kebbie.noise_model.NoiseModel._introduce_typos","title":"<code>_introduce_typos(word, error_free=False)</code>","text":"<p>Method to introduce typos in a given string.</p> <p>Either the word is changed into an existing common typo, or the word is processed as a stream of characters, each character having a chance of being mistyped. This method only add regular typos (deletions, additions, etc...), and is not introducing fuzzy typing.</p> <p>Parameters:</p> Name Type Description Default <code>word</code> <code>str</code> <p>Clean string where to add typos.</p> required <code>error_free</code> <code>bool</code> <p>If set to True, don't introduce typo. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The noisy string.</p> <code>List[Typo]</code> <p>The list of typos introduced.</p> Source code in <code>kebbie/noise_model.py</code> <pre><code>def _introduce_typos(self, word: str, error_free: bool = False) -&gt; Tuple[str, List[Typo]]:  # noqa: C901\n    \"\"\"Method to introduce typos in a given string.\n\n    Either the word is changed into an existing common typo, or the word is\n    processed as a stream of characters, each character having a chance of\n    being mistyped.\n    This method only add regular typos (deletions, additions, etc...), and\n    is not introducing fuzzy typing.\n\n    Args:\n        word (str): Clean string where to add typos.\n        error_free (bool): If set to True, don't introduce typo. Defaults\n            to False.\n\n    Returns:\n        The noisy string.\n        The list of typos introduced.\n    \"\"\"\n    if error_free:\n        return word, []\n\n    # First of all, we either consider the word as a unit and introduce a\n    # language-specific common typo (if available), or treat the word as a\n    # sequence of character, where each character can have a typo\n    if word in self.common_typos and sample(self.probs[Typo.COMMON_TYPO]):\n        # Introduce a common typo\n        return random.choice(self.common_typos[word]), [Typo.COMMON_TYPO]\n\n    # From here, treat the word as a stream of characters, and potentially\n    # add typos for each character\n    noisy_word = \"\"\n    typos = []\n    word_chars = list(word)\n    for i, char in enumerate(word_chars):\n        # First, potentially apply simplifications (removing accent, or\n        # lowercasing an uppercase character)\n        # Note that if the full word is uppercase, we don't apply lowercase\n        # simplification (doesn't feel like a natural typo a user would do)\n        if char in self.klayout.letter_accents and sample(self.probs[Typo.SIMPLIFY_ACCENT]):\n            char = strip_accents(char)\n            typos.append(Typo.SIMPLIFY_ACCENT)\n        if char.isupper() and len(word) &gt; 1 and not word.isupper() and sample(self.probs[Typo.SIMPLIFY_CASE]):\n            char = char.lower()\n            typos.append(Typo.SIMPLIFY_CASE)\n\n        # Check if this character exists on our keyboard\n        try:\n            *_, klayer_id = self.klayout.get_key_info(char)\n            char_is_on_kb = True\n            char_is_on_default_kb = klayer_id == 0\n        except KeyError:\n            char_is_on_kb = char_is_on_default_kb = False\n\n        # Then, add the possible typo depending on the character type\n        events = []\n        is_first_char = bool(i == 0)\n        is_last_char = bool(i &gt;= (len(word_chars) - 1))\n        if char.isnumeric() or not char_is_on_kb:\n            # Don't introduce typos for numbers or symbols that are not on keyboard\n            pass\n        else:\n            if not is_last_char:\n                # Only transpose char if they are on the same keyboard layer\n                try:\n                    *_, next_char_klayer_id = self.klayout.get_key_info(word[i + 1])\n                except KeyError:\n                    next_char_klayer_id = None\n\n                if klayer_id == next_char_klayer_id:\n                    events.append(Typo.TRANSPOSE_CHAR)\n            if char in self.klayout.spelling_symbols:\n                events.append(Typo.DELETE_SPELLING_SYMBOL)\n                events.append(Typo.ADD_SPELLING_SYMBOL)\n            elif char.isspace():\n                events.append(Typo.DELETE_SPACE)\n                events.append(Typo.ADD_SPACE)\n            elif char in string.punctuation:\n                events.append(Typo.DELETE_PUNCTUATION)\n                events.append(Typo.ADD_PUNCTUATION)\n            elif char_is_on_default_kb:\n                events.append(Typo.DELETE_CHAR)\n                events.append(Typo.ADD_CHAR)\n\n        # If it's the last character (and we are not typing a space),\n        # don't add deletions typos, because it's an auto-completion case,\n        # not auto-correction\n        if is_last_char and word != SPACE:\n            events = [e for e in events if e not in DELETIONS]\n\n        # Get the probabilities for these possible events\n        typo_probs = {e: self.probs[e] for e in events}\n        if is_first_char:\n            # Deleting the first character of the word is not so common, update the probabilities accordingly\n            typo_probs = {e: p * FRONT_DELETION_MULTIPLIER if e in DELETIONS else p for e, p in typo_probs.items()}\n\n        # And sample one of them\n        typo = sample_among(typo_probs)\n\n        # Process the typo\n        if typo is Typo.TRANSPOSE_CHAR:\n            noisy_char = word_chars[i + 1]\n            word_chars[i + 1] = char\n        elif typo in [Typo.DELETE_SPELLING_SYMBOL, Typo.DELETE_SPACE, Typo.DELETE_PUNCTUATION, Typo.DELETE_CHAR]:\n            noisy_char = \"\"\n        elif typo in [Typo.ADD_SPELLING_SYMBOL, Typo.ADD_SPACE, Typo.ADD_PUNCTUATION, Typo.ADD_CHAR]:\n            noisy_char = f\"{char}{char}\"\n        else:  # No typo\n            noisy_char = char\n\n        noisy_word += noisy_char\n        if typo is not None:\n            typos.append(typo)\n\n    return noisy_word, typos\n</code></pre>"},{"location":"internals/#kebbie.noise_model.NoiseModel._fuzzy_type","title":"<code>_fuzzy_type(word, error_free=False)</code>","text":"<p>Method adding fuzzy typing.</p> <p>This method takes a string (potentially already noisy from other type of typos), and fuzzy-type it : simulate a user on a soft-keyboard. This \"fat-finger syndrom\" is simulated using two Gaussian distributions, one for each axis (x, y). This method also returns the generated keystrokes (positions on the keyboard), but only for the default keyboard (ID = 0). Keystrokes from other keyboard are set to None.</p> <p>Parameters:</p> Name Type Description Default <code>word</code> <code>str</code> <p>String to fuzzy-type.</p> required <code>error_free</code> <code>bool</code> <p>If set to True, don't introduce typo. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Optional[Tuple[float, float]]]</code> <p>List of keystrokes.</p> <code>str</code> <p>Fuzzy string (corresponding to the keystrokes).</p> <code>List[Typo]</code> <p>List of typos introduced.</p> Source code in <code>kebbie/noise_model.py</code> <pre><code>def _fuzzy_type(\n    self, word: str, error_free: bool = False\n) -&gt; Tuple[List[Optional[Tuple[float, float]]], str, List[Typo]]:\n    \"\"\"Method adding fuzzy typing.\n\n    This method takes a string (potentially already noisy from other type\n    of typos), and fuzzy-type it : simulate a user on a soft-keyboard.\n    This \"fat-finger syndrom\" is simulated using two Gaussian\n    distributions, one for each axis (x, y).\n    This method also returns the generated keystrokes (positions on the\n    keyboard), but only for the default keyboard (ID = 0). Keystrokes from\n    other keyboard are set to None.\n\n    Args:\n        word (str): String to fuzzy-type.\n        error_free (bool): If set to True, don't introduce typo. Defaults\n            to False.\n\n    Returns:\n        List of keystrokes.\n        Fuzzy string (corresponding to the keystrokes).\n        List of typos introduced.\n    \"\"\"\n    fuzzy_word = \"\"\n    keystrokes = []\n    typos = []\n\n    # Type word character by character\n    for char in word:\n        try:\n            width, height, x_center, y_center, klayer_id = self.klayout.get_key_info(char)\n        except KeyError:\n            # This character doesn't exist on the current keyboard\n            # Just type it without introducing typo, like if the user copy-pasted it\n            keystrokes.append(None)\n            fuzzy_word += char\n            continue\n\n        # Sample a keystroke for this character\n        # Note that we don't generate typos for characters outside of the default keyboard\n        if error_free or klayer_id != 0:\n            keystroke = (x_center, y_center)\n        else:\n            # Compute mu and sigma for the Normal distribution\n            x_mu = x_center + self.x_offset\n            y_mu = y_center + self.y_offset\n            x_sigma = (width / 2) / self.x_ratio\n            y_sigma = (height / 2) / self.y_ratio\n\n            # Sample a position (x and y)\n            keystroke = (random.gauss(x_mu, x_sigma), random.gauss(y_mu, y_sigma))\n\n        # Convert it back to a character, to see where we tapped\n        fuzzy_char = self.klayout.get_key(keystroke, klayer_id)\n\n        # Save it (save the keystroke only if part of the default keyboard)\n        keystrokes.append(keystroke if klayer_id == 0 else None)\n        fuzzy_word += fuzzy_char\n        if fuzzy_char != char:\n            typos.append(Typo.SUBSTITUTE_CHAR)\n\n    return keystrokes, fuzzy_word, typos\n</code></pre>"},{"location":"internals/#kebbie.noise_model.NoiseModel._is_correctable","title":"<code>_is_correctable(word)</code>","text":"<p>Method returning True if we expect the given word to be corrected upon typo introduction, False otherwise.</p> <p>This is necessary to ensure we don't introduce typos in words that can't be corrected, because if we do, it will be counted as error.</p> <p>For now, are considered non-correctable :  * Words that don't contains any letter (from Unicode standard)</p> <p>Parameters:</p> Name Type Description Default <code>word</code> <code>str</code> <p>Word to classify as correctable or not.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the word is correctable (and therefore we can introduce</p> <code>bool</code> <p>typo), False otherwise.</p> Source code in <code>kebbie/noise_model.py</code> <pre><code>def _is_correctable(self, word: str) -&gt; bool:\n    \"\"\"Method returning True if we expect the given word to be corrected\n    upon typo introduction, False otherwise.\n\n    This is necessary to ensure we don't introduce typos in words that\n    can't be corrected, because if we do, it will be counted as error.\n\n    For now, are considered non-correctable :\n     * Words that don't contains any letter (from Unicode standard)\n\n    Args:\n        word (str): Word to classify as correctable or not.\n\n    Returns:\n        True if the word is correctable (and therefore we can introduce\n        typo), False otherwise.\n    \"\"\"\n    # Use the Unicode category `L` (see https://en.wikipedia.org/wiki/Unicode_character_property#General_Category)\n    return not bool(re.match(r\"^[^\\pL]+$\", word))\n</code></pre>"},{"location":"internals/#kebbie.noise_model.NoiseModel._get_common_typos","title":"<code>_get_common_typos()</code>","text":"<p>Retrieve the list (if it exists) of plausible common typos to use when introducing typos.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dictionary where the keys are the correct words and the values are the associated possible typos for this word.</p> Source code in <code>kebbie/noise_model.py</code> <pre><code>def _get_common_typos(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Retrieve the list (if it exists) of plausible common typos to use\n    when introducing typos.\n\n    Returns:\n        Dictionary where the keys are the correct words and the values are\n            the associated possible typos for this word.\n    \"\"\"\n    plang = self.lang.split(\"-\")[0]\n    common_typos_cache_file = os.path.join(CACHE_DIR, f\"{plang}.json\")\n\n    # Try to access the cached common typos, and if it fails, it means we\n    # don't have it locally\n    try:\n        with open(common_typos_cache_file, \"r\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        pass\n\n    # File is not cached, download &amp; process the common typos from online\n    os.makedirs(os.path.dirname(common_typos_cache_file), exist_ok=True)\n    typos = defaultdict(list)\n    if plang == \"en\":\n        response = requests.get(TWEET_TYPO_CORPUS_URL)\n        for line in response.text.strip().split(\"\\n\"):\n            typoed_word, correct_word, *_ = line.split(\"\\t\")\n            typos[correct_word].append(typoed_word)\n    else:\n        return {}\n\n    # Save the retrieved typos in cache\n    with open(common_typos_cache_file, \"w\") as f:\n        json.dump(typos, f, indent=4)\n\n    return typos\n</code></pre>"},{"location":"internals/#oraclepy","title":"<code>oracle.py</code>","text":"<p>Module defining the <code>Oracle</code> class, which is the class taking care of iterating the dataset, introducing typos using the noise model, and querying the Corrector to correct these typos. Then the scorer is used to compute metrics about the performances, and the results are returned.</p>"},{"location":"internals/#kebbie.oracle.Oracle","title":"<code>Oracle</code>","text":"<p>Class that takes care of testing a Corrector. It basically gets clean text data, adds noise to it, send the noisy data to the Corrector, and scores its output.</p> <p>This class spawn multiple processes to decrease runtime.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>Language used.</p> required <code>test_data</code> <code>Dict[str, List[str]]</code> <p>List of clean sentences for each domain.</p> required <code>custom_keyboard</code> <code>Dict</code> <p>If provided, instead of relying on the keyboard layout provided by default, uses the given keyboard layout.</p> required <code>track_mistakes</code> <code>bool</code> <p>Set to <code>True</code> for tracking the most common mistakes. Most common mistakes are added to the results dictionary.</p> required <code>n_most_common_mistakes</code> <code>int</code> <p>If <code>track_mistakes</code> is set to <code>True</code>, the top X mistakes to record.</p> required <code>beta</code> <code>float</code> <p>Beta to use for computing the F-beta score.</p> required Source code in <code>kebbie/oracle.py</code> <pre><code>class Oracle:\n    \"\"\"Class that takes care of testing a Corrector. It basically gets clean\n    text data, adds noise to it, send the noisy data to the Corrector, and\n    scores its output.\n\n    This class spawn multiple processes to decrease runtime.\n\n    Args:\n        lang (str): Language used.\n        test_data (Dict[str, List[str]]): List of clean sentences for each\n            domain.\n        custom_keyboard (Dict): If provided, instead of relying on\n            the keyboard layout provided by default, uses the given keyboard\n            layout.\n        track_mistakes (bool): Set to `True` for tracking the most\n            common mistakes. Most common mistakes are added to the results\n            dictionary.\n        n_most_common_mistakes (int): If `track_mistakes` is set to\n            `True`, the top X mistakes to record.\n        beta (float): Beta to use for computing the F-beta score.\n    \"\"\"\n\n    def __init__(\n        self,\n        lang: str,\n        test_data: Dict[str, List[str]],\n        custom_keyboard: Dict,\n        track_mistakes: bool,\n        n_most_common_mistakes: int,\n        beta: float,\n    ) -&gt; None:\n        super().__init__()\n\n        self.lang = lang\n        self.data = test_data\n        self.custom_keyboard = custom_keyboard\n        self.track_mistakes = track_mistakes\n        self.n_most_common_mistakes = n_most_common_mistakes\n        self.beta = beta\n\n    def test(self, corrector: Union[Corrector, List[Corrector]], n_proc: Optional[int], seed: int) -&gt; Dict:\n        \"\"\"Main method, it tests the given Corrector, and returns results as a\n        dictionary.\n\n        This method spawn multiple processes to decrease runtime.\n\n        Args:\n            corrector (Union[Corrector, List[Corrector]]): Corrector to test.\n                If a list of Corrector is given, the argument `n_proc` is\n                ignored, and one corrector is assigned for each process.\n            n_proc (Optional[int]): Number of processes to use. If `None`,\n                `os.cpu_count()` is used.\n            seed (int): Seed to use for running the tests.\n\n        Returns:\n            Results formatted in a dictionary.\n        \"\"\"\n        # Initialize a global Scorer here, that will gather counts across processes\n        scorer = Scorer(domains=self.data.keys(), track_mistakes=self.track_mistakes)\n\n        # For multiprocessing\n        n_proc = n_proc if n_proc is not None else os.cpu_count()\n        d_size = sum(len(d) for d in self.data.values())\n\n        # Create the corrector for each process\n        proc_correctors = mp.Queue()\n        if isinstance(corrector, Corrector):\n            for _ in range(n_proc):\n                proc_correctors.put(corrector)\n        else:\n            # If we already have a list of correctors, assign one for each process\n            n_proc = len(corrector)\n            for c in corrector:\n                proc_correctors.put(c)\n\n        with mp.Pool(\n            processes=n_proc,\n            initializer=init_tester,\n            initargs=(tester, self.lang, self.custom_keyboard, proc_correctors, seed, self.track_mistakes),\n        ) as pool, tqdm(total=d_size) as pbar:\n            # Test data is made of several domain, where each domain contains a list of sentences\n            for domain, sentence_list in self.data.items():\n                chunk_size = max(min(CHUNK_SIZE, len(sentence_list) // n_proc), 1)\n                for scr in pool.imap_unordered(tester, sentence_list, chunksize=chunk_size):\n                    scr.set_domain(domain)\n                    scorer.add(scr)\n                    pbar.update(1)\n\n        # Retrieve the results\n        results = scorer.score(beta=self.beta)\n\n        # Then potentially add the most common mistakes\n        if self.track_mistakes:\n            mistakes = {}\n            for task in [\"nwp\", \"acp\", \"acr\"]:\n                task_name = {\"nwp\": \"next_word_prediction\", \"acp\": \"auto_completion\", \"acr\": \"auto_correction\"}[task]\n\n                m_count = getattr(scorer, f\"{task}_mistakes\")\n\n                mistakes[task_name] = [(\"Count\", \"Expected\", \"Predictions\", \"Context\")]\n                for m, c in m_count.most_common(self.n_most_common_mistakes):\n                    mistakes[task_name].append((c, m.actual, f\"[{', '.join(m.preds)}]\", m.context))\n\n            results[\"most_common_mistakes\"] = mistakes\n\n        return results\n</code></pre>"},{"location":"internals/#kebbie.oracle.Oracle.test","title":"<code>test(corrector, n_proc, seed)</code>","text":"<p>Main method, it tests the given Corrector, and returns results as a dictionary.</p> <p>This method spawn multiple processes to decrease runtime.</p> <p>Parameters:</p> Name Type Description Default <code>corrector</code> <code>Union[Corrector, List[Corrector]]</code> <p>Corrector to test. If a list of Corrector is given, the argument <code>n_proc</code> is ignored, and one corrector is assigned for each process.</p> required <code>n_proc</code> <code>Optional[int]</code> <p>Number of processes to use. If <code>None</code>, <code>os.cpu_count()</code> is used.</p> required <code>seed</code> <code>int</code> <p>Seed to use for running the tests.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Results formatted in a dictionary.</p> Source code in <code>kebbie/oracle.py</code> <pre><code>def test(self, corrector: Union[Corrector, List[Corrector]], n_proc: Optional[int], seed: int) -&gt; Dict:\n    \"\"\"Main method, it tests the given Corrector, and returns results as a\n    dictionary.\n\n    This method spawn multiple processes to decrease runtime.\n\n    Args:\n        corrector (Union[Corrector, List[Corrector]]): Corrector to test.\n            If a list of Corrector is given, the argument `n_proc` is\n            ignored, and one corrector is assigned for each process.\n        n_proc (Optional[int]): Number of processes to use. If `None`,\n            `os.cpu_count()` is used.\n        seed (int): Seed to use for running the tests.\n\n    Returns:\n        Results formatted in a dictionary.\n    \"\"\"\n    # Initialize a global Scorer here, that will gather counts across processes\n    scorer = Scorer(domains=self.data.keys(), track_mistakes=self.track_mistakes)\n\n    # For multiprocessing\n    n_proc = n_proc if n_proc is not None else os.cpu_count()\n    d_size = sum(len(d) for d in self.data.values())\n\n    # Create the corrector for each process\n    proc_correctors = mp.Queue()\n    if isinstance(corrector, Corrector):\n        for _ in range(n_proc):\n            proc_correctors.put(corrector)\n    else:\n        # If we already have a list of correctors, assign one for each process\n        n_proc = len(corrector)\n        for c in corrector:\n            proc_correctors.put(c)\n\n    with mp.Pool(\n        processes=n_proc,\n        initializer=init_tester,\n        initargs=(tester, self.lang, self.custom_keyboard, proc_correctors, seed, self.track_mistakes),\n    ) as pool, tqdm(total=d_size) as pbar:\n        # Test data is made of several domain, where each domain contains a list of sentences\n        for domain, sentence_list in self.data.items():\n            chunk_size = max(min(CHUNK_SIZE, len(sentence_list) // n_proc), 1)\n            for scr in pool.imap_unordered(tester, sentence_list, chunksize=chunk_size):\n                scr.set_domain(domain)\n                scorer.add(scr)\n                pbar.update(1)\n\n    # Retrieve the results\n    results = scorer.score(beta=self.beta)\n\n    # Then potentially add the most common mistakes\n    if self.track_mistakes:\n        mistakes = {}\n        for task in [\"nwp\", \"acp\", \"acr\"]:\n            task_name = {\"nwp\": \"next_word_prediction\", \"acp\": \"auto_completion\", \"acr\": \"auto_correction\"}[task]\n\n            m_count = getattr(scorer, f\"{task}_mistakes\")\n\n            mistakes[task_name] = [(\"Count\", \"Expected\", \"Predictions\", \"Context\")]\n            for m, c in m_count.most_common(self.n_most_common_mistakes):\n                mistakes[task_name].append((c, m.actual, f\"[{', '.join(m.preds)}]\", m.context))\n\n        results[\"most_common_mistakes\"] = mistakes\n\n    return results\n</code></pre>"},{"location":"internals/#kebbie.oracle.init_tester","title":"<code>init_tester(fn, lang, custom_keyboard, correctors, seed, track_mistakes)</code>","text":"<p>Function run at process initialization for Tester workers.</p> <p>Each worker in a Pool will run this function when created. It will instanciate several things needed for testing the given corrector :  * A Tokenizer to split sentences into words  * A NoiseModel to introduce typos  * A Corrector instance, which is the model we want to test</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>Main tester function (instanciated objects will be attached to this function).</p> required <code>lang</code> <code>str</code> <p>Language used.</p> required <code>custom_keyboard</code> <code>Dict</code> <p>If provided, instead of relying on the keyboard layout provided by default, uses the given keyboard layout.</p> required <code>correctors</code> <code>Queue</code> <p>Queue containing list of correctors to test. Each process will get the next corrector available in queue.</p> required <code>seed</code> <code>int</code> <p>Base seed to use.</p> required <code>track_mistakes</code> <code>bool</code> <p>Set to <code>True</code> for tracking the most common mistakes.</p> required Source code in <code>kebbie/oracle.py</code> <pre><code>def init_tester(\n    fn: Callable, lang: str, custom_keyboard: Dict, correctors: mp.Queue, seed: int, track_mistakes: bool\n) -&gt; None:\n    \"\"\"Function run at process initialization for Tester workers.\n\n    Each worker in a Pool will run this function when created. It will\n    instanciate several things needed for testing the given corrector :\n     * A Tokenizer to split sentences into words\n     * A NoiseModel to introduce typos\n     * A Corrector instance, which is the model we want to test\n\n    Args:\n        fn (Callable): Main tester function (instanciated objects will be\n            attached to this function).\n        lang (str): Language used.\n        custom_keyboard (Dict, optional): If provided, instead of relying on\n            the keyboard layout provided by default, uses the given keyboard\n            layout.\n        correctors (mp.Queue): Queue containing list of correctors to test.\n            Each process will get the next corrector available in queue.\n        seed (int): Base seed to use.\n        track_mistakes (bool): Set to `True` for tracking the most common\n            mistakes.\n    \"\"\"\n    fn.tokenizer = BasicTokenizer()\n    fn.noisy = NoiseModel(lang, custom_keyboard=custom_keyboard)\n    fn.corrector = correctors.get()\n    fn.base_seed = seed\n    fn.track_mistakes = track_mistakes\n</code></pre>"},{"location":"internals/#kebbie.oracle.tester","title":"<code>tester(sentence)</code>","text":"<p>Function to test a given sentence.</p> <p>It uses the noise model to introduce typos word by word, run the Corrector on various tasks (auto-completion, auto-correction, next-word prediction), and score the results.</p> <p>Parameters:</p> Name Type Description Default <code>sentence</code> <code>str</code> <p>Sentence to use as data for the test.</p> required <p>Returns:</p> Type Description <code>Scorer</code> <p>Scorer class with the prediction counts for this sentence.</p> Source code in <code>kebbie/oracle.py</code> <pre><code>def tester(sentence: str) -&gt; Scorer:\n    \"\"\"Function to test a given sentence.\n\n    It uses the noise model to introduce typos word by word, run the\n    Corrector on various tasks (auto-completion, auto-correction, next-word\n    prediction), and score the results.\n\n    Args:\n        sentence (str): Sentence to use as data for the test.\n\n    Returns:\n        Scorer class with the prediction counts for this sentence.\n    \"\"\"\n    # Set the seed for reproducibility, using the hash of the sentence\n    hsh = int(hashlib.sha256(sentence.encode(\"utf-8\")).hexdigest(), 16)\n    random.seed(tester.base_seed + hsh)\n    rnd_state = random.getstate()\n\n    # Tokenize the sentence into words\n    sentence = tester.tokenizer.preprocess(sentence)\n    words = tester.tokenizer.word_split(sentence)\n\n    context = \"\"\n    # Keep track for predictions counts with a local scorer, for this sentence\n    scorer = Scorer(domains=[None], track_mistakes=tester.track_mistakes)\n    while words and len(context) &lt; MAX_CHAR_PER_SENTENCE:\n        # Before randomly generating typo, set the random state for determinism\n        random.setstate(rnd_state)\n\n        # It's slow to generate swipe gesture every sentence, so run it just sometimes\n        word_to_swipe = words[0]\n        swipe_gesture = tester.noisy.swipe(word_to_swipe) if sample(SWIPE_PROB) else None\n\n        # Generate noisy keystrokes for the next word(s)\n        keystrokes, typed_word, n_word_typed, typos = tester.noisy.type_till_space(words)\n\n        # Get the clean word(s), update the remaining words to type and get the next word\n        actual_word = \" \".join(words[:n_word_typed])\n        words = words[n_word_typed:]\n        next_word = words[0] if len(words) &gt; 0 else None\n\n        # We are done with generating typo, save the random state for the next iteration\n        rnd_state = random.getstate()\n\n        if swipe_gesture:\n            # Call the swipe model\n            preds, memory, runtime = tester.corrector.profiled_resolve_swipe(context, swipe_gesture)\n            scorer.swp(word_to_swipe, preds, context=context, memory=memory, runtime=runtime)\n\n        # Call the model for auto-completion (for long enough words)\n        if len(typed_word) &gt; 1 and len(actual_word) &gt; 1:\n            partial_keystrokes, partial_word = sample_partial_word(keystrokes, typed_word, actual_word)\n            preds, memory, runtime = tester.corrector.profiled_auto_complete(context, partial_keystrokes, partial_word)\n            scorer.acp(actual_word, preds, partial_word=partial_word, context=context, memory=memory, runtime=runtime)\n\n        # Call the model for auto-correction\n        preds, memory, runtime = tester.corrector.profiled_auto_correct(context, keystrokes, typed_word)\n        scorer.acr(\n            actual_word, preds, typed_word=typed_word, context=context, typos=typos, memory=memory, runtime=runtime\n        )\n\n        # Update the context for the next iteration (input forcing)\n        context = tester.tokenizer.update_context(context, actual_word)\n\n        # Call the model for next-word prediction\n        if next_word:\n            preds, memory, runtime = tester.corrector.profiled_predict_next_word(context)\n            scorer.nwp(next_word, preds, context=context, memory=memory, runtime=runtime)\n\n    return scorer\n</code></pre>"},{"location":"internals/#scorerpy","title":"<code>scorer.py</code>","text":"<p>Module implementing <code>Scorer</code>, a class that keep track of how many errors the model is making, and output various corresponding metrics.</p>"},{"location":"internals/#kebbie.scorer.Count","title":"<code>Count</code>  <code>dataclass</code>","text":"<p>Structure representing the most basic counts for a task.</p> <p>It counts : * Number of correct predictions * Number of top3-correct predictions * Total number of predictions</p> Source code in <code>kebbie/scorer.py</code> <pre><code>@dataclass\nclass Count:\n    \"\"\"Structure representing the most basic counts for a task.\n\n    It counts :\n    * Number of correct predictions\n    * Number of top3-correct predictions\n    * Total number of predictions\n    \"\"\"\n\n    correct: int = 0  # Number of times the first prediction was correct\n    correct_3: int = 0  # Number of times one of the top-3 predictions was correct\n    total: int = 0  # Total number of predictions\n\n    def __add__(self, count: Count) -&gt; Count:\n        \"\"\"Merge two `Count` instance by adding their counts.\n\n        Args:\n            count (Count): Count instance to add.\n\n        Returns:\n            Merged Count.\n        \"\"\"\n        return Count(\n            correct=self.correct + count.correct,\n            correct_3=self.correct_3 + count.correct_3,\n            total=self.total + count.total,\n        )\n\n    def __mul__(self, proportion: float) -&gt; Count:\n        \"\"\"Multiply the current `Count` instance by a given proportion.\n\n        Args:\n            proportion (float): Proportion to multiply by.\n\n        Returns:\n            Count with the right proportion.\n        \"\"\"\n        return Count(\n            correct=round(self.correct * proportion),\n            correct_3=round(self.correct_3 * proportion),\n            total=round(self.total * proportion),\n        )\n</code></pre>"},{"location":"internals/#kebbie.scorer.Count.__add__","title":"<code>__add__(count)</code>","text":"<p>Merge two <code>Count</code> instance by adding their counts.</p> <p>Parameters:</p> Name Type Description Default <code>count</code> <code>Count</code> <p>Count instance to add.</p> required <p>Returns:</p> Type Description <code>Count</code> <p>Merged Count.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def __add__(self, count: Count) -&gt; Count:\n    \"\"\"Merge two `Count` instance by adding their counts.\n\n    Args:\n        count (Count): Count instance to add.\n\n    Returns:\n        Merged Count.\n    \"\"\"\n    return Count(\n        correct=self.correct + count.correct,\n        correct_3=self.correct_3 + count.correct_3,\n        total=self.total + count.total,\n    )\n</code></pre>"},{"location":"internals/#kebbie.scorer.Count.__mul__","title":"<code>__mul__(proportion)</code>","text":"<p>Multiply the current <code>Count</code> instance by a given proportion.</p> <p>Parameters:</p> Name Type Description Default <code>proportion</code> <code>float</code> <p>Proportion to multiply by.</p> required <p>Returns:</p> Type Description <code>Count</code> <p>Count with the right proportion.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def __mul__(self, proportion: float) -&gt; Count:\n    \"\"\"Multiply the current `Count` instance by a given proportion.\n\n    Args:\n        proportion (float): Proportion to multiply by.\n\n    Returns:\n        Count with the right proportion.\n    \"\"\"\n    return Count(\n        correct=round(self.correct * proportion),\n        correct_3=round(self.correct_3 * proportion),\n        total=round(self.total * proportion),\n    )\n</code></pre>"},{"location":"internals/#kebbie.scorer.Mistake","title":"<code>Mistake</code>  <code>dataclass</code>","text":"<p>Structure representing a mistake (including the context of the mistake, the expected word and the predictions).</p> Source code in <code>kebbie/scorer.py</code> <pre><code>@dataclass(eq=True, frozen=True)\nclass Mistake:\n    \"\"\"Structure representing a mistake (including the context of the mistake,\n    the expected word and the predictions).\n    \"\"\"\n\n    actual: str = field(compare=True)\n    preds: List[str] = field(compare=False)\n    context: str = field(compare=False)\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer","title":"<code>Scorer</code>","text":"<p>Class keeping track of the predictions and how correct they are, but also computing the associated score for each task after the end of test.</p> <p>Parameters:</p> Name Type Description Default <code>domains</code> <code>List[str]</code> <p>The list of domains in the dataset. The Scorer keeps track of the score for each domain, so that we can spot discrepancies between domain, if any.</p> required <code>human_readable</code> <code>bool</code> <p>If set to <code>False</code>, performance metrics (memory, runtime) are kept in their raw, numeral form. If set to <code>True</code>, these are converted to a human readable string.</p> <code>True</code> <code>track_mistakes</code> <code>bool</code> <p>Set to <code>True</code> for tracking the most common mistakes.</p> <code>False</code> Source code in <code>kebbie/scorer.py</code> <pre><code>class Scorer:\n    \"\"\"Class keeping track of the predictions and how correct they are, but\n    also computing the associated score for each task after the end of test.\n\n    Args:\n        domains (List[str]): The list of domains in the dataset. The Scorer\n            keeps track of the score for each domain, so that we can spot\n            discrepancies between domain, if any.\n        human_readable (bool, optional): If set to `False`, performance metrics\n            (memory, runtime) are kept in their raw, numeral form. If set to\n            `True`, these are converted to a human readable string.\n        track_mistakes (bool, optional): Set to `True` for tracking the most\n            common mistakes.\n    \"\"\"\n\n    def __init__(self, domains: List[str], human_readable: bool = True, track_mistakes: bool = False) -&gt; None:\n        self.human_readable = human_readable\n\n        # For each task, create a dictionary of Counts\n        # Each task has a different structure :\n\n        # Next-word prediction : [domain] -&gt; counts\n        self.nwp_c = dd_x_layers(1)\n\n        # Autocompletion : [domain] -&gt; [typo/no_typo] -&gt; [word_completion_rate] -&gt; counts\n        self.acp_c = dd_x_layers(3)\n\n        # Autocorrection : [domain] -&gt; [typo type/number of typo] -&gt; counts\n        self.acr_c = dd_x_layers(2)\n\n        # Swipe resolution : [domain] -&gt; counts\n        self.swp_c = dd_x_layers(1)\n\n        # Make sure we track each domain (create a 0-Count for each domain)\n        for d in domains:\n            _ = self.nwp_c[d], self.acp_c[d][WITH_TYPO][0], self.acr_c[d][None], self.swp_c[d]\n\n        # Also keep track of memories &amp; runtimes\n        self.nwp_memories = []\n        self.acp_memories = []\n        self.acr_memories = []\n        self.swp_memories = []\n        self.nwp_runtimes = []\n        self.acp_runtimes = []\n        self.acr_runtimes = []\n        self.swp_runtimes = []\n\n        # Optionally track common mistakes\n        self.track_mistakes = track_mistakes\n        self.nwp_mistakes = Counter()\n        self.acp_mistakes = Counter()\n        self.acr_mistakes = Counter()\n        self.swp_mistakes = Counter()\n\n    def add(self, scorer) -&gt; None:\n        \"\"\"Method to update the current Scorer with the counts from another\n        Scorer.\n\n        Args:\n            scorer (Scorer): Scorer to add.\n        \"\"\"\n\n        def update(d1, d2):\n            for k in d2:\n                if isinstance(d2[k], Count):\n                    d1[k] += d2[k]\n                else:\n                    update(d1[k], d2[k])\n\n        update(self.nwp_c, scorer.nwp_c)\n        update(self.acp_c, scorer.acp_c)\n        update(self.acr_c, scorer.acr_c)\n        update(self.swp_c, scorer.swp_c)\n        self.nwp_memories.extend(scorer.nwp_memories)\n        self.acp_memories.extend(scorer.acp_memories)\n        self.acr_memories.extend(scorer.acr_memories)\n        self.swp_memories.extend(scorer.swp_memories)\n        self.nwp_runtimes.extend(scorer.nwp_runtimes)\n        self.acp_runtimes.extend(scorer.acp_runtimes)\n        self.acr_runtimes.extend(scorer.acr_runtimes)\n        self.swp_runtimes.extend(scorer.swp_runtimes)\n        self.nwp_mistakes.update(scorer.nwp_mistakes)\n        self.acp_mistakes.update(scorer.acp_mistakes)\n        self.acr_mistakes.update(scorer.acr_mistakes)\n        self.swp_mistakes.update(scorer.swp_mistakes)\n\n    def nwp(\n        self,\n        true_word: str,\n        predicted_words: List[str],\n        context: str,\n        memory: int,\n        runtime: int,\n        domain: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Method used to record a prediction for the next-word prediction\n        task.\n\n        Args:\n            true_word (str): The label (clean word to predict).\n            predicted_words (List[str]): Predictions of the model.\n            context (str): The context (previous words in the sentence).\n            memory (int): Memory consumption for the call of the model.\n            runtime (int): Runtime for the call of the model.\n            domain (str): Domain of this prediction.\n        \"\"\"\n        # Record memory &amp; runtime\n        if memory &gt;= 0:\n            self.nwp_memories.append(memory)\n        if runtime &gt;= 0:\n            self.nwp_runtimes.append(runtime)\n\n        # Record counts\n        if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n            self.nwp_c[domain].correct += 1\n        if true_word in predicted_words[:3]:\n            self.nwp_c[domain].correct_3 += 1\n        else:\n            # If the word is not in the top-3 predictions, this is a mistake\n            if self.track_mistakes:\n                self.nwp_mistakes.update([Mistake(actual=true_word, preds=predicted_words[:3], context=context)])\n\n        self.nwp_c[domain].total += 1\n\n    def acp(\n        self,\n        true_word: str,\n        predicted_words: List[str],\n        partial_word: str,\n        context: str,\n        memory: int,\n        runtime: int,\n        domain: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Method used to record a prediction for the auto-completion task.\n\n        Args:\n            true_word (str): The label (clean word to predict).\n            predicted_words (List[str]): Predictions of the model.\n            partial_word (str): The input sent to the model (only part of the\n                word to predict, with potential typos).\n            context (str): The context (previous words in the sentence).\n            memory (int): Memory consumption for the call of the model.\n            runtime (int): Runtime for the call of the model.\n            domain (str): Domain of this prediction.\n        \"\"\"\n        # Record memory &amp; runtime\n        if memory &gt;= 0:\n            self.acp_memories.append(memory)\n        if runtime &gt;= 0:\n            self.acp_runtimes.append(runtime)\n\n        # Check if a typo was introduced or not\n        has_typo = WITHOUT_TYPO if true_word.startswith(partial_word) else WITH_TYPO\n\n        # Compute the completion rate\n        completion_rate = round(len(partial_word) / len(true_word), 2)\n\n        # Record counts\n        if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n            self.acp_c[domain][has_typo][completion_rate].correct += 1\n        if true_word in predicted_words[:3]:\n            self.acp_c[domain][has_typo][completion_rate].correct_3 += 1\n        else:\n            # If the word is not in the top-3 predictions, this is a mistake\n            if self.track_mistakes:\n                self.acp_mistakes.update(\n                    [Mistake(actual=true_word, preds=predicted_words[:3], context=f\"{context}{partial_word}\")]\n                )\n\n        self.acp_c[domain][has_typo][completion_rate].total += 1\n\n    def acr(\n        self,\n        true_word: str,\n        predicted_words: List[str],\n        typed_word: str,\n        context: str,\n        typos: List[Typo],\n        memory: int,\n        runtime: int,\n        domain: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Method used to record a prediction for the auto-correction task.\n\n        Args:\n            true_word (str): The label (clean word to predict).\n            predicted_words (List[str]): Predictions of the model.\n            typed_word (str): The word typed, containing potential typos.\n            context (str): The context (previous words in the sentence).\n            typos (List[Typo]): List of typos introduced.\n            memory (int): Memory consumption for the call of the model.\n            runtime (int): Runtime for the call of the model.\n            domain (str): Domain of this prediction.\n        \"\"\"\n        # Record memory &amp; runtime\n        if memory &gt;= 0:\n            self.acr_memories.append(memory)\n        if runtime &gt;= 0:\n            self.acr_runtimes.append(runtime)\n\n        # Get the type of typo\n        if not typos:\n            typo_type = None\n        elif len(typos) == 1:\n            typo_type = typos[0]\n        else:\n            typo_type = len(typos)\n\n        # Record counts\n        if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n            self.acr_c[domain][typo_type].correct += 1\n        if true_word in predicted_words[:3]:\n            self.acr_c[domain][typo_type].correct_3 += 1\n        else:\n            # If the word is not in the top-3 predictions, this is a mistake\n            if self.track_mistakes:\n                self.acr_mistakes.update(\n                    [Mistake(actual=true_word, preds=predicted_words[:3], context=f\"{context}{typed_word}\")]\n                )\n\n        self.acr_c[domain][typo_type].total += 1\n\n    def swp(\n        self,\n        true_word: str,\n        predicted_words: List[str],\n        context: str,\n        memory: int,\n        runtime: int,\n        domain: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Method used to record a prediction for the swipe resolution task.\n\n        Args:\n            true_word (str): The label (clean word to predict).\n            predicted_words (List[str]): Predictions of the model.\n            context (str): The context (previous words in the sentence).\n            memory (int): Memory consumption for the call of the model.\n            runtime (int): Runtime for the call of the model.\n            domain (str): Domain of this prediction.\n        \"\"\"\n        # Record memory &amp; runtime\n        if memory &gt;= 0:\n            self.swp_memories.append(memory)\n        if runtime &gt;= 0:\n            self.swp_runtimes.append(runtime)\n\n        # Record counts\n        if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n            self.swp_c[domain].correct += 1\n        if true_word in predicted_words[:3]:\n            self.swp_c[domain].correct_3 += 1\n        else:\n            # If the word is not in the top-3 predictions, this is a mistake\n            if self.track_mistakes:\n                self.swp_mistakes.update([Mistake(actual=true_word, preds=predicted_words[:3], context=context)])\n\n        self.swp_c[domain].total += 1\n\n    def set_domain(self, domain: str) -&gt; None:\n        \"\"\"Method setting the domain for the scores associated with no domain.\n\n        To make it easier to score a single sentence, it's possible to call the\n        scorer without a domain (see signature of `nwp()`, `acp()`, `acr()`).\n        In this case the scores are associated to no domain (`None` key).\n        This method allows the user to set the domain name for these scores\n        with no domain (effectively moving the `None` domain scores to the\n        given domain name).\n\n        Note:\n            If some scores were already linked to the given domain, these\n            scores will be erased (replaced by the scores of the `None`\n            domain).\n\n        Args:\n            domain (str): Domain name to associate the scores to.\n        \"\"\"\n        if None in self.nwp_c:\n            self.nwp_c[domain] = self.nwp_c.pop(None)\n        if None in self.acp_c:\n            self.acp_c[domain] = self.acp_c.pop(None)\n        if None in self.acr_c:\n            self.acr_c[domain] = self.acr_c.pop(None)\n        if None in self.swp_c:\n            self.swp_c[domain] = self.swp_c.pop(None)\n\n    def _score_accuracy(self, c: Count) -&gt; Dict:\n        \"\"\"Helper method to compute the accuracy given a prediction count.\n\n        This method return a dictionary with 3 metrics :\n         * Accuracy\n         * Top3 accuracy\n         * Total number of predictions\n\n        Args:\n            c (Count): Count object to use to compute the accuracy.\n\n        Returns:\n            Dictionary with the computed metrics.\n        \"\"\"\n        return {\n            \"accuracy\": round_to_n(c.correct / c.total) if c.total != 0 else 0,\n            \"top3_accuracy\": round_to_n(c.correct_3 / c.total) if c.total != 0 else 0,\n            \"n\": c.total,\n        }\n\n    def _score_precision_recall(self, no_typo_c: Count, typo_c: Count, beta: float) -&gt; Dict:\n        \"\"\"Helper method to compute the precision and recall for\n        auto-correction.\n\n        This method return a dictionary with several metrics :\n         * Accuracy\n         * Precision\n         * Recall\n         * F-score\n         * Top3 accuracy\n         * Top3 precision\n         * Top3 recall\n         * Top3 F-score\n         * Number of predictions with a typo\n         * Total number of predictions\n\n        For auto-correction, we need 2 Count objects : the counts of typos, and\n        the counts of non-typo (to compute the True Negative and False Positive\n        metrics).\n\n        Args:\n            no_typo_c (Count): Count object for the predictions where no typo\n                were added.\n            typo_c (Count): Count object for the predictions where typos were\n                added.\n            beta (float): Beta to use for computing the F-beta score.\n\n        Returns:\n            Dictionary with the computed metrics.\n        \"\"\"\n        # The first step is to divide the counts into TN, FP, TP, FN\n        tn = no_typo_c.correct\n        fp = no_typo_c.total - no_typo_c.correct\n        tp = typo_c.correct\n        fn = typo_c.total - typo_c.correct\n\n        tn_3 = no_typo_c.correct_3\n        fp_3 = no_typo_c.total - no_typo_c.correct_3\n        tp_3 = typo_c.correct_3\n        fn_3 = typo_c.total - typo_c.correct_3\n\n        # Then we compute the metrics\n        p = precision(tp=tp, fp=fp)\n        r = recall(tp=tp, fn=fn)\n\n        p_3 = precision(tp=tp_3, fp=fp_3)\n        r_3 = recall(tp=tp_3, fn=fn_3)\n\n        return {\n            \"accuracy\": round_to_n(accuracy(tp=tp, tn=tn, fp=fp, fn=fn)),\n            \"precision\": round_to_n(p),\n            \"recall\": round_to_n(r),\n            \"fscore\": round_to_n(fbeta(precision=p, recall=r, beta=beta)),\n            \"top3_accuracy\": round_to_n(accuracy(tp=tp_3, tn=tn_3, fp=fp_3, fn=fn_3)),\n            \"top3_precision\": round_to_n(p_3),\n            \"top3_recall\": round_to_n(r_3),\n            \"top3_fscore\": round_to_n(fbeta(precision=p_3, recall=r_3, beta=beta)),\n            \"n_typo\": typo_c.total,\n            \"n\": no_typo_c.total + typo_c.total,\n        }\n\n    def _score_performances(self, memories: List[int], runtimes: List[int]) -&gt; Dict:\n        \"\"\"Helper method to compute metrics related to the memory &amp; runtime.\n\n        This method returns a dictionary with several metrics :\n         * The mean memory consumption\n         * The min memory consumption\n         * The max memory consumption\n         * The mean running time\n         * The fastest running time\n         * The slowest running time\n\n        Args:\n            memories (List[int]): List of memories consumptions for a\n                specific operation.\n            runtimes (List[int]): List of runtimes for a specific operation.\n\n        Returns:\n            Dictionary with the computed metrics.\n        \"\"\"\n        perf = {\n            \"mean_memory\": stats.mean(memories) if memories else 0,\n            \"min_memory\": min(memories) if memories else 0,\n            \"max_memory\": max(memories) if memories else 0,\n            \"mean_runtime\": stats.mean(runtimes) if runtimes else 0,\n            \"fastest_runtime\": min(runtimes) if runtimes else 0,\n            \"slowest_runtime\": max(runtimes) if runtimes else 0,\n        }\n\n        if self.human_readable:\n            perf = {\n                name: human_readable_memory(x) if name.endswith(\"memory\") else human_readable_runtime(x)\n                for name, x in perf.items()\n            }\n\n        return perf\n\n    def score(self, beta: float = DEFAULT_BETA) -&gt; Dict:  # noqa: C901\n        \"\"\"Method that computes the final scores (as well as some alternative\n        metrics that can bring insight in the capabilities of the model), and\n        output these in an organized dictionary.\n\n        Args:\n            beta (float, optional): Beta to use for computing the F-beta score.\n\n        Returns:\n            Dictionary containing the computed scores and metrics for the\n            model tested.\n        \"\"\"\n        # --- Next-word prediction ---\n        # Group scores by domain\n        per = defaultdict(Count)\n        for domain, c in self.nwp_c.items():\n            per[domain] += c\n        total_c = sum(per.values(), Count())\n        per_domain = {k: self._score_accuracy(c) for k, c in per.items()}\n\n        # Task results\n        nwp = {\n            \"score\": self._score_accuracy(total_c),\n            \"per_domain\": per_domain,\n            \"performances\": self._score_performances(self.nwp_memories, self.nwp_runtimes),\n        }\n\n        # --- Auto-completion ---\n        # Group scores by domain\n        per = defaultdict(Count)\n        for domain, d1 in self.acp_c.items():\n            for has_typo, d2 in d1.items():\n                for compl_rate, c in d2.items():\n                    per[domain] += c\n        total_c = sum(per.values(), Count())\n        per_domain = {k: self._score_accuracy(c) for k, c in per.items()}\n\n        # Group scores by completion rate\n        per = defaultdict(Count)\n        for domain, d1 in self.acp_c.items():\n            for has_typo, d2 in d1.items():\n                for compl_rate, c in d2.items():\n                    per[compl_rate] += c\n        per_compl_rate = {\n            \"&lt;25%\": self._score_accuracy(sum((c for k, c in per.items() if k &lt; 0.25), Count())),\n            \"25%~50%\": self._score_accuracy(sum((c for k, c in per.items() if 0.25 &lt;= k &lt; 0.5), Count())),\n            \"50%~75%\": self._score_accuracy(sum((c for k, c in per.items() if 0.5 &lt;= k &lt; 0.75), Count())),\n            \"&gt;75%\": self._score_accuracy(sum((c for k, c in per.items() if 0.75 &lt;= k), Count())),\n        }\n\n        # Group scores by with_typo / without_typo\n        per = defaultdict(Count)\n        for domain, d1 in self.acp_c.items():\n            for has_typo, d2 in d1.items():\n                for compl_rate, c in d2.items():\n                    per[has_typo] += c\n        per_other = {k: self._score_accuracy(per[k]) for k in [WITHOUT_TYPO, WITH_TYPO]}\n\n        # Task results\n        acp = {\n            \"score\": self._score_accuracy(total_c),\n            \"per_domain\": per_domain,\n            \"per_completion_rate\": per_compl_rate,\n            \"per_other\": per_other,\n            \"performances\": self._score_performances(self.acp_memories, self.acp_runtimes),\n        }\n\n        # --- Auto-correction ---\n        # Group scores by domain\n        no_typo_per, typo_per = defaultdict(Count), defaultdict(Count)\n        for domain, d1 in self.acr_c.items():\n            for typo, c in d1.items():\n                if typo is None:\n                    no_typo_per[domain] += c\n                else:\n                    typo_per[domain] += c\n        no_typo_total_c = sum(no_typo_per.values(), Count())\n        typo_total_c = sum(typo_per.values(), Count())\n        per_domain = {k: self._score_precision_recall(no_typo_per[k], typo_per[k], beta=beta) for k in no_typo_per}\n\n        # Group scores by typo type\n        no_typo_c, typo_per = Count(), defaultdict(Count)\n        for domain, d1 in self.acr_c.items():\n            for typo, c in d1.items():\n                if typo is None:\n                    no_typo_c += c\n                else:\n                    typo_per[typo] += c\n        # Divide the total count of no-typo into each type of typos with the right proportions\n        no_typo_per = defaultdict(Count, {k: no_typo_c * (c.total / typo_total_c.total) for k, c in typo_per.items()})\n        per_typo_type = {t.name: self._score_precision_recall(no_typo_per[t], typo_per[t], beta=beta) for t in Typo}\n        per_n_typo = {\n            \"1\": self._score_precision_recall(\n                sum((c for k, c in no_typo_per.items() if isinstance(k, Typo)), Count()),\n                sum((c for k, c in typo_per.items() if isinstance(k, Typo)), Count()),\n                beta=beta,\n            ),\n            \"2\": self._score_precision_recall(no_typo_per[2], typo_per[2], beta=beta),\n            \"3+\": self._score_precision_recall(\n                sum((c for k, c in no_typo_per.items() if isinstance(k, int) and k &gt; 2), Count()),\n                sum((c for k, c in typo_per.items() if isinstance(k, int) and k &gt; 2), Count()),\n                beta=beta,\n            ),\n        }\n\n        # Task results\n        acr = {\n            \"score\": self._score_precision_recall(no_typo_total_c, typo_total_c, beta=beta),\n            \"per_domain\": per_domain,\n            \"per_typo_type\": per_typo_type,\n            \"per_number_of_typos\": per_n_typo,\n            \"performances\": self._score_performances(self.acr_memories, self.acr_runtimes),\n        }\n\n        # --- Swipe resolution ---\n        # Group scores by domain\n        per = defaultdict(Count)\n        for domain, c in self.swp_c.items():\n            per[domain] += c\n        total_c = sum(per.values(), Count())\n        per_domain = {k: self._score_accuracy(c) for k, c in per.items()}\n\n        # Task results\n        swp = {\n            \"score\": self._score_accuracy(total_c),\n            \"per_domain\": per_domain,\n            \"performances\": self._score_performances(self.swp_memories, self.swp_runtimes),\n        }\n\n        # Final results\n        results = {\n            \"next_word_prediction\": nwp,\n            \"auto_completion\": acp,\n            \"auto_correction\": acr,\n            \"swipe_resolution\": swp,\n        }\n\n        # Add the overall score\n        results[\"overall_score\"] = one_score(results)\n\n        return results\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer.add","title":"<code>add(scorer)</code>","text":"<p>Method to update the current Scorer with the counts from another Scorer.</p> <p>Parameters:</p> Name Type Description Default <code>scorer</code> <code>Scorer</code> <p>Scorer to add.</p> required Source code in <code>kebbie/scorer.py</code> <pre><code>def add(self, scorer) -&gt; None:\n    \"\"\"Method to update the current Scorer with the counts from another\n    Scorer.\n\n    Args:\n        scorer (Scorer): Scorer to add.\n    \"\"\"\n\n    def update(d1, d2):\n        for k in d2:\n            if isinstance(d2[k], Count):\n                d1[k] += d2[k]\n            else:\n                update(d1[k], d2[k])\n\n    update(self.nwp_c, scorer.nwp_c)\n    update(self.acp_c, scorer.acp_c)\n    update(self.acr_c, scorer.acr_c)\n    update(self.swp_c, scorer.swp_c)\n    self.nwp_memories.extend(scorer.nwp_memories)\n    self.acp_memories.extend(scorer.acp_memories)\n    self.acr_memories.extend(scorer.acr_memories)\n    self.swp_memories.extend(scorer.swp_memories)\n    self.nwp_runtimes.extend(scorer.nwp_runtimes)\n    self.acp_runtimes.extend(scorer.acp_runtimes)\n    self.acr_runtimes.extend(scorer.acr_runtimes)\n    self.swp_runtimes.extend(scorer.swp_runtimes)\n    self.nwp_mistakes.update(scorer.nwp_mistakes)\n    self.acp_mistakes.update(scorer.acp_mistakes)\n    self.acr_mistakes.update(scorer.acr_mistakes)\n    self.swp_mistakes.update(scorer.swp_mistakes)\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer.nwp","title":"<code>nwp(true_word, predicted_words, context, memory, runtime, domain=None)</code>","text":"<p>Method used to record a prediction for the next-word prediction task.</p> <p>Parameters:</p> Name Type Description Default <code>true_word</code> <code>str</code> <p>The label (clean word to predict).</p> required <code>predicted_words</code> <code>List[str]</code> <p>Predictions of the model.</p> required <code>context</code> <code>str</code> <p>The context (previous words in the sentence).</p> required <code>memory</code> <code>int</code> <p>Memory consumption for the call of the model.</p> required <code>runtime</code> <code>int</code> <p>Runtime for the call of the model.</p> required <code>domain</code> <code>str</code> <p>Domain of this prediction.</p> <code>None</code> Source code in <code>kebbie/scorer.py</code> <pre><code>def nwp(\n    self,\n    true_word: str,\n    predicted_words: List[str],\n    context: str,\n    memory: int,\n    runtime: int,\n    domain: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Method used to record a prediction for the next-word prediction\n    task.\n\n    Args:\n        true_word (str): The label (clean word to predict).\n        predicted_words (List[str]): Predictions of the model.\n        context (str): The context (previous words in the sentence).\n        memory (int): Memory consumption for the call of the model.\n        runtime (int): Runtime for the call of the model.\n        domain (str): Domain of this prediction.\n    \"\"\"\n    # Record memory &amp; runtime\n    if memory &gt;= 0:\n        self.nwp_memories.append(memory)\n    if runtime &gt;= 0:\n        self.nwp_runtimes.append(runtime)\n\n    # Record counts\n    if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n        self.nwp_c[domain].correct += 1\n    if true_word in predicted_words[:3]:\n        self.nwp_c[domain].correct_3 += 1\n    else:\n        # If the word is not in the top-3 predictions, this is a mistake\n        if self.track_mistakes:\n            self.nwp_mistakes.update([Mistake(actual=true_word, preds=predicted_words[:3], context=context)])\n\n    self.nwp_c[domain].total += 1\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer.acp","title":"<code>acp(true_word, predicted_words, partial_word, context, memory, runtime, domain=None)</code>","text":"<p>Method used to record a prediction for the auto-completion task.</p> <p>Parameters:</p> Name Type Description Default <code>true_word</code> <code>str</code> <p>The label (clean word to predict).</p> required <code>predicted_words</code> <code>List[str]</code> <p>Predictions of the model.</p> required <code>partial_word</code> <code>str</code> <p>The input sent to the model (only part of the word to predict, with potential typos).</p> required <code>context</code> <code>str</code> <p>The context (previous words in the sentence).</p> required <code>memory</code> <code>int</code> <p>Memory consumption for the call of the model.</p> required <code>runtime</code> <code>int</code> <p>Runtime for the call of the model.</p> required <code>domain</code> <code>str</code> <p>Domain of this prediction.</p> <code>None</code> Source code in <code>kebbie/scorer.py</code> <pre><code>def acp(\n    self,\n    true_word: str,\n    predicted_words: List[str],\n    partial_word: str,\n    context: str,\n    memory: int,\n    runtime: int,\n    domain: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Method used to record a prediction for the auto-completion task.\n\n    Args:\n        true_word (str): The label (clean word to predict).\n        predicted_words (List[str]): Predictions of the model.\n        partial_word (str): The input sent to the model (only part of the\n            word to predict, with potential typos).\n        context (str): The context (previous words in the sentence).\n        memory (int): Memory consumption for the call of the model.\n        runtime (int): Runtime for the call of the model.\n        domain (str): Domain of this prediction.\n    \"\"\"\n    # Record memory &amp; runtime\n    if memory &gt;= 0:\n        self.acp_memories.append(memory)\n    if runtime &gt;= 0:\n        self.acp_runtimes.append(runtime)\n\n    # Check if a typo was introduced or not\n    has_typo = WITHOUT_TYPO if true_word.startswith(partial_word) else WITH_TYPO\n\n    # Compute the completion rate\n    completion_rate = round(len(partial_word) / len(true_word), 2)\n\n    # Record counts\n    if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n        self.acp_c[domain][has_typo][completion_rate].correct += 1\n    if true_word in predicted_words[:3]:\n        self.acp_c[domain][has_typo][completion_rate].correct_3 += 1\n    else:\n        # If the word is not in the top-3 predictions, this is a mistake\n        if self.track_mistakes:\n            self.acp_mistakes.update(\n                [Mistake(actual=true_word, preds=predicted_words[:3], context=f\"{context}{partial_word}\")]\n            )\n\n    self.acp_c[domain][has_typo][completion_rate].total += 1\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer.acr","title":"<code>acr(true_word, predicted_words, typed_word, context, typos, memory, runtime, domain=None)</code>","text":"<p>Method used to record a prediction for the auto-correction task.</p> <p>Parameters:</p> Name Type Description Default <code>true_word</code> <code>str</code> <p>The label (clean word to predict).</p> required <code>predicted_words</code> <code>List[str]</code> <p>Predictions of the model.</p> required <code>typed_word</code> <code>str</code> <p>The word typed, containing potential typos.</p> required <code>context</code> <code>str</code> <p>The context (previous words in the sentence).</p> required <code>typos</code> <code>List[Typo]</code> <p>List of typos introduced.</p> required <code>memory</code> <code>int</code> <p>Memory consumption for the call of the model.</p> required <code>runtime</code> <code>int</code> <p>Runtime for the call of the model.</p> required <code>domain</code> <code>str</code> <p>Domain of this prediction.</p> <code>None</code> Source code in <code>kebbie/scorer.py</code> <pre><code>def acr(\n    self,\n    true_word: str,\n    predicted_words: List[str],\n    typed_word: str,\n    context: str,\n    typos: List[Typo],\n    memory: int,\n    runtime: int,\n    domain: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Method used to record a prediction for the auto-correction task.\n\n    Args:\n        true_word (str): The label (clean word to predict).\n        predicted_words (List[str]): Predictions of the model.\n        typed_word (str): The word typed, containing potential typos.\n        context (str): The context (previous words in the sentence).\n        typos (List[Typo]): List of typos introduced.\n        memory (int): Memory consumption for the call of the model.\n        runtime (int): Runtime for the call of the model.\n        domain (str): Domain of this prediction.\n    \"\"\"\n    # Record memory &amp; runtime\n    if memory &gt;= 0:\n        self.acr_memories.append(memory)\n    if runtime &gt;= 0:\n        self.acr_runtimes.append(runtime)\n\n    # Get the type of typo\n    if not typos:\n        typo_type = None\n    elif len(typos) == 1:\n        typo_type = typos[0]\n    else:\n        typo_type = len(typos)\n\n    # Record counts\n    if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n        self.acr_c[domain][typo_type].correct += 1\n    if true_word in predicted_words[:3]:\n        self.acr_c[domain][typo_type].correct_3 += 1\n    else:\n        # If the word is not in the top-3 predictions, this is a mistake\n        if self.track_mistakes:\n            self.acr_mistakes.update(\n                [Mistake(actual=true_word, preds=predicted_words[:3], context=f\"{context}{typed_word}\")]\n            )\n\n    self.acr_c[domain][typo_type].total += 1\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer.swp","title":"<code>swp(true_word, predicted_words, context, memory, runtime, domain=None)</code>","text":"<p>Method used to record a prediction for the swipe resolution task.</p> <p>Parameters:</p> Name Type Description Default <code>true_word</code> <code>str</code> <p>The label (clean word to predict).</p> required <code>predicted_words</code> <code>List[str]</code> <p>Predictions of the model.</p> required <code>context</code> <code>str</code> <p>The context (previous words in the sentence).</p> required <code>memory</code> <code>int</code> <p>Memory consumption for the call of the model.</p> required <code>runtime</code> <code>int</code> <p>Runtime for the call of the model.</p> required <code>domain</code> <code>str</code> <p>Domain of this prediction.</p> <code>None</code> Source code in <code>kebbie/scorer.py</code> <pre><code>def swp(\n    self,\n    true_word: str,\n    predicted_words: List[str],\n    context: str,\n    memory: int,\n    runtime: int,\n    domain: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Method used to record a prediction for the swipe resolution task.\n\n    Args:\n        true_word (str): The label (clean word to predict).\n        predicted_words (List[str]): Predictions of the model.\n        context (str): The context (previous words in the sentence).\n        memory (int): Memory consumption for the call of the model.\n        runtime (int): Runtime for the call of the model.\n        domain (str): Domain of this prediction.\n    \"\"\"\n    # Record memory &amp; runtime\n    if memory &gt;= 0:\n        self.swp_memories.append(memory)\n    if runtime &gt;= 0:\n        self.swp_runtimes.append(runtime)\n\n    # Record counts\n    if len(predicted_words) &gt; 0 and predicted_words[0] == true_word:\n        self.swp_c[domain].correct += 1\n    if true_word in predicted_words[:3]:\n        self.swp_c[domain].correct_3 += 1\n    else:\n        # If the word is not in the top-3 predictions, this is a mistake\n        if self.track_mistakes:\n            self.swp_mistakes.update([Mistake(actual=true_word, preds=predicted_words[:3], context=context)])\n\n    self.swp_c[domain].total += 1\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer.set_domain","title":"<code>set_domain(domain)</code>","text":"<p>Method setting the domain for the scores associated with no domain.</p> <p>To make it easier to score a single sentence, it's possible to call the scorer without a domain (see signature of <code>nwp()</code>, <code>acp()</code>, <code>acr()</code>). In this case the scores are associated to no domain (<code>None</code> key). This method allows the user to set the domain name for these scores with no domain (effectively moving the <code>None</code> domain scores to the given domain name).</p> Note <p>If some scores were already linked to the given domain, these scores will be erased (replaced by the scores of the <code>None</code> domain).</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>Domain name to associate the scores to.</p> required Source code in <code>kebbie/scorer.py</code> <pre><code>def set_domain(self, domain: str) -&gt; None:\n    \"\"\"Method setting the domain for the scores associated with no domain.\n\n    To make it easier to score a single sentence, it's possible to call the\n    scorer without a domain (see signature of `nwp()`, `acp()`, `acr()`).\n    In this case the scores are associated to no domain (`None` key).\n    This method allows the user to set the domain name for these scores\n    with no domain (effectively moving the `None` domain scores to the\n    given domain name).\n\n    Note:\n        If some scores were already linked to the given domain, these\n        scores will be erased (replaced by the scores of the `None`\n        domain).\n\n    Args:\n        domain (str): Domain name to associate the scores to.\n    \"\"\"\n    if None in self.nwp_c:\n        self.nwp_c[domain] = self.nwp_c.pop(None)\n    if None in self.acp_c:\n        self.acp_c[domain] = self.acp_c.pop(None)\n    if None in self.acr_c:\n        self.acr_c[domain] = self.acr_c.pop(None)\n    if None in self.swp_c:\n        self.swp_c[domain] = self.swp_c.pop(None)\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer._score_accuracy","title":"<code>_score_accuracy(c)</code>","text":"<p>Helper method to compute the accuracy given a prediction count.</p> This method return a dictionary with 3 metrics <ul> <li>Accuracy</li> <li>Top3 accuracy</li> <li>Total number of predictions</li> </ul> <p>Parameters:</p> Name Type Description Default <code>c</code> <code>Count</code> <p>Count object to use to compute the accuracy.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary with the computed metrics.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def _score_accuracy(self, c: Count) -&gt; Dict:\n    \"\"\"Helper method to compute the accuracy given a prediction count.\n\n    This method return a dictionary with 3 metrics :\n     * Accuracy\n     * Top3 accuracy\n     * Total number of predictions\n\n    Args:\n        c (Count): Count object to use to compute the accuracy.\n\n    Returns:\n        Dictionary with the computed metrics.\n    \"\"\"\n    return {\n        \"accuracy\": round_to_n(c.correct / c.total) if c.total != 0 else 0,\n        \"top3_accuracy\": round_to_n(c.correct_3 / c.total) if c.total != 0 else 0,\n        \"n\": c.total,\n    }\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer._score_precision_recall","title":"<code>_score_precision_recall(no_typo_c, typo_c, beta)</code>","text":"<p>Helper method to compute the precision and recall for auto-correction.</p> This method return a dictionary with several metrics <ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F-score</li> <li>Top3 accuracy</li> <li>Top3 precision</li> <li>Top3 recall</li> <li>Top3 F-score</li> <li>Number of predictions with a typo</li> <li>Total number of predictions</li> </ul> <p>For auto-correction, we need 2 Count objects : the counts of typos, and the counts of non-typo (to compute the True Negative and False Positive metrics).</p> <p>Parameters:</p> Name Type Description Default <code>no_typo_c</code> <code>Count</code> <p>Count object for the predictions where no typo were added.</p> required <code>typo_c</code> <code>Count</code> <p>Count object for the predictions where typos were added.</p> required <code>beta</code> <code>float</code> <p>Beta to use for computing the F-beta score.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary with the computed metrics.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def _score_precision_recall(self, no_typo_c: Count, typo_c: Count, beta: float) -&gt; Dict:\n    \"\"\"Helper method to compute the precision and recall for\n    auto-correction.\n\n    This method return a dictionary with several metrics :\n     * Accuracy\n     * Precision\n     * Recall\n     * F-score\n     * Top3 accuracy\n     * Top3 precision\n     * Top3 recall\n     * Top3 F-score\n     * Number of predictions with a typo\n     * Total number of predictions\n\n    For auto-correction, we need 2 Count objects : the counts of typos, and\n    the counts of non-typo (to compute the True Negative and False Positive\n    metrics).\n\n    Args:\n        no_typo_c (Count): Count object for the predictions where no typo\n            were added.\n        typo_c (Count): Count object for the predictions where typos were\n            added.\n        beta (float): Beta to use for computing the F-beta score.\n\n    Returns:\n        Dictionary with the computed metrics.\n    \"\"\"\n    # The first step is to divide the counts into TN, FP, TP, FN\n    tn = no_typo_c.correct\n    fp = no_typo_c.total - no_typo_c.correct\n    tp = typo_c.correct\n    fn = typo_c.total - typo_c.correct\n\n    tn_3 = no_typo_c.correct_3\n    fp_3 = no_typo_c.total - no_typo_c.correct_3\n    tp_3 = typo_c.correct_3\n    fn_3 = typo_c.total - typo_c.correct_3\n\n    # Then we compute the metrics\n    p = precision(tp=tp, fp=fp)\n    r = recall(tp=tp, fn=fn)\n\n    p_3 = precision(tp=tp_3, fp=fp_3)\n    r_3 = recall(tp=tp_3, fn=fn_3)\n\n    return {\n        \"accuracy\": round_to_n(accuracy(tp=tp, tn=tn, fp=fp, fn=fn)),\n        \"precision\": round_to_n(p),\n        \"recall\": round_to_n(r),\n        \"fscore\": round_to_n(fbeta(precision=p, recall=r, beta=beta)),\n        \"top3_accuracy\": round_to_n(accuracy(tp=tp_3, tn=tn_3, fp=fp_3, fn=fn_3)),\n        \"top3_precision\": round_to_n(p_3),\n        \"top3_recall\": round_to_n(r_3),\n        \"top3_fscore\": round_to_n(fbeta(precision=p_3, recall=r_3, beta=beta)),\n        \"n_typo\": typo_c.total,\n        \"n\": no_typo_c.total + typo_c.total,\n    }\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer._score_performances","title":"<code>_score_performances(memories, runtimes)</code>","text":"<p>Helper method to compute metrics related to the memory &amp; runtime.</p> This method returns a dictionary with several metrics <ul> <li>The mean memory consumption</li> <li>The min memory consumption</li> <li>The max memory consumption</li> <li>The mean running time</li> <li>The fastest running time</li> <li>The slowest running time</li> </ul> <p>Parameters:</p> Name Type Description Default <code>memories</code> <code>List[int]</code> <p>List of memories consumptions for a specific operation.</p> required <code>runtimes</code> <code>List[int]</code> <p>List of runtimes for a specific operation.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary with the computed metrics.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def _score_performances(self, memories: List[int], runtimes: List[int]) -&gt; Dict:\n    \"\"\"Helper method to compute metrics related to the memory &amp; runtime.\n\n    This method returns a dictionary with several metrics :\n     * The mean memory consumption\n     * The min memory consumption\n     * The max memory consumption\n     * The mean running time\n     * The fastest running time\n     * The slowest running time\n\n    Args:\n        memories (List[int]): List of memories consumptions for a\n            specific operation.\n        runtimes (List[int]): List of runtimes for a specific operation.\n\n    Returns:\n        Dictionary with the computed metrics.\n    \"\"\"\n    perf = {\n        \"mean_memory\": stats.mean(memories) if memories else 0,\n        \"min_memory\": min(memories) if memories else 0,\n        \"max_memory\": max(memories) if memories else 0,\n        \"mean_runtime\": stats.mean(runtimes) if runtimes else 0,\n        \"fastest_runtime\": min(runtimes) if runtimes else 0,\n        \"slowest_runtime\": max(runtimes) if runtimes else 0,\n    }\n\n    if self.human_readable:\n        perf = {\n            name: human_readable_memory(x) if name.endswith(\"memory\") else human_readable_runtime(x)\n            for name, x in perf.items()\n        }\n\n    return perf\n</code></pre>"},{"location":"internals/#kebbie.scorer.Scorer.score","title":"<code>score(beta=DEFAULT_BETA)</code>","text":"<p>Method that computes the final scores (as well as some alternative metrics that can bring insight in the capabilities of the model), and output these in an organized dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>beta</code> <code>float</code> <p>Beta to use for computing the F-beta score.</p> <code>DEFAULT_BETA</code> <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary containing the computed scores and metrics for the</p> <code>Dict</code> <p>model tested.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def score(self, beta: float = DEFAULT_BETA) -&gt; Dict:  # noqa: C901\n    \"\"\"Method that computes the final scores (as well as some alternative\n    metrics that can bring insight in the capabilities of the model), and\n    output these in an organized dictionary.\n\n    Args:\n        beta (float, optional): Beta to use for computing the F-beta score.\n\n    Returns:\n        Dictionary containing the computed scores and metrics for the\n        model tested.\n    \"\"\"\n    # --- Next-word prediction ---\n    # Group scores by domain\n    per = defaultdict(Count)\n    for domain, c in self.nwp_c.items():\n        per[domain] += c\n    total_c = sum(per.values(), Count())\n    per_domain = {k: self._score_accuracy(c) for k, c in per.items()}\n\n    # Task results\n    nwp = {\n        \"score\": self._score_accuracy(total_c),\n        \"per_domain\": per_domain,\n        \"performances\": self._score_performances(self.nwp_memories, self.nwp_runtimes),\n    }\n\n    # --- Auto-completion ---\n    # Group scores by domain\n    per = defaultdict(Count)\n    for domain, d1 in self.acp_c.items():\n        for has_typo, d2 in d1.items():\n            for compl_rate, c in d2.items():\n                per[domain] += c\n    total_c = sum(per.values(), Count())\n    per_domain = {k: self._score_accuracy(c) for k, c in per.items()}\n\n    # Group scores by completion rate\n    per = defaultdict(Count)\n    for domain, d1 in self.acp_c.items():\n        for has_typo, d2 in d1.items():\n            for compl_rate, c in d2.items():\n                per[compl_rate] += c\n    per_compl_rate = {\n        \"&lt;25%\": self._score_accuracy(sum((c for k, c in per.items() if k &lt; 0.25), Count())),\n        \"25%~50%\": self._score_accuracy(sum((c for k, c in per.items() if 0.25 &lt;= k &lt; 0.5), Count())),\n        \"50%~75%\": self._score_accuracy(sum((c for k, c in per.items() if 0.5 &lt;= k &lt; 0.75), Count())),\n        \"&gt;75%\": self._score_accuracy(sum((c for k, c in per.items() if 0.75 &lt;= k), Count())),\n    }\n\n    # Group scores by with_typo / without_typo\n    per = defaultdict(Count)\n    for domain, d1 in self.acp_c.items():\n        for has_typo, d2 in d1.items():\n            for compl_rate, c in d2.items():\n                per[has_typo] += c\n    per_other = {k: self._score_accuracy(per[k]) for k in [WITHOUT_TYPO, WITH_TYPO]}\n\n    # Task results\n    acp = {\n        \"score\": self._score_accuracy(total_c),\n        \"per_domain\": per_domain,\n        \"per_completion_rate\": per_compl_rate,\n        \"per_other\": per_other,\n        \"performances\": self._score_performances(self.acp_memories, self.acp_runtimes),\n    }\n\n    # --- Auto-correction ---\n    # Group scores by domain\n    no_typo_per, typo_per = defaultdict(Count), defaultdict(Count)\n    for domain, d1 in self.acr_c.items():\n        for typo, c in d1.items():\n            if typo is None:\n                no_typo_per[domain] += c\n            else:\n                typo_per[domain] += c\n    no_typo_total_c = sum(no_typo_per.values(), Count())\n    typo_total_c = sum(typo_per.values(), Count())\n    per_domain = {k: self._score_precision_recall(no_typo_per[k], typo_per[k], beta=beta) for k in no_typo_per}\n\n    # Group scores by typo type\n    no_typo_c, typo_per = Count(), defaultdict(Count)\n    for domain, d1 in self.acr_c.items():\n        for typo, c in d1.items():\n            if typo is None:\n                no_typo_c += c\n            else:\n                typo_per[typo] += c\n    # Divide the total count of no-typo into each type of typos with the right proportions\n    no_typo_per = defaultdict(Count, {k: no_typo_c * (c.total / typo_total_c.total) for k, c in typo_per.items()})\n    per_typo_type = {t.name: self._score_precision_recall(no_typo_per[t], typo_per[t], beta=beta) for t in Typo}\n    per_n_typo = {\n        \"1\": self._score_precision_recall(\n            sum((c for k, c in no_typo_per.items() if isinstance(k, Typo)), Count()),\n            sum((c for k, c in typo_per.items() if isinstance(k, Typo)), Count()),\n            beta=beta,\n        ),\n        \"2\": self._score_precision_recall(no_typo_per[2], typo_per[2], beta=beta),\n        \"3+\": self._score_precision_recall(\n            sum((c for k, c in no_typo_per.items() if isinstance(k, int) and k &gt; 2), Count()),\n            sum((c for k, c in typo_per.items() if isinstance(k, int) and k &gt; 2), Count()),\n            beta=beta,\n        ),\n    }\n\n    # Task results\n    acr = {\n        \"score\": self._score_precision_recall(no_typo_total_c, typo_total_c, beta=beta),\n        \"per_domain\": per_domain,\n        \"per_typo_type\": per_typo_type,\n        \"per_number_of_typos\": per_n_typo,\n        \"performances\": self._score_performances(self.acr_memories, self.acr_runtimes),\n    }\n\n    # --- Swipe resolution ---\n    # Group scores by domain\n    per = defaultdict(Count)\n    for domain, c in self.swp_c.items():\n        per[domain] += c\n    total_c = sum(per.values(), Count())\n    per_domain = {k: self._score_accuracy(c) for k, c in per.items()}\n\n    # Task results\n    swp = {\n        \"score\": self._score_accuracy(total_c),\n        \"per_domain\": per_domain,\n        \"performances\": self._score_performances(self.swp_memories, self.swp_runtimes),\n    }\n\n    # Final results\n    results = {\n        \"next_word_prediction\": nwp,\n        \"auto_completion\": acp,\n        \"auto_correction\": acr,\n        \"swipe_resolution\": swp,\n    }\n\n    # Add the overall score\n    results[\"overall_score\"] = one_score(results)\n\n    return results\n</code></pre>"},{"location":"internals/#kebbie.scorer.dd_x_layers","title":"<code>dd_x_layers(n_layers=1)</code>","text":"<p>Helper function for creating a nested defaultdict, with a specified number of nest level. The end object is a Count.</p> <p>Parameters:</p> Name Type Description Default <code>n_layers</code> <code>int</code> <p>Number of layer for the defaultdict.</p> <code>1</code> <p>Returns:</p> Type Description <code>defaultdict</code> <p>Created nested defaultdict.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def dd_x_layers(n_layers: int = 1) -&gt; defaultdict:\n    \"\"\"Helper function for creating a nested defaultdict, with a specified\n    number of nest level. The end object is a Count.\n\n    Args:\n        n_layers (int): Number of layer for the defaultdict.\n\n    Returns:\n        Created nested defaultdict.\n    \"\"\"\n    assert n_layers &gt; 0, f\"A default dict have at least 1 layer ({n_layers} given)\"\n    if n_layers == 1:\n        return defaultdict(Count)\n    else:\n        return defaultdict(partial(dd_x_layers, n_layers=n_layers - 1))\n</code></pre>"},{"location":"internals/#kebbie.scorer.one_score","title":"<code>one_score(results)</code>","text":"<p>One Score to rule them all, One Score to find them, One Score to bring them all and in the darkness bind them.</p> <p>This function is here to gather the various testing metrics of a JET file in a single number, to easily compare models.</p> <p>We take a single metric for each task, and weight them based on the importance of the task (these metrics already have the same scale : between 0 and 1).</p> <p>For NWP and ACP we take a top-3 metric, because these tasks usually involve a user action from a proposed list. For ACR and SWP, we take a top-1 metric, since usually it's automatically applied without user input.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Dict</code> <p>Testing results. Should be a dictionary containing all the metrics (used to compute the one score).</p> required <p>Returns:</p> Type Description <code>float</code> <p>One score, computed from the results given.</p> Source code in <code>kebbie/scorer.py</code> <pre><code>def one_score(results: Dict) -&gt; float:\n    \"\"\"One Score to rule them all, One Score to find them, One Score to bring\n    them all and in the darkness bind them.\n\n    This function is here to gather the various testing metrics of a JET file\n    in a single number, to easily compare models.\n\n    We take a single metric for each task, and weight them based on the\n    importance of the task (these metrics already have the same scale : between\n    0 and 1).\n\n    For NWP and ACP we take a top-3 metric, because these tasks usually involve\n    a user action from a proposed list. For ACR and SWP, we take a top-1\n    metric, since usually it's automatically applied without user input.\n\n    Args:\n        results (Dict): Testing results. Should be a dictionary containing all\n            the metrics (used to compute the one score).\n\n    Returns:\n        One score, computed from the results given.\n    \"\"\"\n    nwp = results[\"next_word_prediction\"][\"score\"][\"top3_accuracy\"]\n    acp = results[\"auto_completion\"][\"score\"][\"top3_accuracy\"]\n    acr = results[\"auto_correction\"][\"score\"][\"fscore\"]\n    swp = results[\"swipe_resolution\"][\"score\"][\"accuracy\"]\n\n    return 0.15 * nwp + 0.2 * acp + 0.4 * acr + 0.25 * swp\n</code></pre>"},{"location":"internals/#tokenizerpy","title":"<code>tokenizer.py</code>","text":"<p>Module defining <code>BasicTokenizer</code>, very basic tokenizer to separate a sentence into words.</p>"},{"location":"internals/#kebbie.tokenizer.BasicTokenizer","title":"<code>BasicTokenizer</code>","text":"<p>A basic tokenizer, used for regular latin languages. This tokenizer simply use space as word separator. Since it is used for testing only, we don't need to care about punctuations, etc...</p> Source code in <code>kebbie/tokenizer.py</code> <pre><code>class BasicTokenizer:\n    \"\"\"A basic tokenizer, used for regular latin languages.\n    This tokenizer simply use space as word separator. Since it is used for\n    testing only, we don't need to care about punctuations, etc...\n    \"\"\"\n\n    def preprocess(self, sentence: str) -&gt; str:\n        \"\"\"Method for simple preprocessing.\n\n        The goal of this function is not to provide an extensive and clean\n        preprocessing. The goal is just to normalize some characters (that\n        are not in our keyboard, so the user can't officially type them) into\n        their normal counterpart, that are in the keyboard.\n\n        Args:\n            sentence (str): String to normalize.\n\n        Returns:\n            Normalized string.\n        \"\"\"\n        # Replace things that are like \"\n        sentence = sentence.replace(\"\u201c\", '\"').replace(\"\u201d\", '\"').replace(\"\u201e\", '\"')\n\n        # Replace things that are like '\n        sentence = sentence.replace(\"\u2019\", \"'\").replace(\"\u02bb\", \"'\").replace(\"\u2018\", \"'\").replace(\"\u00b4\", \"'\").replace(\"\u02bc\", \"'\")\n\n        # Replace things that are like -\n        sentence = sentence.replace(\"\u2013\", \"-\").replace(\"\u2014\", \"-\").replace(\"\u2011\", \"-\").replace(\"\u2212\", \"-\").replace(\"\u30fc\", \"-\")\n\n        # Replace other punctuations\n        sentence = sentence.replace(\"\u2026\", \"...\").replace(\"\u201a\", \",\").replace(\"\u2024\", \".\")\n\n        # TODO: Each keyboard has its own way to deal with punctuation\n        # (applying auto-correction or not, displaying next-word prediction or\n        # not, etc...). So for now we just get rid of the punctuations, it's a\n        # convenient shortcut and it's fair to all keyboards.\n        # Eventually we should find a better way to deal with that.\n        sentence = re.sub(r\"\\s*\\.+\\s*\", \" \", sentence)\n        sentence = re.sub(r\"\\s*[,:;\\(\\)\\\"!?\\[\\]\\{\\}~]\\s*\", \" \", sentence)\n\n        return sentence\n\n    def word_split(self, sentence: str) -&gt; List[str]:\n        \"\"\"Method for splitting a sentence into a list of words.\n\n        Args:\n            sentence (str): Sentence to split.\n\n        Returns:\n            List of words from the sentence.\n        \"\"\"\n        return sentence.strip().split()\n\n    def update_context(self, context: str, word: str) -&gt; str:\n        \"\"\"Method for updating a context, given a word that was typed.\n\n        Args:\n            context (str): Existing context.\n            word (str): Word being typed.\n\n        Returns:\n            Updated context.\n        \"\"\"\n        return context + word + \" \"\n</code></pre>"},{"location":"internals/#kebbie.tokenizer.BasicTokenizer.preprocess","title":"<code>preprocess(sentence)</code>","text":"<p>Method for simple preprocessing.</p> <p>The goal of this function is not to provide an extensive and clean preprocessing. The goal is just to normalize some characters (that are not in our keyboard, so the user can't officially type them) into their normal counterpart, that are in the keyboard.</p> <p>Parameters:</p> Name Type Description Default <code>sentence</code> <code>str</code> <p>String to normalize.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Normalized string.</p> Source code in <code>kebbie/tokenizer.py</code> <pre><code>def preprocess(self, sentence: str) -&gt; str:\n    \"\"\"Method for simple preprocessing.\n\n    The goal of this function is not to provide an extensive and clean\n    preprocessing. The goal is just to normalize some characters (that\n    are not in our keyboard, so the user can't officially type them) into\n    their normal counterpart, that are in the keyboard.\n\n    Args:\n        sentence (str): String to normalize.\n\n    Returns:\n        Normalized string.\n    \"\"\"\n    # Replace things that are like \"\n    sentence = sentence.replace(\"\u201c\", '\"').replace(\"\u201d\", '\"').replace(\"\u201e\", '\"')\n\n    # Replace things that are like '\n    sentence = sentence.replace(\"\u2019\", \"'\").replace(\"\u02bb\", \"'\").replace(\"\u2018\", \"'\").replace(\"\u00b4\", \"'\").replace(\"\u02bc\", \"'\")\n\n    # Replace things that are like -\n    sentence = sentence.replace(\"\u2013\", \"-\").replace(\"\u2014\", \"-\").replace(\"\u2011\", \"-\").replace(\"\u2212\", \"-\").replace(\"\u30fc\", \"-\")\n\n    # Replace other punctuations\n    sentence = sentence.replace(\"\u2026\", \"...\").replace(\"\u201a\", \",\").replace(\"\u2024\", \".\")\n\n    # TODO: Each keyboard has its own way to deal with punctuation\n    # (applying auto-correction or not, displaying next-word prediction or\n    # not, etc...). So for now we just get rid of the punctuations, it's a\n    # convenient shortcut and it's fair to all keyboards.\n    # Eventually we should find a better way to deal with that.\n    sentence = re.sub(r\"\\s*\\.+\\s*\", \" \", sentence)\n    sentence = re.sub(r\"\\s*[,:;\\(\\)\\\"!?\\[\\]\\{\\}~]\\s*\", \" \", sentence)\n\n    return sentence\n</code></pre>"},{"location":"internals/#kebbie.tokenizer.BasicTokenizer.word_split","title":"<code>word_split(sentence)</code>","text":"<p>Method for splitting a sentence into a list of words.</p> <p>Parameters:</p> Name Type Description Default <code>sentence</code> <code>str</code> <p>Sentence to split.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of words from the sentence.</p> Source code in <code>kebbie/tokenizer.py</code> <pre><code>def word_split(self, sentence: str) -&gt; List[str]:\n    \"\"\"Method for splitting a sentence into a list of words.\n\n    Args:\n        sentence (str): Sentence to split.\n\n    Returns:\n        List of words from the sentence.\n    \"\"\"\n    return sentence.strip().split()\n</code></pre>"},{"location":"internals/#kebbie.tokenizer.BasicTokenizer.update_context","title":"<code>update_context(context, word)</code>","text":"<p>Method for updating a context, given a word that was typed.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>Existing context.</p> required <code>word</code> <code>str</code> <p>Word being typed.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Updated context.</p> Source code in <code>kebbie/tokenizer.py</code> <pre><code>def update_context(self, context: str, word: str) -&gt; str:\n    \"\"\"Method for updating a context, given a word that was typed.\n\n    Args:\n        context (str): Existing context.\n        word (str): Word being typed.\n\n    Returns:\n        Updated context.\n    \"\"\"\n    return context + word + \" \"\n</code></pre>"},{"location":"internals/#utilspy","title":"<code>utils.py</code>","text":"<p>Various utils function used by <code>kebbie</code>.</p>"},{"location":"internals/#kebbie.utils.profile_fn","title":"<code>profile_fn(fn, *args, **kwargs)</code>","text":"<p>Profile the runtime and memory usage of the given function.</p> <p>Note that it will only account for memory allocated by python (if you use a library in C/C++ that does its own allocation, it won't report it).</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>Function to profile.</p> required <code>*args</code> <code>Any</code> <p>Positional arguments to pass to the given function.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keywords arguments to pass to the given function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The return value of the function called.</p> <code>int</code> <p>The memory usage (in bytes).</p> <code>int</code> <p>The runtime (in nano seconds).</p> Source code in <code>kebbie/utils.py</code> <pre><code>def profile_fn(fn: Callable, *args: Any, **kwargs: Any) -&gt; Tuple[Any, int, int]:\n    \"\"\"Profile the runtime and memory usage of the given function.\n\n    Note that it will only account for memory allocated by python (if you use\n    a library in C/C++ that does its own allocation, it won't report it).\n\n    Args:\n        fn (Callable): Function to profile.\n        *args: Positional arguments to pass to the given function.\n        **kwargs: Keywords arguments to pass to the given function.\n\n    Returns:\n        The return value of the function called.\n        The memory usage (in bytes).\n        The runtime (in nano seconds).\n    \"\"\"\n    tracemalloc.start()\n    t0 = time.time()\n\n    result = fn(*args, **kwargs)\n\n    runtime = time.time() - t0\n    _, memory = tracemalloc.get_traced_memory()\n\n    return result, memory, runtime * SEC_TO_NANOSEC\n</code></pre>"},{"location":"internals/#kebbie.utils.euclidian_dist","title":"<code>euclidian_dist(p1, p2)</code>","text":"<p>Function computing the euclidian distance between 2 points.</p> <p>Parameters:</p> Name Type Description Default <code>p1</code> <code>Tuple[float, float]</code> <p>Point 1.</p> required <code>p2</code> <code>Tuple[float, float]</code> <p>Point 2.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Euclidian distance between the 2 given points.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def euclidian_dist(p1: Tuple[float, float], p2: Tuple[float, float]) -&gt; float:\n    \"\"\"Function computing the euclidian distance between 2 points.\n\n    Args:\n        p1 (Tuple[float, float]): Point 1.\n        p2 (Tuple[float, float]): Point 2.\n\n    Returns:\n        Euclidian distance between the 2 given points.\n    \"\"\"\n    return math.sqrt(sum((a - b) ** 2 for a, b in zip(p1, p2)))\n</code></pre>"},{"location":"internals/#kebbie.utils.load_keyboard","title":"<code>load_keyboard(lang='en-US')</code>","text":"<p>Load the keyboard data for the given language.</p> <p>For now, only <code>en-US</code> is supported.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>Language of the keyboard to load.</p> <code>'en-US'</code> <p>Returns:</p> Type Description <code>Dict</code> <p>The keyboard data.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def load_keyboard(lang: str = \"en-US\") -&gt; Dict:\n    \"\"\"Load the keyboard data for the given language.\n\n    For now, only `en-US` is supported.\n\n    Args:\n        lang (str, optional): Language of the keyboard to load.\n\n    Returns:\n        The keyboard data.\n    \"\"\"\n    layout_folder = Path(__file__).parent / \"layouts\"\n    with open(layout_folder / f\"{lang}.json\", \"r\") as f:\n        keyboard = json.load(f)\n    return keyboard\n</code></pre>"},{"location":"internals/#kebbie.utils.strip_accents","title":"<code>strip_accents(s)</code>","text":"<p>Util function for removing accents from a given string.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Accented string.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Same string, without accent.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def strip_accents(s: str) -&gt; str:\n    \"\"\"Util function for removing accents from a given string.\n\n    Args:\n        s (str): Accented string.\n\n    Returns:\n        Same string, without accent.\n    \"\"\"\n    nfkd_form = unicodedata.normalize(\"NFKD\", s)\n    return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n</code></pre>"},{"location":"internals/#kebbie.utils.sample","title":"<code>sample(proba)</code>","text":"<p>Simple function to sample an event with the given probability. For example, calling <code>sample(0.95)</code> will return <code>True</code> in 95% cases, and <code>False</code> in 5% cases.</p> <p>Parameters:</p> Name Type Description Default <code>proba</code> <code>float</code> <p>Probability of the event to happen. Should be between 0 and 1 (included).</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the event was sampled, <code>False</code> otherwise.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def sample(proba: float) -&gt; bool:\n    \"\"\"Simple function to sample an event with the given probability.\n    For example, calling `sample(0.95)` will return `True` in 95% cases, and\n    `False` in 5% cases.\n\n    Args:\n        proba (float): Probability of the event to happen. Should be between 0\n            and 1 (included).\n\n    Returns:\n        `True` if the event was sampled, `False` otherwise.\n    \"\"\"\n    assert 0 &lt;= proba &lt;= 1, f\"`{proba}` is not a valid probability (should be between 0 and 1)\"\n    if proba == 0:\n        return False\n    elif proba == 1:\n        return True\n    else:\n        return random.choices([True, False], weights=[proba, 1 - proba])[0]\n</code></pre>"},{"location":"internals/#kebbie.utils.sample_among","title":"<code>sample_among(probs, with_none=True)</code>","text":"<p>Function that sample an event among several with different probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>probs</code> <code>Dict[Any, float]</code> <p>Dictionary representing the different events and their probabilities. Each probability should be above 0 and their sum should not exceed 1.</p> required <code>with_none</code> <code>bool</code> <p>If set to <code>True</code>, add a <code>None</code> option (no event sampled).</p> <code>True</code> <p>Returns:</p> Type Description <code>Any</code> <p>The corresponding key of the event sampled.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def sample_among(probs: Dict[Any, float], with_none: bool = True) -&gt; Any:\n    \"\"\"Function that sample an event among several with different\n    probabilities.\n\n    Args:\n        probs (Dict[Any, float]): Dictionary representing the different events\n            and their probabilities. Each probability should be above 0 and\n            their sum should not exceed 1.\n        with_none (bool): If set to `True`, add a `None` option (no event\n            sampled).\n\n    Returns:\n        The corresponding key of the event sampled.\n    \"\"\"\n    options = list(probs.keys())\n    weights = list(probs.values())\n    assert (\n        all(w &gt;= 0 for w in weights) and sum(weights) &lt;= 1\n    ), \"The numbers given are not a probability (should be above 0 and their sum should not exceed 1)\"\n\n    if with_none:\n        options.append(None)\n        weights.append(1 - sum(weights))\n\n    return random.choices(options, weights=weights)[0]\n</code></pre>"},{"location":"internals/#kebbie.utils.sample_partial_word","title":"<code>sample_partial_word(keystrokes, word, true_word)</code>","text":"<p>Sample a partial word from a given word, and extract the corresponding keystrokes as well.</p> <p>Sampling is done with increasing weights (more chances to sample a longer list). For example if the list represent the keystrokes of \"abcdef\", the probabilities are as follow:  * \"a\" :     1/15  * \"ab\" :    2/15  * \"abc\" :   3/15  * \"abcd\" :  4/15  * \"abcde\" : 5/15</p> <p>Parameters:</p> Name Type Description Default <code>keystrokes</code> <code>List[Optional[Tuple[float, float]]]</code> <p>Complete list of keystrokes, representing a full word.</p> required <code>word</code> <code>str</code> <p>The word corresponding to the keystrokes.</p> required <code>true_word</code> <code>str</code> <p>Actual word (without typo). Necessary to ensure the sampled keystrokes are partial.</p> required <p>Returns:</p> Type Description <code>List[Optional[Tuple[float, float]]]</code> <p>The partial list of keystrokes (sampled from the given word).</p> <code>str</code> <p>The partial word (sampled from the given word).</p> Source code in <code>kebbie/utils.py</code> <pre><code>def sample_partial_word(\n    keystrokes: List[Optional[Tuple[float, float]]], word: str, true_word: str\n) -&gt; Tuple[List[Optional[Tuple[float, float]]], str]:\n    \"\"\"Sample a partial word from a given word, and extract the corresponding\n    keystrokes as well.\n\n    Sampling is done with increasing weights (more chances to sample a longer\n    list). For example if the list represent the keystrokes of \"abcdef\", the\n    probabilities are as follow:\n     * \"a\" :     1/15\n     * \"ab\" :    2/15\n     * \"abc\" :   3/15\n     * \"abcd\" :  4/15\n     * \"abcde\" : 5/15\n\n    Args:\n        keystrokes (List[Optional[Tuple[float, float]]]): Complete list of\n            keystrokes, representing a full word.\n        word (str): The word corresponding to the keystrokes.\n        true_word (str): Actual word (without typo). Necessary to ensure the\n            sampled keystrokes are partial.\n\n    Returns:\n        The partial list of keystrokes (sampled from the given word).\n        The partial word (sampled from the given word).\n    \"\"\"\n    r = range(1, min(len(true_word), len(word)))\n    s = random.choices(r, weights=r)[0]\n    return keystrokes[:s], word[:s]\n</code></pre>"},{"location":"internals/#kebbie.utils.accuracy","title":"<code>accuracy(tp, tn, fp, fn)</code>","text":"<p>Function computing the precision.</p> <p>Parameters:</p> Name Type Description Default <code>tp</code> <code>int</code> <p>Number of True Positive.</p> required <code>tn</code> <code>int</code> <p>Number of True Negative.</p> required <code>fp</code> <code>int</code> <p>Number of False Positive.</p> required <code>fn</code> <code>int</code> <p>Number of False Negative.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Accuracy.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def accuracy(tp: int, tn: int, fp: int, fn: int) -&gt; float:\n    \"\"\"Function computing the precision.\n\n    Args:\n        tp (int): Number of True Positive.\n        tn (int): Number of True Negative.\n        fp (int): Number of False Positive.\n        fn (int): Number of False Negative.\n\n    Returns:\n        Accuracy.\n    \"\"\"\n    try:\n        return (tp + tn) / (tp + tn + fp + fn)\n    except ZeroDivisionError:\n        return 0\n</code></pre>"},{"location":"internals/#kebbie.utils.precision","title":"<code>precision(tp, fp)</code>","text":"<p>Function computing the precision.</p> <p>Parameters:</p> Name Type Description Default <code>tp</code> <code>int</code> <p>Number of True Positive.</p> required <code>fp</code> <code>int</code> <p>Number of False Positive.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Precision.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def precision(tp: int, fp: int) -&gt; float:\n    \"\"\"Function computing the precision.\n\n    Args:\n        tp (int): Number of True Positive.\n        fp (int): Number of False Positive.\n\n    Returns:\n        Precision.\n    \"\"\"\n    try:\n        return tp / (tp + fp)\n    except ZeroDivisionError:\n        return 0\n</code></pre>"},{"location":"internals/#kebbie.utils.recall","title":"<code>recall(tp, fn)</code>","text":"<p>Function computing the recall.</p> <p>Parameters:</p> Name Type Description Default <code>tp</code> <code>int</code> <p>Number of True Positive.</p> required <code>fn</code> <code>int</code> <p>Number of False Negative.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Recall.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def recall(tp: int, fn: int) -&gt; float:\n    \"\"\"Function computing the recall.\n\n    Args:\n        tp (int): Number of True Positive.\n        fn (int): Number of False Negative.\n\n    Returns:\n        Recall.\n    \"\"\"\n    try:\n        return tp / (tp + fn)\n    except ZeroDivisionError:\n        return 0\n</code></pre>"},{"location":"internals/#kebbie.utils.fbeta","title":"<code>fbeta(precision, recall, beta=1)</code>","text":"<p>Function computing the F-beta score (which is a generalization of the F1 score).</p> The value of Beta changes how much we weight recall versus precision <ul> <li>For beta=0.5, Precision is twice as important as Recall</li> <li>For beta=2, Recall is twice as important as Precision</li> </ul> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>float</code> <p>Precision.</p> required <code>recall</code> <code>float</code> <p>Recall.</p> required <code>beta</code> <code>float</code> <p>Beta factor.</p> <code>1</code> <p>Returns:</p> Type Description <code>float</code> <p>F-beta score.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def fbeta(precision: float, recall: float, beta: float = 1) -&gt; float:\n    \"\"\"Function computing the F-beta score (which is a generalization of the\n    F1 score).\n\n    The value of Beta changes how much we weight recall versus precision:\n     * For beta=0.5, Precision is twice as important as Recall\n     * For beta=2, Recall is twice as important as Precision\n\n    Args:\n        precision (float): Precision.\n        recall (float): Recall.\n        beta (float): Beta factor.\n\n    Returns:\n        F-beta score.\n    \"\"\"\n    try:\n        return (1 + beta**2) * precision * recall / (beta**2 * precision + recall)\n    except ZeroDivisionError:\n        return 0\n</code></pre>"},{"location":"internals/#kebbie.utils.round_to_n","title":"<code>round_to_n(x, n=2)</code>","text":"<p>Util function to round a given number to n significant digits.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>Number to round.</p> required <code>n</code> <code>int</code> <p>Number of significant digits to use.</p> <code>2</code> <p>Returns:</p> Type Description <code>float</code> <p>Rounded number.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def round_to_n(x: float, n: int = 2) -&gt; float:\n    \"\"\"Util function to round a given number to n significant digits.\n\n    Args:\n        x (float): Number to round.\n        n (int): Number of significant digits to use.\n\n    Returns:\n        Rounded number.\n    \"\"\"\n    return round(x, -int(math.floor(math.log10(x))) + (n - 1)) if x != 0 else 0\n</code></pre>"},{"location":"internals/#kebbie.utils.human_readable_memory","title":"<code>human_readable_memory(x)</code>","text":"<p>Given a number in bytes, return a human-readable string of this number, with the right unit.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>Number in bytes.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable version of the given number, with the right unit.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def human_readable_memory(x: int) -&gt; str:\n    \"\"\"Given a number in bytes, return a human-readable string of this number,\n    with the right unit.\n\n    Args:\n        x (int): Number in bytes.\n\n    Returns:\n        Human-readable version of the given number, with the right unit.\n    \"\"\"\n    x = round_to_n(x, n=3)\n    for unit in [\"B\", \"KB\", \"MB\", \"GB\"]:\n        if x &lt; 1000:\n            return f\"{x:g} {unit}\"\n\n        x /= 1000\n    return f\"{x:g} TB\"\n</code></pre>"},{"location":"internals/#kebbie.utils.human_readable_runtime","title":"<code>human_readable_runtime(x)</code>","text":"<p>Given a number in nanoseconds, return a human-readable string of this number, with the right unit.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>int</code> <p>Number in nanoseconds.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable version of the given number, with the right unit.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def human_readable_runtime(x: int) -&gt; str:\n    \"\"\"Given a number in nanoseconds, return a human-readable string of this\n    number, with the right unit.\n\n    Args:\n        x (int): Number in nanoseconds.\n\n    Returns:\n        Human-readable version of the given number, with the right unit.\n    \"\"\"\n    x = round_to_n(x, n=3)\n    for unit in [\"ns\", \"\u03bcs\", \"ms\"]:\n        if x &lt; 1000:\n            return f\"{x:g} {unit}\"\n\n        x /= 1000\n    return f\"{x:g} s\"\n</code></pre>"},{"location":"internals/#kebbie.utils.get_soda_dataset","title":"<code>get_soda_dataset(max_sentences=2000, seed=31)</code>","text":"<p>Load the SODA dataset.</p> <p>Parameters:</p> Name Type Description Default <code>max_sentences</code> <code>int</code> <p>Maximum number of sentences in total in the dataset. They will be shared across domain (50% from the <code>narrative</code> domain, 50% from the <code>dialogue</code> domain).</p> <code>2000</code> <code>seed</code> <code>int</code> <p>Seed to use when shuffling the dataset (since we don't use the whole dataset, it's better to shuffle it before extracting the X first sentences).</p> <code>31</code> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>The dataset, separated into two domains : narrative and dialogue.</p> Source code in <code>kebbie/utils.py</code> <pre><code>def get_soda_dataset(max_sentences: int = 2_000, seed: int = 31) -&gt; Dict[str, List[str]]:\n    \"\"\"Load the SODA dataset.\n\n    Args:\n        max_sentences (int, optional): Maximum number of sentences in total in\n            the dataset. They will be shared across domain (50% from the\n            `narrative` domain, 50% from the `dialogue` domain).\n        seed (int, optional): Seed to use when shuffling the dataset (since we\n            don't use the whole dataset, it's better to shuffle it before\n            extracting the X first sentences).\n\n    Returns:\n        The dataset, separated into two domains : narrative and dialogue.\n    \"\"\"\n    data = {\"narrative\": [], \"dialogue\": []}\n    max_domain_sentences = max_sentences // 2\n\n    hf_dataset = datasets.load_dataset(\"allenai/soda\", split=\"test\")\n    hf_dataset = hf_dataset.shuffle(seed=seed)\n\n    for sample in hf_dataset:\n        if len(data[\"narrative\"]) &gt;= max_domain_sentences and len(data[\"dialogue\"]) &gt;= max_domain_sentences:\n            break\n\n        if len(data[\"narrative\"]) &lt; max_domain_sentences:\n            data[\"narrative\"].append(sample[\"narrative\"])\n\n        for sen in sample[\"dialogue\"]:\n            if len(data[\"dialogue\"]) &lt; max_domain_sentences:\n                data[\"dialogue\"].append(sen)\n\n    return data\n</code></pre>"},{"location":"internals/#constants","title":"Constants","text":""},{"location":"internals/#__init__py","title":"<code>__init__.py</code>","text":""},{"location":"internals/#kebbie.SUPPORTED_LANG","title":"<code>SUPPORTED_LANG = ['en-US']</code>","text":""},{"location":"internals/#kebbie.N_MOST_COMMON_MISTAKES","title":"<code>N_MOST_COMMON_MISTAKES = 1000</code>","text":""},{"location":"internals/#kebbie.DEFAULT_SEED","title":"<code>DEFAULT_SEED = 42</code>","text":""},{"location":"internals/#emulatorpy_1","title":"<code>emulator.py</code>","text":""},{"location":"internals/#kebbie.emulator.ANDROID","title":"<code>ANDROID = 'android'</code>","text":""},{"location":"internals/#kebbie.emulator.IOS","title":"<code>IOS = 'ios'</code>","text":""},{"location":"internals/#kebbie.emulator.GBOARD","title":"<code>GBOARD = 'gboard'</code>","text":""},{"location":"internals/#kebbie.emulator.TAPPA","title":"<code>TAPPA = 'tappa'</code>","text":""},{"location":"internals/#kebbie.emulator.FLEKSY","title":"<code>FLEKSY = 'fleksy'</code>","text":""},{"location":"internals/#kebbie.emulator.KBKITPRO","title":"<code>KBKITPRO = 'kbkitpro'</code>","text":""},{"location":"internals/#kebbie.emulator.KBKITOSS","title":"<code>KBKITOSS = 'kbkitoss'</code>","text":""},{"location":"internals/#kebbie.emulator.SWIFTKEY","title":"<code>SWIFTKEY = 'swiftkey'</code>","text":""},{"location":"internals/#kebbie.emulator.KEYBOARD_PACKAGE","title":"<code>KEYBOARD_PACKAGE = {GBOARD: 'com.google.android.inputmethod.latin', SWIFTKEY: 'com.touchtype.swiftkey', TAPPA: 'com.tappa.keyboard'}</code>","text":""},{"location":"internals/#kebbie.emulator.ANDROID_CAPABILITIES","title":"<code>ANDROID_CAPABILITIES = {'platformName': 'android', 'automationName': 'UiAutomator2', 'enableMultiWindows': True, 'deviceName': 'test', 'newCommandTimeout': 3600}</code>","text":""},{"location":"internals/#kebbie.emulator.IOS_CAPABILITIES","title":"<code>IOS_CAPABILITIES = {'platformName': 'iOS', 'automationName': 'XCUITest', 'udid': 'auto', 'xcodeOrgId': '8556JTA4X4', 'xcodeSigningId': 'iPhone Developer', 'useNewWDA': False, 'usePrebuiltWdDA': True, 'startIWDP': True, 'bundleId': 'com.apple.MobileSMS', 'newCommandTimeout': 3600}</code>","text":""},{"location":"internals/#kebbie.emulator.BROWSER_PAD_URL","title":"<code>BROWSER_PAD_URL = 'https://www.justnotepad.com'</code>","text":""},{"location":"internals/#kebbie.emulator.ANDROID_TYPING_FIELD_CLASS_NAME","title":"<code>ANDROID_TYPING_FIELD_CLASS_NAME = 'android.widget.EditText'</code>","text":""},{"location":"internals/#kebbie.emulator.DUMMY_RECIPIENT","title":"<code>DUMMY_RECIPIENT = '0'</code>","text":""},{"location":"internals/#kebbie.emulator.IOS_TYPING_FIELD_ID","title":"<code>IOS_TYPING_FIELD_ID = 'messageBodyField'</code>","text":""},{"location":"internals/#kebbie.emulator.IOS_START_CHAT_CLASS_NAME","title":"<code>IOS_START_CHAT_CLASS_NAME = 'XCUIElementTypeCell'</code>","text":""},{"location":"internals/#kebbie.emulator.TESSERACT_CONFIG","title":"<code>TESSERACT_CONFIG = '-c tessedit_char_blacklist=0123456789\u201d:!@\u00b7$%&amp;/()=.\u00bf?'</code>","text":""},{"location":"internals/#kebbie.emulator.PREDICTION_DELAY","title":"<code>PREDICTION_DELAY = 0.4</code>","text":""},{"location":"internals/#kebbie.emulator.CONTENT_TO_IGNORE","title":"<code>CONTENT_TO_IGNORE = ['Sticker', 'GIF', 'Clipboard', 'Settings', 'Back', 'Switch input method', 'Paste item', 'Close', 'paintpalette', 'Search Document', 'Microphone', 'gearshape', 'Next Locale', 'paintpalette', 'EmojiCategories/smileysAndPeople', 'EmojiCategories/animalsAndNature', 'EmojiCategories/foodAndDrink', 'EmojiCategories/activity', 'EmojiCategories/travelAndPlaces', 'EmojiCategories/objects', 'EmojiCategories/symbols', 'EmojiCategories/flags', 'Add', 'And', 'Are', '\u201cA\u201d', '\ud83d\ude80']</code>","text":""},{"location":"internals/#kebbie.emulator.CONTENT_TO_RENAME","title":"<code>CONTENT_TO_RENAME = {'Shift': 'shift', 'Delete': 'backspace', 'Backspace': 'backspace', 'Space': 'spacebar', 'space': 'spacebar', 'Emoji button': 'smiley', 'Emoji': 'smiley', 'Keyboard Type - emojis': 'smiley', 'Search': 'enter', 'return': 'enter', 'Enter': 'enter', 'Symbol keyboard': 'numbers', 'Symbols': 'numbers', 'Symbols and numbers': 'numbers', 'Keyboard Type - numeric': 'numbers', 'Voice input': 'mic', ',, alternatives available, Voice typing, long press to activate': 'mic', 'Close features menu': 'magic', 'Open features menu': 'magic', 'underline': '_', '&amp;amp;': '&amp;', 'ampersand': '&amp;', 'Dash': '-', 'Plus': '+', 'Left parenthesis': '(', 'Right parenthesis': ')', 'slash': '/', 'Apostrophe': \"'\", 'Colon': ':', 'Semicolon': ';', 'Exclamation': '!', 'Question mark': '?', 'Letter keyboard': 'letters', 'Letters': 'letters', 'Keyboard Type - auto': 'letters', 'Digit keyboard': 'numbers', 'More symbols': 'shift', 'Keyboard Type - symbolic': 'shift', 'Double tap for uppercase': 'shift', 'Double tap for caps lock': 'shift', 'capital Q': 'Q', 'capital W': 'W', 'capital E': 'E', 'capital R': 'R', 'capital T': 'T', 'capital Y': 'Y', 'capital U': 'U', 'capital I': 'I', 'Capital I': 'I', 'capital O': 'O', 'capital P': 'P', 'capital A': 'A', 'capital S': 'S', 'capital D': 'D', 'capital F': 'F', 'capital G': 'G', 'capital H': 'H', 'capital J': 'J', 'capital K': 'K', 'capital L': 'L', 'capital Z': 'Z', 'capital X': 'X', 'capital C': 'C', 'capital V': 'V', 'capital B': 'B', 'capital N': 'N', 'capital M': 'M'}</code>","text":""},{"location":"internals/#kebbie.emulator.FLEKSY_LAYOUT","title":"<code>FLEKSY_LAYOUT = {'keyboard_frame': [0, 517, 393, 266], 'lowercase': {'q': [0.007407407407407408, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'w': [0.10462962962962963, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'e': [0.20462962962962963, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'r': [0.30462962962962964, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 't': [0.4046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'y': [0.5046296296296297, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'u': [0.6046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'i': [0.7046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'o': [0.8046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'p': [0.9046296296296297, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'a': [0.05740740740740741, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 's': [0.15555555555555556, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'd': [0.25555555555555554, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'f': [0.35462962962962963, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'g': [0.4546296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'h': [0.5546296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'j': [0.6546296296296297, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'k': [0.7546296296296297, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'l': [0.8555555555555555, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'shift': [0.007407407407407408, 0.5994520547945206, 0.1361111111111111, 0.1643835616438356], 'z': [0.15555555555555556, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'x': [0.25555555555555554, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'c': [0.35462962962962963, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'v': [0.4546296296296296, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'b': [0.5546296296296296, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'n': [0.6546296296296297, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'm': [0.7546296296296297, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'backspace': [0.8555555555555555, 0.5994520547945206, 0.1361111111111111, 0.1643835616438356], 'numbers': [0.007407407407407408, 0.8080821917808219, 0.125, 0.1643835616438356], 'smiley': [0.14351851851851852, 0.8080821917808219, 0.10277777777777777, 0.1643835616438356], 'spacebar': [0.25555555555555554, 0.8080821917808219, 0.48703703703703705, 0.1643835616438356], '.': [0.7546296296296297, 0.8080821917808219, 0.1, 0.1643835616438356], 'enter': [0.8648148148148148, 0.8080821917808219, 0.12962962962962962, 0.1643835616438356]}, 'uppercase': {'Q': [0.007407407407407408, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'W': [0.10462962962962963, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'E': [0.20462962962962963, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'R': [0.30462962962962964, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'T': [0.4046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'Y': [0.5046296296296297, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'U': [0.6046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'I': [0.7046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'O': [0.8046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'P': [0.9046296296296297, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], 'A': [0.05740740740740741, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'S': [0.15555555555555556, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'D': [0.25555555555555554, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'F': [0.35462962962962963, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'G': [0.4546296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'H': [0.5546296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'J': [0.6546296296296297, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'K': [0.7546296296296297, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'L': [0.8555555555555555, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'shift': [0.007407407407407408, 0.5994520547945206, 0.1361111111111111, 0.1643835616438356], 'Z': [0.15555555555555556, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'X': [0.25555555555555554, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'C': [0.35462962962962963, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'V': [0.4546296296296296, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'B': [0.5546296296296296, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'N': [0.6546296296296297, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'M': [0.7546296296296297, 0.5994520547945206, 0.08796296296296297, 0.1643835616438356], 'backspace': [0.8555555555555555, 0.5994520547945206, 0.1361111111111111, 0.1643835616438356], 'numbers': [0.007407407407407408, 0.8080821917808219, 0.125, 0.1643835616438356], 'smiley': [0.14351851851851852, 0.8080821917808219, 0.10277777777777777, 0.1643835616438356], 'spacebar': [0.25555555555555554, 0.8080821917808219, 0.48703703703703705, 0.1643835616438356], '.': [0.7546296296296297, 0.8080821917808219, 0.1, 0.1643835616438356], 'enter': [0.8648148148148148, 0.8080821917808219, 0.12962962962962962, 0.1643835616438356]}, 'numbers': {'1': [0.007407407407407408, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '2': [0.10462962962962963, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '3': [0.20462962962962963, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '4': [0.30462962962962964, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '5': [0.4046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '6': [0.5046296296296297, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '7': [0.6046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '8': [0.7046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '9': [0.8046296296296296, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '0': [0.9046296296296297, 0.19356164383561644, 0.08796296296296297, 0.1643835616438356], '-': [0.007407407407407408, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], '/': [0.10462962962962963, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], ':': [0.20462962962962963, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], ';': [0.30462962962962964, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], '(': [0.4046296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], ')': [0.5046296296296297, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], '$': [0.6046296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], '&amp;': [0.7046296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], '@': [0.8046296296296296, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], '\"': [0.9046296296296297, 0.4008219178082192, 0.08796296296296297, 0.1643835616438356], 'shift': [0.007407407407407408, 0.5994520547945206, 0.1361111111111111, 0.1643835616438356], ',': [0.3101851851851852, 0.5994520547945206, 0.12, 0.1643835616438356], '?': [0.44044444444444447, 0.5994520547945206, 0.12, 0.1643835616438356], '!': [0.5707037037037037, 0.5994520547945206, 0.12, 0.1643835616438356], \"'\": [0.705962962962963, 0.5994520547945206, 0.12, 0.1643835616438356], 'backspace': [0.8551851851851852, 0.5994520547945206, 0.1361111111111111, 0.1643835616438356], 'letters': [0.007407407407407408, 0.8080821917808219, 0.125, 0.1643835616438356], 'smiley': [0.14351851851851852, 0.8080821917808219, 0.10277777777777777, 0.1643835616438356], 'spacebar': [0.25555555555555554, 0.8080821917808219, 0.48703703703703705, 0.1643835616438356], '.': [0.7546296296296297, 0.8080821917808219, 0.1, 0.1643835616438356], 'enter': [0.8648148148148148, 0.8080821917808219, 0.12962962962962962, 0.1643835616438356]}}</code>","text":""},{"location":"internals/#gesturepy_1","title":"<code>gesture.py</code>","text":""},{"location":"internals/#kebbie.gesture.MAX_RADIUS","title":"<code>MAX_RADIUS = 16</code>","text":""},{"location":"internals/#kebbie.gesture.MIN_N_POINTS_PER_DIST","title":"<code>MIN_N_POINTS_PER_DIST = 0.1</code>","text":""},{"location":"internals/#kebbie.gesture.MAX_N_POINTS_PER_DIST","title":"<code>MAX_N_POINTS_PER_DIST = 0.25</code>","text":""},{"location":"internals/#kebbie.gesture.MIN_ACCELERATION","title":"<code>MIN_ACCELERATION = 0.2</code>","text":""},{"location":"internals/#kebbie.gesture.MAX_ACCELERATION","title":"<code>MAX_ACCELERATION = 0.5</code>","text":""},{"location":"internals/#layoutpy_1","title":"<code>layout.py</code>","text":""},{"location":"internals/#kebbie.layout.SPACE","title":"<code>SPACE = 'spacebar'</code>","text":""},{"location":"internals/#kebbie.layout.POINT","title":"<code>POINT = '.'</code>","text":""},{"location":"internals/#kebbie.layout.N_ACCENT_PER_LINE","title":"<code>N_ACCENT_PER_LINE = 4</code>","text":""},{"location":"internals/#noise_modelpy_1","title":"<code>noise_model.py</code>","text":""},{"location":"internals/#kebbie.noise_model.DEFAULT_TYPO_PROBS","title":"<code>DEFAULT_TYPO_PROBS = {Typo.TRANSPOSE_CHAR: 0.01, Typo.DELETE_SPELLING_SYMBOL: 0.1, Typo.ADD_SPELLING_SYMBOL: 0, Typo.DELETE_SPACE: 0.01, Typo.ADD_SPACE: 0, Typo.DELETE_PUNCTUATION: 0, Typo.ADD_PUNCTUATION: 0, Typo.DELETE_CHAR: 0.005, Typo.ADD_CHAR: 0.005, Typo.SIMPLIFY_ACCENT: 0.08, Typo.SIMPLIFY_CASE: 0.08, Typo.COMMON_TYPO: 0.05}</code>","text":""},{"location":"internals/#kebbie.noise_model.SPACE","title":"<code>SPACE = ' '</code>","text":""},{"location":"internals/#kebbie.noise_model.DELETIONS","title":"<code>DELETIONS = [Typo.DELETE_SPELLING_SYMBOL, Typo.DELETE_SPACE, Typo.DELETE_PUNCTUATION, Typo.DELETE_CHAR]</code>","text":""},{"location":"internals/#kebbie.noise_model.FRONT_DELETION_MULTIPLIER","title":"<code>FRONT_DELETION_MULTIPLIER = 0.36</code>","text":""},{"location":"internals/#kebbie.noise_model.DEFAULT_SIGMA_RATIO","title":"<code>DEFAULT_SIGMA_RATIO = 3</code>","text":""},{"location":"internals/#kebbie.noise_model.CACHE_DIR","title":"<code>CACHE_DIR = os.path.expanduser('~/.cache/common_typos/')</code>","text":""},{"location":"internals/#kebbie.noise_model.TWEET_TYPO_CORPUS_URL","title":"<code>TWEET_TYPO_CORPUS_URL = 'https://luululu.com/tweet/typo-corpus-r1.txt'</code>","text":""},{"location":"internals/#oraclepy_1","title":"<code>oracle.py</code>","text":""},{"location":"internals/#kebbie.oracle.CHUNK_SIZE","title":"<code>CHUNK_SIZE = 10</code>","text":""},{"location":"internals/#kebbie.oracle.MAX_CHAR_PER_SENTENCE","title":"<code>MAX_CHAR_PER_SENTENCE = 256</code>","text":""},{"location":"internals/#kebbie.oracle.SWIPE_PROB","title":"<code>SWIPE_PROB = 0.01</code>","text":""},{"location":"internals/#scorerpy_1","title":"<code>scorer.py</code>","text":""},{"location":"internals/#kebbie.scorer.DEFAULT_BETA","title":"<code>DEFAULT_BETA = 0.9</code>","text":""},{"location":"internals/#kebbie.scorer.WITH_TYPO","title":"<code>WITH_TYPO = 'with_typo'</code>","text":""},{"location":"internals/#kebbie.scorer.WITHOUT_TYPO","title":"<code>WITHOUT_TYPO = 'without_typo'</code>","text":""},{"location":"internals/#utilspy_1","title":"<code>utils.py</code>","text":""},{"location":"internals/#kebbie.utils.SEC_TO_NANOSEC","title":"<code>SEC_TO_NANOSEC = 10000000000.0</code>","text":""},{"location":"leaderboard/","title":"Leaderboard","text":"Keyboard Score Next-word prediction Auto-completion Auto-correction Gboard 0.54 0.33 0.79 0.82 Swiftkey 0.47 0.33 0.76 0.68 iOS keyboard 0.46 0.43 0.8 0.6 Fleksy 0.43 0.27 0.73 0.6 KeyboardKit Pro 0.31 0 0.4 0.58 KeyboardKit Open-source 0 0 0 0.01 <p>Info</p> <p>The metrics used in this leaderboard are :</p> <ul> <li>For next-word prediction : top-3 accuracy</li> <li>For auto-completion : top-3 accuracy</li> <li>For auto-correction : F-score</li> </ul> <p>See Understanding the metrics for more details.</p> <p>The overall score is a weighted sum of each task's score.</p>"},{"location":"public_api/","title":"Public API","text":""},{"location":"public_api/#classes","title":"Classes","text":""},{"location":"public_api/#kebbie.correctors.Corrector","title":"<code>Corrector</code>","text":"<p>Base class for Corrector, which is the component being tested.</p> <p>Child classes should overwrite <code>auto_correct()</code>, <code>auto_complete()</code>, <code>resolve_swipe()</code>, and <code>predict_next_word()</code>.</p> <p>By default, the implementation for these methods is dummy : just return an empty list of candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>class Corrector:\n    \"\"\"Base class for Corrector, which is the component being tested.\n\n    Child classes should overwrite `auto_correct()`, `auto_complete()`,\n    `resolve_swipe()`, and `predict_next_word()`.\n\n    By default, the implementation for these methods is dummy : just return an\n    empty list of candidates.\n    \"\"\"\n\n    def auto_correct(\n        self,\n        context: str,\n        keystrokes: List[Optional[Tuple[float, float]]],\n        word: str,\n    ) -&gt; List[str]:\n        \"\"\"Method used for auto-correction.\n        Given a context and a typed word, this method should return a list of\n        possible candidates for correction.\n\n        Note that the typed word is given both as a plain string, and as a list\n        of keystrokes. The child class overwriting this method can use either\n        of them.\n\n        Args:\n            context (str): String representing the previously typed characters\n                (the beginning of the sentence basically).\n            keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n                (x and y coordinates) for each keystroke of the word being\n                typed.\n            word (str): Word being typed (corresponding to the keystrokes).\n\n        Returns:\n            The list of correction candidates.\n        \"\"\"\n        return []\n\n    def auto_complete(\n        self,\n        context: str,\n        keystrokes: List[Optional[Tuple[float, float]]],\n        partial_word: str,\n    ) -&gt; List[str]:\n        \"\"\"Method used for auto-completion.\n        Given a context and a partially typed word, this method should return\n        a list of possible candidates for completion.\n\n        Note that the typed word is given both as a plain string, and as a list\n        of keystrokes. The child class overwriting this method can use either\n        of them.\n\n        Args:\n            context (str): String representing the previously typed characters\n                (the beginning of the sentence basically).\n            keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n                (x and y coordinates) for each keystroke of the word being\n                typed.\n            partial_word (str): Partial word being typed (corresponding to the\n                keystrokes).\n\n        Returns:\n            The list of completion candidates.\n        \"\"\"\n        return []\n\n    def resolve_swipe(self, context: str, swipe_gesture: List[Tuple[float, float]]) -&gt; List[str]:\n        \"\"\"Method used for resolving a swipe gesture. Given a context and a\n        swipe gesture, this method should return a list of possible candidates\n        corresponding to this swipe gesture.\n\n        Args:\n            context (str): String representing the previously typed characters\n                (the beginning of the sentence basically).\n            swipe_gesture (List[Tuple[float, float]]): List of positions (x and\n                y coordinates) along the keyboard, representing the swipe\n                gesture.\n\n        Returns:\n            The list of swiped word candidates.\n        \"\"\"\n        return []\n\n    def predict_next_word(self, context: str) -&gt; List[str]:\n        \"\"\"Method used for next-word prediction task. Given a context, this\n        method should return a list of possible candidates for next-word.\n\n        Args:\n            context (str): String representing the previously typed characters\n                (the beginning of the sentence basically).\n\n        Returns:\n            The list of next-word candidates.\n        \"\"\"\n        return []\n\n    def profiled_auto_correct(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n        \"\"\"Profiled (memory &amp; runtime) version of `auto_correct` method.\n\n        No need to overwrite this method, unless you want to specify a custom\n        memory and/or runtime measure.\n\n        Returns:\n            List of candidates returned from the profiled method.\n            Memory consumption in bytes.\n            Runtime in nano seconds.\n        \"\"\"\n        return profile_fn(self.auto_correct, *args, **kwargs)\n\n    def profiled_auto_complete(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n        \"\"\"Profiled (memory &amp; runtime) version of `auto_complete` method.\n\n        No need to overwrite this method, unless you want to specify a custom\n        memory and/or runtime measure.\n\n        Returns:\n            List of candidates returned from the profiled method.\n            Memory consumption in bytes.\n            Runtime in nano seconds.\n        \"\"\"\n        return profile_fn(self.auto_complete, *args, **kwargs)\n\n    def profiled_resolve_swipe(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n        \"\"\"Profiled (memory &amp; runtime) version of `resolve_swipe` method.\n\n        No need to overwrite this method, unless you want to specify a custom\n        memory and/or runtime measure.\n\n        Returns:\n            List of candidates returned from the profiled method.\n            Memory consumption in bytes.\n            Runtime in nano seconds.\n        \"\"\"\n        return profile_fn(self.resolve_swipe, *args, **kwargs)\n\n    def profiled_predict_next_word(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n        \"\"\"Profiled (memory &amp; runtime) version of `predict_next_word` method.\n\n        No need to overwrite this method, unless you want to specify a custom\n        memory and/or runtime measure.\n\n        Returns:\n            List of candidates returned from the profiled method.\n            Memory consumption in bytes.\n            Runtime in nano seconds.\n        \"\"\"\n        return profile_fn(self.predict_next_word, *args, **kwargs)\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.auto_correct","title":"<code>auto_correct(context, keystrokes, word)</code>","text":"<p>Method used for auto-correction. Given a context and a typed word, this method should return a list of possible candidates for correction.</p> <p>Note that the typed word is given both as a plain string, and as a list of keystrokes. The child class overwriting this method can use either of them.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>String representing the previously typed characters (the beginning of the sentence basically).</p> required <code>keystrokes</code> <code>List[Optional[Tuple[float, float]]]</code> <p>List of positions (x and y coordinates) for each keystroke of the word being typed.</p> required <code>word</code> <code>str</code> <p>Word being typed (corresponding to the keystrokes).</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of correction candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def auto_correct(\n    self,\n    context: str,\n    keystrokes: List[Optional[Tuple[float, float]]],\n    word: str,\n) -&gt; List[str]:\n    \"\"\"Method used for auto-correction.\n    Given a context and a typed word, this method should return a list of\n    possible candidates for correction.\n\n    Note that the typed word is given both as a plain string, and as a list\n    of keystrokes. The child class overwriting this method can use either\n    of them.\n\n    Args:\n        context (str): String representing the previously typed characters\n            (the beginning of the sentence basically).\n        keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n            (x and y coordinates) for each keystroke of the word being\n            typed.\n        word (str): Word being typed (corresponding to the keystrokes).\n\n    Returns:\n        The list of correction candidates.\n    \"\"\"\n    return []\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.auto_complete","title":"<code>auto_complete(context, keystrokes, partial_word)</code>","text":"<p>Method used for auto-completion. Given a context and a partially typed word, this method should return a list of possible candidates for completion.</p> <p>Note that the typed word is given both as a plain string, and as a list of keystrokes. The child class overwriting this method can use either of them.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>String representing the previously typed characters (the beginning of the sentence basically).</p> required <code>keystrokes</code> <code>List[Optional[Tuple[float, float]]]</code> <p>List of positions (x and y coordinates) for each keystroke of the word being typed.</p> required <code>partial_word</code> <code>str</code> <p>Partial word being typed (corresponding to the keystrokes).</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of completion candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def auto_complete(\n    self,\n    context: str,\n    keystrokes: List[Optional[Tuple[float, float]]],\n    partial_word: str,\n) -&gt; List[str]:\n    \"\"\"Method used for auto-completion.\n    Given a context and a partially typed word, this method should return\n    a list of possible candidates for completion.\n\n    Note that the typed word is given both as a plain string, and as a list\n    of keystrokes. The child class overwriting this method can use either\n    of them.\n\n    Args:\n        context (str): String representing the previously typed characters\n            (the beginning of the sentence basically).\n        keystrokes (List[Optional[Tuple[float, float]]]): List of positions\n            (x and y coordinates) for each keystroke of the word being\n            typed.\n        partial_word (str): Partial word being typed (corresponding to the\n            keystrokes).\n\n    Returns:\n        The list of completion candidates.\n    \"\"\"\n    return []\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.resolve_swipe","title":"<code>resolve_swipe(context, swipe_gesture)</code>","text":"<p>Method used for resolving a swipe gesture. Given a context and a swipe gesture, this method should return a list of possible candidates corresponding to this swipe gesture.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>String representing the previously typed characters (the beginning of the sentence basically).</p> required <code>swipe_gesture</code> <code>List[Tuple[float, float]]</code> <p>List of positions (x and y coordinates) along the keyboard, representing the swipe gesture.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of swiped word candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def resolve_swipe(self, context: str, swipe_gesture: List[Tuple[float, float]]) -&gt; List[str]:\n    \"\"\"Method used for resolving a swipe gesture. Given a context and a\n    swipe gesture, this method should return a list of possible candidates\n    corresponding to this swipe gesture.\n\n    Args:\n        context (str): String representing the previously typed characters\n            (the beginning of the sentence basically).\n        swipe_gesture (List[Tuple[float, float]]): List of positions (x and\n            y coordinates) along the keyboard, representing the swipe\n            gesture.\n\n    Returns:\n        The list of swiped word candidates.\n    \"\"\"\n    return []\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.predict_next_word","title":"<code>predict_next_word(context)</code>","text":"<p>Method used for next-word prediction task. Given a context, this method should return a list of possible candidates for next-word.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>String representing the previously typed characters (the beginning of the sentence basically).</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>The list of next-word candidates.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def predict_next_word(self, context: str) -&gt; List[str]:\n    \"\"\"Method used for next-word prediction task. Given a context, this\n    method should return a list of possible candidates for next-word.\n\n    Args:\n        context (str): String representing the previously typed characters\n            (the beginning of the sentence basically).\n\n    Returns:\n        The list of next-word candidates.\n    \"\"\"\n    return []\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.profiled_auto_correct","title":"<code>profiled_auto_correct(*args, **kwargs)</code>","text":"<p>Profiled (memory &amp; runtime) version of <code>auto_correct</code> method.</p> <p>No need to overwrite this method, unless you want to specify a custom memory and/or runtime measure.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of candidates returned from the profiled method.</p> <code>int</code> <p>Memory consumption in bytes.</p> <code>int</code> <p>Runtime in nano seconds.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def profiled_auto_correct(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n    \"\"\"Profiled (memory &amp; runtime) version of `auto_correct` method.\n\n    No need to overwrite this method, unless you want to specify a custom\n    memory and/or runtime measure.\n\n    Returns:\n        List of candidates returned from the profiled method.\n        Memory consumption in bytes.\n        Runtime in nano seconds.\n    \"\"\"\n    return profile_fn(self.auto_correct, *args, **kwargs)\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.profiled_auto_complete","title":"<code>profiled_auto_complete(*args, **kwargs)</code>","text":"<p>Profiled (memory &amp; runtime) version of <code>auto_complete</code> method.</p> <p>No need to overwrite this method, unless you want to specify a custom memory and/or runtime measure.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of candidates returned from the profiled method.</p> <code>int</code> <p>Memory consumption in bytes.</p> <code>int</code> <p>Runtime in nano seconds.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def profiled_auto_complete(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n    \"\"\"Profiled (memory &amp; runtime) version of `auto_complete` method.\n\n    No need to overwrite this method, unless you want to specify a custom\n    memory and/or runtime measure.\n\n    Returns:\n        List of candidates returned from the profiled method.\n        Memory consumption in bytes.\n        Runtime in nano seconds.\n    \"\"\"\n    return profile_fn(self.auto_complete, *args, **kwargs)\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.profiled_resolve_swipe","title":"<code>profiled_resolve_swipe(*args, **kwargs)</code>","text":"<p>Profiled (memory &amp; runtime) version of <code>resolve_swipe</code> method.</p> <p>No need to overwrite this method, unless you want to specify a custom memory and/or runtime measure.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of candidates returned from the profiled method.</p> <code>int</code> <p>Memory consumption in bytes.</p> <code>int</code> <p>Runtime in nano seconds.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def profiled_resolve_swipe(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n    \"\"\"Profiled (memory &amp; runtime) version of `resolve_swipe` method.\n\n    No need to overwrite this method, unless you want to specify a custom\n    memory and/or runtime measure.\n\n    Returns:\n        List of candidates returned from the profiled method.\n        Memory consumption in bytes.\n        Runtime in nano seconds.\n    \"\"\"\n    return profile_fn(self.resolve_swipe, *args, **kwargs)\n</code></pre>"},{"location":"public_api/#kebbie.correctors.Corrector.profiled_predict_next_word","title":"<code>profiled_predict_next_word(*args, **kwargs)</code>","text":"<p>Profiled (memory &amp; runtime) version of <code>predict_next_word</code> method.</p> <p>No need to overwrite this method, unless you want to specify a custom memory and/or runtime measure.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of candidates returned from the profiled method.</p> <code>int</code> <p>Memory consumption in bytes.</p> <code>int</code> <p>Runtime in nano seconds.</p> Source code in <code>kebbie/correctors.py</code> <pre><code>def profiled_predict_next_word(self, *args, **kwargs) -&gt; Tuple[List[str], int, int]:\n    \"\"\"Profiled (memory &amp; runtime) version of `predict_next_word` method.\n\n    No need to overwrite this method, unless you want to specify a custom\n    memory and/or runtime measure.\n\n    Returns:\n        List of candidates returned from the profiled method.\n        Memory consumption in bytes.\n        Runtime in nano seconds.\n    \"\"\"\n    return profile_fn(self.predict_next_word, *args, **kwargs)\n</code></pre>"},{"location":"public_api/#functions","title":"Functions","text":""},{"location":"public_api/#kebbie.evaluate","title":"<code>evaluate(corrector, lang='en-US', custom_keyboard=None, dataset=None, track_mistakes=False, n_most_common_mistakes=N_MOST_COMMON_MISTAKES, n_proc=None, seed=DEFAULT_SEED, beta=DEFAULT_BETA)</code>","text":"<p>Main function of the <code>kebbie</code> framework, it evaluates the given Corrector.</p> <p>Parameters:</p> Name Type Description Default <code>corrector</code> <code>Corrector</code> <p>The corrector to evaluate.</p> required <code>lang</code> <code>str</code> <p>Language to test. For now, only <code>en-US</code> is supported.</p> <code>'en-US'</code> <code>custom_keyboard</code> <code>Dict</code> <p>If provided, instead of relying on the keyboard layout provided by default, uses the given keyboard layout.</p> <code>None</code> <code>dataset</code> <code>Dict[str, List[str]]</code> <p>Data to use for testing. It should be a dictionary where the key is the name of the domain, and the value is a list of sentences. If <code>None</code> is given, it will use the SODA dataset.</p> <code>None</code> <code>track_mistakes</code> <code>bool</code> <p>If <code>True</code>, we will track the most common mistakes of the Corrector (these will be saved as TSV files in the working directory).</p> <code>False</code> <code>n_most_common_mistakes</code> <code>int</code> <p>If <code>track_mistakes</code> is set to <code>True</code>, the top X mistakes to record.</p> <code>N_MOST_COMMON_MISTAKES</code> <code>n_proc</code> <code>int</code> <p>Number of processes to use. If <code>None</code>, <code>os.cpu_count()</code> is used.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Seed to use for running the tests.</p> <code>DEFAULT_SEED</code> <code>beta</code> <code>float</code> <p>Beta to use for computing the F-beta score.</p> <code>DEFAULT_BETA</code> <p>Raises:</p> Type Description <code>UnsupportedLanguage</code> <p>Exception raised if <code>lang</code> is set to a language that is not supported yet.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>The results, in a dictionary.</p> Source code in <code>kebbie/__init__.py</code> <pre><code>def evaluate(\n    corrector: Corrector,\n    lang: str = \"en-US\",\n    custom_keyboard: Dict = None,\n    dataset: Dict[str, List[str]] = None,\n    track_mistakes: bool = False,\n    n_most_common_mistakes: int = N_MOST_COMMON_MISTAKES,\n    n_proc: Optional[int] = None,\n    seed: int = DEFAULT_SEED,\n    beta: float = DEFAULT_BETA,\n) -&gt; Dict:\n    \"\"\"Main function of the `kebbie` framework, it evaluates the given\n    Corrector.\n\n    Args:\n        corrector (Corrector): The corrector to evaluate.\n        lang (str, optional): Language to test. For now, only `en-US` is\n            supported.\n        custom_keyboard (Dict, optional): If provided, instead of relying on\n            the keyboard layout provided by default, uses the given keyboard\n            layout.\n        dataset (Dict[str, List[str]], optional): Data to use for testing. It\n            should be a dictionary where the key is the name of the domain, and\n            the value is a list of sentences. If `None` is given, it will use\n            the SODA dataset.\n        track_mistakes (bool, optional): If `True`, we will track the most\n            common mistakes of the Corrector (these will be saved as TSV files\n            in the working directory).\n        n_most_common_mistakes (int, optional): If `track_mistakes` is set to\n            `True`, the top X mistakes to record.\n        n_proc (int, optional): Number of processes to use. If `None`,\n            `os.cpu_count()` is used.\n        seed (int): Seed to use for running the tests.\n        beta (float, optional): Beta to use for computing the F-beta score.\n\n    Raises:\n        UnsupportedLanguage: Exception raised if `lang` is set to a language\n            that is not supported yet.\n\n    Returns:\n        The results, in a dictionary.\n    \"\"\"\n    if lang not in SUPPORTED_LANG and custom_keyboard is None:\n        raise UnsupportedLanguage(f\"{lang} is not supported yet. List of supported languages : {SUPPORTED_LANG}\")\n\n    if dataset is None:\n        dataset = get_soda_dataset()\n\n    # Create the Oracle, the class used to create test cases and evaluate the scores\n    oracle = Oracle(\n        lang,\n        dataset,\n        custom_keyboard=custom_keyboard,\n        track_mistakes=track_mistakes,\n        n_most_common_mistakes=n_most_common_mistakes,\n        beta=beta,\n    )\n\n    # Run the tests &amp; get the results\n    results = oracle.test(corrector, n_proc=n_proc, seed=seed)\n    return results\n</code></pre>"},{"location":"public_api/#exceptions","title":"Exceptions","text":""},{"location":"public_api/#kebbie.UnsupportedLanguage","title":"<code>UnsupportedLanguage</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom Exception when the required language is not supported.</p> Source code in <code>kebbie/__init__.py</code> <pre><code>class UnsupportedLanguage(Exception):\n    \"\"\"Custom Exception when the required language is not supported.\"\"\"\n\n    pass\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p><code>kebbie</code> exposes a class Corrector and a function evaluate().</p> <p>The user creates a custom class which inherits from Corrector, over-write methods such as auto_correct(), auto_complete(), predict_next_word(), and resolve_swipe(). Then the user calls evaluate() with the custom Corrector, which will run the benchmark and return the results as a <code>Dictionary</code> (it contains various metrics for each task).</p> <p>Let's see how to do that in details with a basic example : we will use <code>pyspellchecker</code>, a pure-Python spell-checking library, and test it using <code>kebbie</code> to see how well it performs.</p>"},{"location":"usage/#creating-your-own-corrector","title":"Creating your own Corrector","text":"<p>First, we define a subclass of Corrector, and we implement the constructor.</p> <p>In our case, the constructor will simply initialize the <code>pyspellchecker</code> library :</p> <pre><code>from spellchecker import SpellChecker\nfrom kebbie import Corrector\n\n\nclass ExampleCorrector(Corrector):\n    def __init__(self):\n        self.spellchecker = SpellChecker()\n</code></pre> <p>For this example we are only interested in auto-correction (spell-checking). So we need to over-write the auto_correct() method.</p> <p>The implementation is straightforward thanks to <code>pyspellchecker</code> :</p> <pre><code>from typing import List\n\nfrom spellchecker import SpellChecker\nfrom kebbie import Corrector\n\n\nclass ExampleCorrector(Corrector):\n    def __init__(self):\n        self.spellchecker = SpellChecker()\n\n    def auto_correct(self, context: str, keystrokes, word: str) -&gt; List[str]:\n        cands = self.spellchecker.candidates(word)\n        return list(cands) if cands is not None else []\n</code></pre> <p>Great ! We have a testable Corrector class.</p> <p>Info</p> <p>We didn't overwrite the methods for the other tasks, and that's fine ! Other tasks' score will be set to 0, but we are just interested in auto-correction score anyway.</p>"},{"location":"usage/#calling-the-evaluate-function","title":"Calling the evaluate() function","text":"<p>Once we have the Corrector implemented, we can simply instantiate it and call the evaluate() function :</p> <pre><code>import json\nfrom typing import List\n\nfrom spellchecker import SpellChecker\nfrom kebbie import Corrector, evaluate\n\n\nclass ExampleCorrector(Corrector):\n    def __init__(self):\n        self.spellchecker = SpellChecker()\n\n    def auto_correct(self, context: str, keystrokes, word: str) -&gt; List[str]:\n        cands = self.spellchecker.candidates(word)\n        return list(cands) if cands is not None else []\n\n\nif __name__ == \"__main__\":\n    corrector = ExampleCorrector()\n    results = evaluate(corrector)\n\n    # Save the results in a local file for later inspection\n    with open(\"results.json\", \"w\") as f:\n        json.dump(results, f, ensure_ascii=False, indent=4)\n</code></pre> <p>And that's it !</p> <p>Now you can just run your script. It might take some time to go over the 2 000 sentences of the test set, but eventually it will end and you should see a file <code>results.json</code> in your working directory.</p>"},{"location":"usage/#inspecting-the-results","title":"Inspecting the results","text":"<p>Go ahead and open the file <code>results.json</code>.</p> <p>It contains the results of the test, with various metrics.</p> Results for <code>pyspellchecker==0.8.1</code> at the time of writing <pre><code>{\n    \"next_word_prediction\": {\n        \"score\": {\n            \"accuracy\": 0,\n            \"top3_accuracy\": 0,\n            \"n\": 46978\n        },\n        \"per_domain\": {\n            \"narrative\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 32044\n            },\n            \"dialogue\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 14934\n            }\n        },\n        \"performances\": {\n            \"mean_memory\": \"865.0 KB\",\n            \"min_memory\": \"8.24 KB\",\n            \"max_memory\": \"1.1 MB\",\n            \"mean_runtime\": \"5.91 \u03bcs\",\n            \"fastest_runtime\": \"0 ns\",\n            \"slowest_runtime\": \"2.13 ms\"\n        }\n    },\n    \"auto_completion\": {\n        \"score\": {\n            \"accuracy\": 0,\n            \"top3_accuracy\": 0,\n            \"n\": 46910\n        },\n        \"per_domain\": {\n            \"narrative\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 32002\n            },\n            \"dialogue\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 14908\n            }\n        },\n        \"per_completion_rate\": {\n            \"&lt;25%\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 1335\n            },\n            \"25%~50%\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 8891\n            },\n            \"50%~75%\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 25757\n            },\n            \"&gt;75%\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 10927\n            }\n        },\n        \"per_other\": {\n            \"without_typo\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 43450\n            },\n            \"with_typo\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 3460\n            }\n        },\n        \"performances\": {\n            \"mean_memory\": \"865.0 KB\",\n            \"min_memory\": \"424 B\",\n            \"max_memory\": \"1.1 MB\",\n            \"mean_runtime\": \"9.57 \u03bcs\",\n            \"fastest_runtime\": \"0 ns\",\n            \"slowest_runtime\": \"89.8 ms\"\n        }\n    },\n    \"auto_correction\": {\n        \"score\": {\n            \"accuracy\": 0.87,\n            \"precision\": 0.47,\n            \"recall\": 0.35,\n            \"fscore\": 0.41,\n            \"top3_accuracy\": 0.88,\n            \"top3_precision\": 0.56,\n            \"top3_recall\": 0.5,\n            \"top3_fscore\": 0.53,\n            \"n_typo\": 6302,\n            \"n\": 48864\n        },\n        \"per_domain\": {\n            \"narrative\": {\n                \"accuracy\": 0.87,\n                \"precision\": 0.48,\n                \"recall\": 0.36,\n                \"fscore\": 0.42,\n                \"top3_accuracy\": 0.89,\n                \"top3_precision\": 0.57,\n                \"top3_recall\": 0.51,\n                \"top3_fscore\": 0.54,\n                \"n_typo\": 4247,\n                \"n\": 32948\n            },\n            \"dialogue\": {\n                \"accuracy\": 0.86,\n                \"precision\": 0.44,\n                \"recall\": 0.34,\n                \"fscore\": 0.39,\n                \"top3_accuracy\": 0.88,\n                \"top3_precision\": 0.53,\n                \"top3_recall\": 0.48,\n                \"top3_fscore\": 0.51,\n                \"n_typo\": 2055,\n                \"n\": 15916\n            }\n        },\n        \"per_typo_type\": {\n            \"DELETE_SPELLING_SYMBOL\": {\n                \"accuracy\": 0.83,\n                \"precision\": 0.15,\n                \"recall\": 0.07,\n                \"fscore\": 0.099,\n                \"top3_accuracy\": 0.84,\n                \"top3_precision\": 0.26,\n                \"top3_recall\": 0.14,\n                \"top3_fscore\": 0.19,\n                \"n_typo\": 129,\n                \"n\": 1000\n            },\n            \"DELETE_SPACE\": {\n                \"accuracy\": 0.83,\n                \"precision\": 0.11,\n                \"recall\": 0.051,\n                \"fscore\": 0.074,\n                \"top3_accuracy\": 0.83,\n                \"top3_precision\": 0.11,\n                \"top3_recall\": 0.051,\n                \"top3_fscore\": 0.074,\n                \"n_typo\": 137,\n                \"n\": 1062\n            },\n            \"DELETE_PUNCTUATION\": {\n                \"accuracy\": 0,\n                \"precision\": 0,\n                \"recall\": 0,\n                \"fscore\": 0,\n                \"top3_accuracy\": 0,\n                \"top3_precision\": 0,\n                \"top3_recall\": 0,\n                \"top3_fscore\": 0,\n                \"n_typo\": 0,\n                \"n\": 0\n            },\n            \"DELETE_CHAR\": {\n                \"accuracy\": 0.86,\n                \"precision\": 0.42,\n                \"recall\": 0.29,\n                \"fscore\": 0.35,\n                \"top3_accuracy\": 0.88,\n                \"top3_precision\": 0.55,\n                \"top3_recall\": 0.48,\n                \"top3_fscore\": 0.52,\n                \"n_typo\": 559,\n                \"n\": 4334\n            },\n            \"ADD_SPELLING_SYMBOL\": {\n                \"accuracy\": 0,\n                \"precision\": 0,\n                \"recall\": 0,\n                \"fscore\": 0,\n                \"top3_accuracy\": 0,\n                \"top3_precision\": 0,\n                \"top3_recall\": 0,\n                \"top3_fscore\": 0,\n                \"n_typo\": 0,\n                \"n\": 0\n            },\n            \"ADD_SPACE\": {\n                \"accuracy\": 0,\n                \"precision\": 0,\n                \"recall\": 0,\n                \"fscore\": 0,\n                \"top3_accuracy\": 0,\n                \"top3_precision\": 0,\n                \"top3_recall\": 0,\n                \"top3_fscore\": 0,\n                \"n_typo\": 0,\n                \"n\": 0\n            },\n            \"ADD_PUNCTUATION\": {\n                \"accuracy\": 0,\n                \"precision\": 0,\n                \"recall\": 0,\n                \"fscore\": 0,\n                \"top3_accuracy\": 0,\n                \"top3_precision\": 0,\n                \"top3_recall\": 0,\n                \"top3_fscore\": 0,\n                \"n_typo\": 0,\n                \"n\": 0\n            },\n            \"ADD_CHAR\": {\n                \"accuracy\": 0.9,\n                \"precision\": 0.6,\n                \"recall\": 0.59,\n                \"fscore\": 0.59,\n                \"top3_accuracy\": 0.92,\n                \"top3_precision\": 0.66,\n                \"top3_recall\": 0.76,\n                \"top3_fscore\": 0.7,\n                \"n_typo\": 855,\n                \"n\": 6629\n            },\n            \"SUBSTITUTE_CHAR\": {\n                \"accuracy\": 0.86,\n                \"precision\": 0.47,\n                \"recall\": 0.35,\n                \"fscore\": 0.4,\n                \"top3_accuracy\": 0.88,\n                \"top3_precision\": 0.55,\n                \"top3_recall\": 0.49,\n                \"top3_fscore\": 0.53,\n                \"n_typo\": 863,\n                \"n\": 6691\n            },\n            \"SIMPLIFY_ACCENT\": {\n                \"accuracy\": 0,\n                \"precision\": 0,\n                \"recall\": 0,\n                \"fscore\": 0,\n                \"top3_accuracy\": 0,\n                \"top3_precision\": 0,\n                \"top3_recall\": 0,\n                \"top3_fscore\": 0,\n                \"n_typo\": 0,\n                \"n\": 0\n            },\n            \"SIMPLIFY_CASE\": {\n                \"accuracy\": 0.82,\n                \"precision\": 0,\n                \"recall\": 0,\n                \"fscore\": 0,\n                \"top3_accuracy\": 0.82,\n                \"top3_precision\": 0,\n                \"top3_recall\": 0,\n                \"top3_fscore\": 0,\n                \"n_typo\": 403,\n                \"n\": 3125\n            },\n            \"TRANSPOSE_CHAR\": {\n                \"accuracy\": 0.89,\n                \"precision\": 0.58,\n                \"recall\": 0.54,\n                \"fscore\": 0.56,\n                \"top3_accuracy\": 0.91,\n                \"top3_precision\": 0.64,\n                \"top3_recall\": 0.7,\n                \"top3_fscore\": 0.66,\n                \"n_typo\": 1313,\n                \"n\": 10181\n            },\n            \"COMMON_TYPO\": {\n                \"accuracy\": 0.85,\n                \"precision\": 0.39,\n                \"recall\": 0.26,\n                \"fscore\": 0.32,\n                \"top3_accuracy\": 0.88,\n                \"top3_precision\": 0.53,\n                \"top3_recall\": 0.45,\n                \"top3_fscore\": 0.49,\n                \"n_typo\": 1725,\n                \"n\": 13375\n            }\n        },\n        \"per_number_of_typos\": {\n            \"1\": {\n                \"accuracy\": 0.87,\n                \"precision\": 0.47,\n                \"recall\": 0.36,\n                \"fscore\": 0.41,\n                \"top3_accuracy\": 0.89,\n                \"top3_precision\": 0.56,\n                \"top3_recall\": 0.51,\n                \"top3_fscore\": 0.54,\n                \"n_typo\": 5984,\n                \"n\": 46397\n            },\n            \"2\": {\n                \"accuracy\": 0.86,\n                \"precision\": 0.43,\n                \"recall\": 0.29,\n                \"fscore\": 0.35,\n                \"top3_accuracy\": 0.87,\n                \"top3_precision\": 0.47,\n                \"top3_recall\": 0.36,\n                \"top3_fscore\": 0.41,\n                \"n_typo\": 292,\n                \"n\": 2264\n            },\n            \"3+\": {\n                \"accuracy\": 0.83,\n                \"precision\": 0.17,\n                \"recall\": 0.077,\n                \"fscore\": 0.11,\n                \"top3_accuracy\": 0.84,\n                \"top3_precision\": 0.23,\n                \"top3_recall\": 0.12,\n                \"top3_fscore\": 0.16,\n                \"n_typo\": 26,\n                \"n\": 202\n            }\n        },\n        \"performances\": {\n            \"mean_memory\": \"866.0 KB\",\n            \"min_memory\": \"7.05 KB\",\n            \"max_memory\": \"1.1 MB\",\n            \"mean_runtime\": \"358.0 ms\",\n            \"fastest_runtime\": \"69.1 \u03bcs\",\n            \"slowest_runtime\": \"77.1 s\"\n        }\n    },\n    \"swipe_resolution\": {\n        \"score\": {\n            \"accuracy\": 0,\n            \"top3_accuracy\": 0,\n            \"n\": 417\n        },\n        \"per_domain\": {\n            \"narrative\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 313\n            },\n            \"dialogue\": {\n                \"accuracy\": 0,\n                \"top3_accuracy\": 0,\n                \"n\": 104\n            }\n        },\n        \"performances\": {\n            \"mean_memory\": \"860.0 KB\",\n            \"min_memory\": \"96.0 KB\",\n            \"max_memory\": \"1.1 MB\",\n            \"mean_runtime\": \"24.5 \u03bcs\",\n            \"fastest_runtime\": \"0 ns\",\n            \"slowest_runtime\": \"4.68 ms\"\n        }\n    },\n    \"overall_score\": 0.164\n}\n</code></pre> <p>Let's go over the content quickly.</p> <p>First, the metrics are divided into each tasks :</p> <ul> <li><code>next_word_prediction</code></li> <li><code>auto_completion</code></li> <li><code>auto_correction</code></li> <li><code>swipe_resolution</code></li> </ul> <p>Info</p> <p>At the end of the file, there is also a field <code>overall_score</code>. This is just an aggregation of the scores of all tasks, to have an easy way to compare runs.</p> <p>As expected, if you look at other tasks than <code>auto_correction</code>, their score is zero. That's expected, because we are interested only on auto-correction, and we didn't implement the code for the other tasks.</p> <p>Let's take a deeper look at the <code>auto_correction</code> results.</p> <p>First, we have a <code>score</code> field, which contains various overall metrics about the auto-correction capability : precision, recall, F-score, etc...</p> <p>There is also a value <code>n</code>, which shows the total number of words we tried to auto-correct, and <code>n_typo</code>, the number of words which contained a typo.</p> <p>For auto-correction, the metric we care about is the F-score, as it measure both the precision and the recall.</p> <p>Info</p> <p>For more information about the metrics and their meaning, check out the Metrics page.</p> <p>Then we have a <code>per_domain</code> field, which also contains the same metrics, but divided into the various domains of our dataset. We can see that <code>pyspellchecker</code> is better at correcting <code>narrative</code> data than <code>dialogue</code> data, since the F-score is higher.</p> <p>We then have a <code>per_typo_type</code> field, which shows the metrics for each type of typo introduced. Note that the evaluate() does not introduce all type of typos by default, so some of them are set to <code>0</code>.</p> <p>After we have a <code>per_number_of_typos</code> field, which gives the metrics depending on how many typos were introduced in that word.</p> <p>And finally we have a field <code>performances</code>, which show the memory consumption and runtime for the auto_correct() method that we wrote.</p>"},{"location":"usage/#a-note-about-multiprocessing","title":"A note about multiprocessing","text":"<p>Under the hood, evaluate() uses multiprocessing to run faster.</p> <p>It means that your Corrector should be pickable !</p> <p>Example</p> <p>In the example above, the implementation provided is already pickable, so there is nothing to do.</p> <p>If you need to make your class pickable, just implement the <code>__reduce__()</code> magic method, like this :</p> <pre><code>from typing import Tuple\n\nfrom kebbie import Corrector\n\n\nclass GreatCorrector(Corrector):\n    def __init__(self, model_path: str):\n        self.m_path = model_path\n\n        # Because of this (imaginary) non-pickable attribute,\n        # the class `GreatCorrector` is not pickable as-is\n        self.non_pickable_model = load_model(model_path)\n\n    def __reduce__(self) -&gt; Tuple:\n        # But by implementing `__reduce__()`, we can make it pickable !\n        return (GreatCorrector, (self.m_path,))\n</code></pre>"},{"location":"usage/#advanced-usage","title":"Advanced usage","text":""},{"location":"usage/#leveraging-the-keystroke-coordinates","title":"Leveraging the keystroke coordinates","text":"<p>Did you notice that in our auto_correct() implementation, there is an argument <code>keystrokes</code> that we didn't use ?</p> <pre><code>class ExampleCorrector(Corrector):\n    def __init__(self):\n        self.spellchecker = SpellChecker()\n\n    def auto_correct(self, context: str, keystrokes, word: str) -&gt; List[str]:\n        cands = self.spellchecker.candidates(word)\n        return list(cands) if cands is not None else []\n</code></pre> <p>This <code>keystrokes</code> argument is a list of keystrokes coordinates (one per character of the typed <code>word</code>).</p> <p>These coordinates may hold useful information : for example on a QWERTY keyboard, if the word typed is <code>lovw</code> but the keystroke for <code>w</code> is very close to the border of the <code>e</code> key... There is a great chance that the word should be auto-corrected to <code>love</code>...</p> <p>These coordinates are defined in a layout file internally. To interact easily with the layout, you can use the LayoutHelper class.</p> <p>You can use the method get_key_info() to retrieve data about the key for the given character.</p> <p>For example, let's compute the distance between the first keystroke of the word, and the key for the character <code>w</code> :</p> <pre><code>import math\nfrom kebbie.layout import LayoutHelper\n\nlayout = LayoutHelper()\n\ndef auto_correct(self, context: str, keystrokes, word: str) -&gt; List[str]:\n    _, _, w_key_center_x, w_key_center_y, _ = layout.get_key_info(\"w\")\n    if len(keystrokes) &gt; 0 and keystrokes[0] is not None:\n        print(math.dist(keystrokes[0], [w_key_center_x, w_key_center_y]))\n</code></pre>"},{"location":"usage/#custom-dataset","title":"Custom dataset","text":"<p>The evaluate() function uses a good default dataset (see Test data) to run the evaluation.</p> <p>However, you might want to run the evaluation on your own dataset.</p> <p>You can do this by passing your custom dataset to the evaluate() function :</p> <pre><code>my_dataset = load_my_private_dataset()\ncorrector = ExampleCorrector()\nresults = evaluate(corrector, dataset=my_dataset)\n</code></pre> <p>Your custom dataset should be a <code>Dict[str, List[str]]</code>, where each keys of the dictionary represents a specific domain, and the values are just the list of sentences.</p>"},{"location":"usage/#get-insights-on-most-common-mistakes","title":"Get insights on most common mistakes","text":"<p>When trying to improve your models, you might want to take a look at the most common mistakes your model is doing.</p> <p>You can achieve this simply by passing <code>track_mistakes=True</code> to the evaluate() function :</p> <pre><code>corrector = ExampleCorrector()\nresults = evaluate(corrector, track_mistakes=True)\n</code></pre> <p>It will record the most common mistakes your Corrector is doing, and add them in a new field (<code>most_common_mistakes</code>) in the returned results.</p> <p>The mistakes are tracked for the following tasks : next-word prediction, auto-completion, and auto-correction.</p> <p>Let's look at the most common mistakes for our example with <code>pyspellchecker</code> :</p> <pre><code>\"auto_correction\": [\n    [\n        \"Count\",\n        \"Expected\",\n        \"Predictions\",\n        \"Context\"\n    ],\n    [\n        266,\n        \"I'm\",\n        \"[ism, h'm]\",\n        \"Kolten beckoned Aida over wanting to hear what he had to say Aida I want to know what's on your mind Kolten said I'm\"\n    ],\n    [\n        157,\n        \"to\",\n        \"[tho]\",\n        \"Destanie was so angry that he felt like he might explode He felt the hot blood rushing to his head and his fists clenched tightly at his sides He took a deep breath and tried tho\"\n    ],\n    ...\n</code></pre> <p>Here we can see that we track several thing for each mistake :</p> <ul> <li><code>Count</code> : The total number of times this mistake happened</li> <li><code>Expected</code> : The expected word</li> <li><code>Predictions</code> : The model's predictions</li> <li><code>Context</code> : An example of a sentence where the mistake happened</li> </ul> <p>So we can see that the most common mistake of <code>pyspellchecker</code> is to try to auto correct <code>I'm</code> into <code>ism</code>, even though it should not be corrected. This mistake was encountered 266 times during the evaluation.</p> <p>The second most common mistake is to not auto-correct <code>tho</code>, even though it should be corrected to <code>to</code>. This mistake was encountered 157 times during the evaluation.</p> <p>Tip</p> <p>By default, the 1 000 most common mistakes will be saved. You can specify a different <code>n</code>, with the <code>n_most_common_mistakes</code> argument :</p> <pre><code>corrector = ExampleCorrector()\nresults = evaluate(corrector, track_mistakes=True, n_most_common_mistakes=150)\n</code></pre>"},{"location":"usage/#other-arguments","title":"Other arguments","text":"<p>Specify the number of processes to be used for multiprocessing with the <code>n_proc</code> argument :</p> <pre><code>corrector = ExampleCorrector()\nresults = evaluate(corrector, n_proc=4)\n</code></pre> <p>Note</p> <p>If <code>None</code> is given, evaluate() will use <code>os.cpu_count()</code> (the number of CPU of your machine). Defaults to <code>None</code>.</p> <p>Specify a different seed with the <code>seed</code> argument :</p> <pre><code>corrector = ExampleCorrector()\nresults = evaluate(corrector, seed=36)\n</code></pre> <p>Specify a different Beta for the F-score calculation (see the Metrics section) with the <code>beta</code> argument :</p> <pre><code>corrector = ExampleCorrector()\nresults = evaluate(corrector, beta=1.2)\n</code></pre>"}]}